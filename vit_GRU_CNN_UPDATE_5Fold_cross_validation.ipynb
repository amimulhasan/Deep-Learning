{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNw9g0eUw9Y1OZ2881g3G4+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amimulhasan/Deep-Learning/blob/main/vit_GRU_CNN_UPDATE_5Fold_cross_validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQQ5BYIQhyWL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# -----------------------\n",
        "# Hyperparameters\n",
        "# -----------------------\n",
        "input_shape = (128, 128, 3)\n",
        "patch_size = 16\n",
        "num_patches = (input_shape[0] // patch_size) * (input_shape[1] // patch_size)\n",
        "projection_dim = 64\n",
        "transformer_layers = 4\n",
        "num_heads = 4\n",
        "num_classes = 4\n",
        "\n",
        "# -----------------------\n",
        "# Patches layer\n",
        "# -----------------------\n",
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches\n",
        "\n",
        "# -----------------------\n",
        "# Patch Encoder layer\n",
        "# -----------------------\n",
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patches):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patches) + self.position_embedding(positions)\n",
        "        return encoded\n",
        "\n",
        "# -----------------------\n",
        "# Build the combined model\n",
        "# -----------------------\n",
        "def build_hybrid_model():\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # ---------------------\n",
        "    # DCNN Branch\n",
        "    # ---------------------\n",
        "    x_cnn = layers.Conv2D(32, (3,3), activation='relu', padding='same')(inputs)\n",
        "    x_cnn = layers.MaxPooling2D((2,2))(x_cnn)\n",
        "    x_cnn = layers.Conv2D(64, (3,3), activation='relu', padding='same')(x_cnn)\n",
        "    x_cnn = layers.MaxPooling2D((2,2))(x_cnn)\n",
        "    x_cnn = layers.Conv2D(128, (3,3), activation='relu', padding='same')(x_cnn)\n",
        "    x_cnn = layers.MaxPooling2D((2,2))(x_cnn)\n",
        "    x_cnn = layers.Flatten()(x_cnn)\n",
        "\n",
        "    # ---------------------\n",
        "    # ViT + GRU Branch\n",
        "    # ---------------------\n",
        "    x_vit = layers.Rescaling(1./255)(inputs)\n",
        "    patches = Patches(patch_size)(x_vit)\n",
        "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "\n",
        "    for _ in range(transformer_layers):\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.2\n",
        "        )(x1, x1)\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    x_vit = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    x_vit = layers.Dropout(0.2)(x_vit)\n",
        "    x_vit = layers.Flatten()(x_vit)\n",
        "    x_vit = layers.Reshape((-1, x_vit.shape[-1]))(x_vit)\n",
        "    x_vit = layers.GRU(256)(x_vit)\n",
        "\n",
        "    # ---------------------\n",
        "    # Concatenate DCNN and ViT+GRU\n",
        "    # ---------------------\n",
        "    x = layers.concatenate([x_cnn, x_vit])\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    # Build model\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# -----------------------\n",
        "# 5-Fold Cross Validation\n",
        "# -----------------------\n",
        "X = np.load(\"/kaggle/input/brain-tumor-dataset/X.npy\")  # Your data\n",
        "y = np.load(\"/kaggle/input/brain-tumor-dataset/y.npy\")  # Your labels\n",
        "\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "for train_idx, val_idx in kfold.split(X, y):\n",
        "    X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
        "    y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
        "\n",
        "    # Build the model\n",
        "    model = build_hybrid_model()\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train_fold, y_train_fold, epochs=5, batch_size=32)\n",
        "\n",
        "    # Predict on the validation set\n",
        "    y_pred_fold = model.predict(X_val_fold)\n",
        "    y_pred_fold = np.argmax(y_pred_fold, axis=1)  # Convert softmax output to class label\n",
        "\n",
        "    # Calculate metrics\n",
        "    metrics = classification_report(y_val_fold, y_pred_fold, output_dict=True)\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Plot confusion matrix for this fold\n",
        "    cm = confusion_matrix(y_val_fold, y_pred_fold)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
        "    plt.title(f\"Confusion Matrix for Fold {fold}\")\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.show()\n",
        "\n",
        "    # Print fold results\n",
        "    print(f\"Fold {fold} Classification Report:\\n\", classification_report(y_val_fold, y_pred_fold))\n",
        "    fold += 1\n",
        "\n",
        "# Compute average performance across folds\n",
        "avg_accuracy = np.mean([metrics['accuracy'] for metrics in all_metrics])\n",
        "avg_f1 = np.mean([metrics['weighted avg']['f1-score'] for metrics in all_metrics])\n",
        "\n",
        "print(f\"Average Accuracy across all folds: {avg_accuracy:.4f}\")\n",
        "print(f\"Average F1-score across all folds: {avg_f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_val_fold, y_pred_fold)\n"
      ],
      "metadata": {
        "id": "iP7k7sEBhznH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n"
      ],
      "metadata": {
        "id": "YlG0l2N6hz7L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}