{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1267593,"sourceType":"datasetVersion","datasetId":723383}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import Necessary Libraries\n\nimport os\nimport h5py\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras import layers, Model, backend as K","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:41:31.541268Z","iopub.execute_input":"2025-10-15T18:41:31.541838Z","iopub.status.idle":"2025-10-15T18:41:31.545804Z","shell.execute_reply.started":"2025-10-15T18:41:31.541815Z","shell.execute_reply":"2025-10-15T18:41:31.544854Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data Loading\n\nDATA_PATH = \"/kaggle/input/brats2020-training-data/BraTS2020_training_data/content/data\"\nMAX_FILES = 2000\n\ndef safe_load_h5(path):\n    try:\n        with h5py.File(path, 'r') as f:\n            img = np.array(f['image']).astype(np.float32)\n            msk = np.array(f['mask']).astype(np.float32)\n            return img, msk\n    except Exception as e:\n        return None, None\n\nprint(\"Loading dataset...\")\nfiles = sorted([f for f in os.listdir(DATA_PATH) if f.endswith('.h5')])[:MAX_FILES]\n\nimages = []\nmasks = []\n\nfor fname in tqdm(files, desc=\"Loading files\"):\n    p = os.path.join(DATA_PATH, fname)\n    img, msk = safe_load_h5(p)\n    if img is None:\n        continue\n        \n    if img.ndim == 2:\n        img = np.expand_dims(img, -1)\n    if msk.ndim == 2:\n        msk = np.expand_dims(msk, -1)\n\n    # Normalize image\n    p99 = np.percentile(img, 99)\n    img_norm = img / p99 if p99 > 0 else img\n    img_norm = np.clip(img_norm, 0.0, 1.0)\n\n    # Mask processing\n    msk = np.clip(msk, 0.0, 1.0)\n\n    images.append(img_norm)\n    masks.append(msk)\n\nX = np.array(images, dtype=np.float32)\nY = np.array(masks, dtype=np.float32)\nprint(f\"Loaded shapes -> X: {X.shape}, Y: {Y.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:41:31.557411Z","iopub.execute_input":"2025-10-15T18:41:31.557613Z","iopub.status.idle":"2025-10-15T18:42:09.076584Z","shell.execute_reply.started":"2025-10-15T18:41:31.5576Z","shell.execute_reply":"2025-10-15T18:42:09.075731Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Loss Functions\n\ndef dice_coef(y_true, y_pred, smooth=1e-6):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef dice_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n\ndef combined_loss(y_true, y_pred):\n    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n    bce = K.mean(bce)\n    d_loss = dice_loss(y_true, y_pred)\n    return bce + d_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:42:09.07806Z","iopub.execute_input":"2025-10-15T18:42:09.078511Z","iopub.status.idle":"2025-10-15T18:42:09.082974Z","shell.execute_reply.started":"2025-10-15T18:42:09.078493Z","shell.execute_reply":"2025-10-15T18:42:09.082438Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3-Channel U-Net\n\ndef build_simple_multi_unet(input_shape=(240, 240, 4), num_classes=3):\n    \"\"\"U-Net that works well\"\"\"\n    inputs = tf.keras.Input(shape=input_shape)\n    \n    # Downsample\n    c1 = layers.Conv2D(32, 3, activation='relu', padding='same')(inputs)\n    c1 = layers.Conv2D(32, 3, activation='relu', padding='same')(c1)\n    p1 = layers.MaxPooling2D(2)(c1)\n    \n    c2 = layers.Conv2D(64, 3, activation='relu', padding='same')(p1)\n    c2 = layers.Conv2D(64, 3, activation='relu', padding='same')(c2)\n    p2 = layers.MaxPooling2D(2)(c2)\n    \n    # Bottleneck\n    c3 = layers.Conv2D(128, 3, activation='relu', padding='same')(p2)\n    c3 = layers.Conv2D(128, 3, activation='relu', padding='same')(c3)\n    \n    # Upsample\n    u1 = layers.UpSampling2D(2)(c3)\n    u1 = layers.concatenate([u1, c2])\n    c4 = layers.Conv2D(64, 3, activation='relu', padding='same')(u1)\n    c4 = layers.Conv2D(64, 3, activation='relu', padding='same')(c4)\n    \n    u2 = layers.UpSampling2D(2)(c4)\n    u2 = layers.concatenate([u2, c1])\n    c5 = layers.Conv2D(32, 3, activation='relu', padding='same')(u2)\n    c5 = layers.Conv2D(32, 3, activation='relu', padding='same')(c5)\n    \n    # 3 output channels with sigmoid (independent segmentation)\n    outputs = layers.Conv2D(num_classes, 1, activation='sigmoid')(c5)\n    \n    model = tf.keras.Model(inputs, outputs)\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:42:09.083646Z","iopub.execute_input":"2025-10-15T18:42:09.083879Z","iopub.status.idle":"2025-10-15T18:42:09.099876Z","shell.execute_reply.started":"2025-10-15T18:42:09.083856Z","shell.execute_reply":"2025-10-15T18:42:09.099345Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train/Val Split\n\nX_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.18, random_state=42)\nprint(f\"Train: {X_train.shape}, {y_train.shape}\")\nprint(f\"Val: {X_val.shape}, {y_val.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:42:09.101683Z","iopub.execute_input":"2025-10-15T18:42:09.102234Z","iopub.status.idle":"2025-10-15T18:42:10.044055Z","shell.execute_reply.started":"2025-10-15T18:42:09.102192Z","shell.execute_reply":"2025-10-15T18:42:10.04325Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Build & Compile Model\n\nprint(\"Building 3-channel U-Net...\")\nmodel = build_simple_multi_unet(input_shape=X_train.shape[1:], num_classes=3)\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n    loss=combined_loss,\n    metrics=['accuracy', dice_coef]\n)\n\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:42:10.044723Z","iopub.execute_input":"2025-10-15T18:42:10.044926Z","iopub.status.idle":"2025-10-15T18:42:10.150293Z","shell.execute_reply.started":"2025-10-15T18:42:10.044908Z","shell.execute_reply":"2025-10-15T18:42:10.14952Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Callbacks\n\ncallbacks = [\n    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_dice_coef', factor=0.5, patience=10, min_lr=1e-7, mode='max'),\n    tf.keras.callbacks.EarlyStopping(monitor='val_dice_coef', patience=20, restore_best_weights=True, mode='max'),\n    tf.keras.callbacks.ModelCheckpoint('best_multi_model.h5', monitor='val_dice_coef', save_best_only=True, mode='max')\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:42:10.151315Z","iopub.execute_input":"2025-10-15T18:42:10.152116Z","iopub.status.idle":"2025-10-15T18:42:10.156266Z","shell.execute_reply.started":"2025-10-15T18:42:10.152091Z","shell.execute_reply":"2025-10-15T18:42:10.155614Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training\n\nprint(\"Starting training with 3-channel model...\")\nhistory = model.fit(\n    X_train, y_train,\n    batch_size=8,\n    epochs=100,  \n    validation_data=(X_val, y_val),\n    callbacks=callbacks,\n    shuffle=True,\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:42:10.156932Z","iopub.execute_input":"2025-10-15T18:42:10.157177Z","iopub.status.idle":"2025-10-15T19:18:48.605401Z","shell.execute_reply.started":"2025-10-15T18:42:10.15716Z","shell.execute_reply":"2025-10-15T19:18:48.60456Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluation Matrices\n\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\n\n# Enhanced metrics functions\ndef iou_coef(y_true, y_pred, smooth=1e-6):\n    \"\"\"Intersection over Union (Jaccard Index)\"\"\"\n    intersection = tf.reduce_sum(tf.abs(y_true * y_pred), axis=[1,2,3])\n    union = tf.reduce_sum(y_true, axis=[1,2,3]) + tf.reduce_sum(y_pred, axis=[1,2,3]) - intersection\n    iou = tf.reduce_mean((intersection + smooth) / (union + smooth))\n    return iou\n\ndef precision_metric(y_true, y_pred):\n    \"\"\"Precision metric\"\"\"\n    true_positives = tf.reduce_sum(tf.round(tf.clip_by_value(y_true * y_pred, 0, 1)))\n    predicted_positives = tf.reduce_sum(tf.round(tf.clip_by_value(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n    return precision\n\ndef recall_metric(y_true, y_pred):\n    \"\"\"Recall metric (Sensitivity)\"\"\"\n    true_positives = tf.reduce_sum(tf.round(tf.clip_by_value(y_true * y_pred, 0, 1)))\n    possible_positives = tf.reduce_sum(tf.round(tf.clip_by_value(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + tf.keras.backend.epsilon())\n    return recall\n\ndef specificity_metric(y_true, y_pred):\n    \"\"\"Specificity metric\"\"\"\n    true_negatives = tf.reduce_sum(tf.round(tf.clip_by_value((1-y_true) * (1-y_pred), 0, 1)))\n    possible_negatives = tf.reduce_sum(tf.round(tf.clip_by_value(1-y_true, 0, 1)))\n    specificity = true_negatives / (possible_negatives + tf.keras.backend.epsilon())\n    return specificity\n\ndef f1_score(y_true, y_pred):\n    \"\"\"F1-Score metric\"\"\"\n    precision = precision_metric(y_true, y_pred)\n    recall = recall_metric(y_true, y_pred)\n    return 2 * ((precision * recall) / (precision + recall + tf.keras.backend.epsilon()))\n\n# Enhanced evaluation function\ndef comprehensive_evaluation(model, X_val, y_val, threshold=0.5):\n    \"\"\"Comprehensive evaluation with medical segmentation metrics\"\"\"\n    \n    print(\"=\" * 70)\n    print(\"COMPREHENSIVE MODEL EVALUATION - MEDICAL SEGMENTATION\")\n    print(\"=\" * 70)\n    \n    # Get predictions\n    y_pred = model.predict(X_val, verbose=0)\n    y_pred_binary = (y_pred > threshold).astype(np.float32)\n    \n    # Flatten for overall metrics\n    y_true_flat = y_val.flatten()\n    y_pred_flat = y_pred_binary.flatten()\n    \n    # Calculate metrics\n    val_loss = model.evaluate(X_val, y_val, verbose=0)[0]\n    \n    # Overall metrics\n    overall_dice = dice_coef(\n        tf.convert_to_tensor(y_val), \n        tf.convert_to_tensor(y_pred)\n    ).numpy()\n    \n    overall_iou = iou_coef(\n        tf.convert_to_tensor(y_val), \n        tf.convert_to_tensor(y_pred_binary)\n    ).numpy()\n    \n    # Confusion matrix\n    cm = confusion_matrix(y_true_flat, y_pred_flat)\n    tn, fp, fn, tp = cm.ravel()\n    \n    # Calculate rates\n    accuracy = (tp + tn) / (tp + tn + fp + fn)\n    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n    \n    print(f\"\\nOVERALL PERFORMANCE METRICS:\")\n    print(f\"   Loss: {val_loss:.4f}\")\n    print(f\"   Dice Coefficient: {overall_dice:.4f}\")\n    print(f\"   IoU (Jaccard): {overall_iou:.4f}\")\n    print(f\"   F1-Score: {f1:.4f}\")\n    \n    print(f\"\\nCLASSIFICATION METRICS:\")\n    print(f\"   Accuracy: {accuracy:.4f}\")\n    print(f\"   Precision: {precision:.4f}\")\n    print(f\"   Recall (Sensitivity): {recall:.4f}\") \n    print(f\"   Specificity: {specificity:.4f}\")\n    \n    print(f\"\\nCONFUSION MATRIX (Pixel-wise):\")\n    print(f\"   True Negatives: {tn:,}\")\n    print(f\"   False Positives: {fp:,}\")\n    print(f\"   False Negatives: {fn:,}\")\n    print(f\"   True Positives: {tp:,}\")\n\n    return {\n        'loss': val_loss,\n        'dice': overall_dice,\n        'iou': overall_iou,\n        'f1_score': f1,\n        'precision': precision,\n        'recall': recall,\n        'specificity': specificity\n    }\n\n\nprint(\"PERFORMING COMPREHENSIVE EVALUATION...\")\n\n# Load best model with enhanced metrics\nprint(\"Loading best model with enhanced metrics...\")\nbest_model = tf.keras.models.load_model('best_multi_model.h5', \n    custom_objects={\n        'combined_loss': combined_loss,\n        'dice_coef': dice_coef,\n        'dice_loss': dice_loss,\n        'iou_coef': iou_coef,\n        'precision_metric': precision_metric,\n        'recall_metric': recall_metric,\n        'specificity_metric': specificity_metric,\n        'f1_score': f1_score\n    }\n)\n\n# Run comprehensive evaluation\nresults = comprehensive_evaluation(best_model, X_val, y_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T20:02:59.364961Z","iopub.execute_input":"2025-10-15T20:02:59.365279Z","iopub.status.idle":"2025-10-15T20:03:59.978363Z","shell.execute_reply.started":"2025-10-15T20:02:59.365258Z","shell.execute_reply":"2025-10-15T20:03:59.977525Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==================== SIMPLE SIDE-BY-SIDE VISUALIZATION ====================\n\ndef visualize_comparison(model, X_data, y_true, num_samples=3):\n    \"\"\"Simple side-by-side: MRI vs Ground Truth vs Prediction\"\"\"\n    \n    indices = np.random.choice(len(X_data), num_samples, replace=False)\n    \n    for i, idx in enumerate(indices):\n        # Get data\n        X_sample = X_data[idx]\n        y_true_sample = y_true[idx]\n        y_pred = model.predict(X_sample[np.newaxis, ...], verbose=0)[0]\n        y_pred_binary = (y_pred > 0.5).astype(np.float32)\n        \n        # Use FLAIR channel as background\n        background = X_sample[:, :, 0]\n        \n        # Create figure\n        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n        \n        # 1. Original MRI\n        axes[0].imshow(background, cmap='gray')\n        axes[0].set_title('Input MRI')\n        axes[0].axis('off')\n        \n        # 2. Ground Truth (combine all tumor regions)\n        axes[1].imshow(background, cmap='gray')\n        # Create binary mask of all tumor regions\n        gt_combined = np.any(y_true_sample > 0, axis=-1)\n        axes[1].imshow(gt_combined, cmap='Reds', alpha=0.5)\n        axes[1].set_title('Ground Truth')\n        axes[1].axis('off')\n        \n        # 3. Prediction (combine all tumor regions)\n        axes[2].imshow(background, cmap='gray')\n        pred_combined = np.any(y_pred_binary > 0, axis=-1)\n        axes[2].imshow(pred_combined, cmap='Reds', alpha=0.5)\n        \n        # Calculate Dice score\n        dice = dice_coef(\n            tf.convert_to_tensor(y_true_sample[np.newaxis, ...]),\n            tf.convert_to_tensor(y_pred[np.newaxis, ...])\n        ).numpy()\n        \n        axes[2].set_title(f'Prediction\\nDice: {dice:.3f}')\n        axes[2].axis('off')\n        \n        plt.suptitle(f'Sample {i+1}', fontsize=14, fontweight='bold')\n        plt.tight_layout()\n        plt.show()\n\n# Execute\nprint(\"Generating side-by-side visualizations...\")\nvisualize_comparison(best_model, X_val, y_val, num_samples=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T20:07:41.93253Z","iopub.execute_input":"2025-10-15T20:07:41.93305Z","iopub.status.idle":"2025-10-15T20:07:43.199693Z","shell.execute_reply.started":"2025-10-15T20:07:41.933029Z","shell.execute_reply":"2025-10-15T20:07:43.198831Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}