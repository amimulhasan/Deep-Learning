{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuIW9ZSJN3MoLJav38taWv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amimulhasan/Deep-Learning/blob/main/cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OQi4yV8vlDK4"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download bilalakgz/brain-tumor-mri-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N60aQydmlF_b",
        "outputId": "4c88fe39-4269-4fab-b97c-72ab9966aee6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/bilalakgz/brain-tumor-mri-dataset\n",
            "License(s): MIT\n",
            "Downloading brain-tumor-mri-dataset.zip to /content\n",
            "  0% 0.00/92.1M [00:00<?, ?B/s]\n",
            "100% 92.1M/92.1M [00:00<00:00, 1.26GB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/brain-tumor-mri-dataset.zip'\n",
        "extract_to = 'brain_tumor_data'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "print(\"Unzipping completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaFARSuHlGCT",
        "outputId": "080597aa-907b-46a8-c5c2-e59bc04ae7ad"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# A. Configuration Setup\n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        self.seed = 42\n",
        "        self.batch_size = 64\n",
        "        self.learning_rate = 0.001\n",
        "        self.num_epochs = 15\n",
        "        self.num_classes = 10\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.data_dir = '/content/brain_tumor_data'\n",
        "        self.log_dir = './logs'\n",
        "        self.model_save_path = './model.pth'\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# B. Set Random Seeds for Reproducibility\n",
        "torch.manual_seed(config.seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(config.seed)\n",
        "\n",
        "# C. Data Preparation\n",
        "def prepare_data():\n",
        "    # Define transformations\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    # Load datasets\n",
        "    train_dataset = datasets.MNIST(\n",
        "        root=config.data_dir,\n",
        "        train=True,\n",
        "        transform=transform,\n",
        "        download=True\n",
        "    )\n",
        "\n",
        "    test_dataset = datasets.MNIST(\n",
        "        root=config.data_dir,\n",
        "        train=False,\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    # Split train into train and validation\n",
        "    train_size = int(0.8 * len(train_dataset))\n",
        "    val_size = len(train_dataset) - train_size\n",
        "    train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(\n",
        "        dataset=train_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        dataset=val_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        dataset=test_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "# D. Model Architecture\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CNN, self).__init__()\n",
        "        # Feature extraction layers\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        # Classifier layers\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(64 * 7 * 7, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# E. Model Initialization\n",
        "def initialize_model():\n",
        "    model = CNN(num_classes=config.num_classes).to(config.device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)\n",
        "    return model, criterion, optimizer, scheduler\n",
        "\n",
        "# F. Training Function\n",
        "def train_model(model, criterion, optimizer, scheduler, train_loader, val_loader):\n",
        "    writer = SummaryWriter(config.log_dir)\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(config.num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{config.num_epochs}')\n",
        "        for inputs, labels in progress_bar:\n",
        "            inputs, labels = inputs.to(config.device), labels.to(config.device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            progress_bar.set_postfix({\n",
        "                'loss': train_loss/(total/config.batch_size),\n",
        "                'acc': 100.*correct/total\n",
        "            })\n",
        "\n",
        "        train_loss = train_loss/len(train_loader)\n",
        "        train_acc = 100.*correct/total\n",
        "\n",
        "        # Validation phase\n",
        "        val_loss, val_acc = evaluate_model(model, criterion, val_loader)\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Log metrics\n",
        "        writer.add_scalar('Loss/train', train_loss, epoch)\n",
        "        writer.add_scalar('Loss/val', val_loss, epoch)\n",
        "        writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
        "        writer.add_scalar('Accuracy/val', val_acc, epoch)\n",
        "\n",
        "        # Save best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), config.model_save_path)\n",
        "            print(f\"New best model saved with val_loss: {val_loss:.4f}\")\n",
        "\n",
        "        print(f'Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Acc: {train_acc:.2f}% | Val Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%')\n",
        "\n",
        "    writer.close()\n",
        "    return model\n",
        "\n",
        "# G. Evaluation Function\n",
        "def evaluate_model(model, criterion, data_loader):\n",
        "    model.eval()\n",
        "    loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs, labels = inputs.to(config.device), labels.to(config.device)\n",
        "            outputs = model(inputs)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    avg_loss = loss/len(data_loader)\n",
        "    accuracy = 100.*correct/total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "# H. Visualization Functions\n",
        "def plot_sample_images(loader):\n",
        "    dataiter = iter(loader)\n",
        "    images, labels = next(dataiter)\n",
        "\n",
        "    fig = plt.figure(figsize=(10, 4))\n",
        "    for idx in np.arange(10):\n",
        "        ax = fig.add_subplot(2, 5, idx+1, xticks=[], yticks=[])\n",
        "        img = images[idx].numpy().squeeze()\n",
        "        ax.imshow(img, cmap='gray')\n",
        "        ax.set_title(str(labels[idx].item()))\n",
        "    plt.show()\n",
        "\n",
        "def plot_metrics(log_dir):\n",
        "    # This would typically be done in TensorBoard\n",
        "    print(\"Run 'tensorboard --logdir={}' to view metrics\".format(log_dir))\n",
        "\n",
        "# I. Main Execution\n",
        "def main():\n",
        "    # Prepare data\n",
        "    train_loader, val_loader, test_loader = prepare_data()\n",
        "\n",
        "    # Visualize sample images\n",
        "    plot_sample_images(train_loader)\n",
        "\n",
        "    # Initialize model\n",
        "    model, criterion, optimizer, scheduler = initialize_model()\n",
        "\n",
        "    # Train model\n",
        "    print(\"Starting training...\")\n",
        "    model = train_model(model, criterion, optimizer, scheduler, train_loader, val_loader)\n",
        "\n",
        "    # Load best model\n",
        "    model.load_state_dict(torch.load(config.model_save_path))\n",
        "\n",
        "    # Final evaluation\n",
        "    print(\"Evaluating on test set...\")\n",
        "    test_loss, test_acc = evaluate_model(model, criterion, test_loader)\n",
        "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%')\n",
        "\n",
        "    # Visualize metrics\n",
        "    plot_metrics(config.log_dir)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Create directories if they don't exist\n",
        "    os.makedirs(config.data_dir, exist_ok=True)\n",
        "    os.makedirs(config.log_dir, exist_ok=True)\n",
        "\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WsEJGYYilGFH",
        "outputId": "a1bfac36-508f-4f0b-8696-4d139e8abcf5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.7MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 481kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.43MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.43MB/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/15: 100%|██████████| 750/750 [01:19<00:00,  9.38it/s, loss=0.165, acc=96.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best model saved with val_loss: 0.0529\n",
            "Epoch 1: Train Loss: 0.1655, Acc: 96.16% | Val Loss: 0.0529, Acc: 98.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/15: 100%|██████████| 750/750 [01:19<00:00,  9.43it/s, loss=0.0654, acc=98.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best model saved with val_loss: 0.0387\n",
            "Epoch 2: Train Loss: 0.0654, Acc: 98.21% | Val Loss: 0.0387, Acc: 98.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/15: 100%|██████████| 750/750 [01:19<00:00,  9.44it/s, loss=0.048, acc=98.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best model saved with val_loss: 0.0334\n",
            "Epoch 3: Train Loss: 0.0480, Acc: 98.54% | Val Loss: 0.0334, Acc: 98.92%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/15: 100%|██████████| 750/750 [01:19<00:00,  9.49it/s, loss=0.0379, acc=98.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best model saved with val_loss: 0.0319\n",
            "Epoch 4: Train Loss: 0.0379, Acc: 98.82% | Val Loss: 0.0319, Acc: 99.01%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/15: 100%|██████████| 750/750 [01:19<00:00,  9.49it/s, loss=0.0329, acc=99]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best model saved with val_loss: 0.0314\n",
            "Epoch 5: Train Loss: 0.0329, Acc: 99.00% | Val Loss: 0.0314, Acc: 99.05%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/15: 100%|██████████| 750/750 [01:18<00:00,  9.50it/s, loss=0.0278, acc=99.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best model saved with val_loss: 0.0293\n",
            "Epoch 6: Train Loss: 0.0278, Acc: 99.17% | Val Loss: 0.0293, Acc: 99.12%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/15:  83%|████████▎ | 619/750 [01:05<00:13,  9.39it/s, loss=0.0245, acc=99.2]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-5-2782867046.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-5-2782867046.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;31m# Load best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-5-2782867046.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, train_loader, val_loader)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-5-2782867046.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         return F.max_pool2d(\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cfgxweealGH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lrUFyHKflGLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_g6r3NvUlGOg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}