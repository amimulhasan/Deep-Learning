{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        (os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-01T05:58:51.734624Z","iopub.execute_input":"2026-01-01T05:58:51.735255Z","iopub.status.idle":"2026-01-01T05:58:52.339249Z","shell.execute_reply.started":"2026-01-01T05:58:51.735230Z","shell.execute_reply":"2026-01-01T05:58:52.338231Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"pip install torch torchvision albumentations opencv-python numpy scikit-learn tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T05:58:52.340797Z","iopub.execute_input":"2026-01-01T05:58:52.341221Z","iopub.status.idle":"2026-01-01T05:58:55.669730Z","shell.execute_reply.started":"2026-01-01T05:58:52.341192Z","shell.execute_reply":"2026-01-01T05:58:55.668820Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (2.0.8)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.2.6)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\nRequirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations) (1.15.3)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations) (6.0.3)\nRequirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations) (2.12.4)\nRequirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.11/dist-packages (from albumentations) (0.0.24)\nRequirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations) (4.12.0.88)\nRequirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations) (3.12.5)\nRequirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations) (6.5.0)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.3)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import os\nimport cv2\nimport torch\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.models import resnet50\nfrom sklearn.model_selection import train_test_split\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom tqdm import tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T05:58:55.670696Z","iopub.execute_input":"2026-01-01T05:58:55.670935Z","iopub.status.idle":"2026-01-01T05:58:55.675869Z","shell.execute_reply.started":"2026-01-01T05:58:55.670912Z","shell.execute_reply":"2026-01-01T05:58:55.675085Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"IMAGE_DIR = \"/kaggle/input/chest-x-ray-lungs-segmentation/Chest-X-Ray/Chest-X-Ray/image\"\nMASK_DIR  = \"/kaggle/input/chest-x-ray-lungs-segmentation/Chest-X-Ray/Chest-X-Ray/mask\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T05:58:55.677703Z","iopub.execute_input":"2026-01-01T05:58:55.677927Z","iopub.status.idle":"2026-01-01T05:58:55.690890Z","shell.execute_reply.started":"2026-01-01T05:58:55.677912Z","shell.execute_reply":"2026-01-01T05:58:55.690337Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"train_transform = A.Compose([\n    A.Resize(256, 256),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.Rotate(limit=20, p=0.5),\n    A.Normalize(mean=(0.5,), std=(0.5,)),\n    ToTensorV2()\n])\n\nval_test_transform = A.Compose([\n    A.Resize(256, 256),\n    A.Normalize(mean=(0.5,), std=(0.5,)),\n    ToTensorV2()\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T05:58:55.691649Z","iopub.execute_input":"2026-01-01T05:58:55.691850Z","iopub.status.idle":"2026-01-01T05:58:55.712317Z","shell.execute_reply.started":"2026-01-01T05:58:55.691826Z","shell.execute_reply":"2026-01-01T05:58:55.711737Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"class XRaySegmentationDataset(Dataset):\n    def __init__(self, image_paths, mask_paths, transform=None):\n        self.image_paths = image_paths\n        self.mask_paths = mask_paths\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        image = cv2.imread(self.image_paths[idx], cv2.IMREAD_GRAYSCALE)\n        mask  = cv2.imread(self.mask_paths[idx],  cv2.IMREAD_GRAYSCALE)\n\n        image = np.stack([image, image, image], axis=-1)  # âœ… FIX\n        image = image / 255.0\n        mask  = mask / 255.0\n\n        if self.transform:\n            augmented = self.transform(image=image, mask=mask)\n            image = augmented[\"image\"]\n            mask  = augmented[\"mask\"]\n\n        return image, mask.unsqueeze(0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T05:58:55.713078Z","iopub.execute_input":"2026-01-01T05:58:55.713313Z","iopub.status.idle":"2026-01-01T05:58:55.718826Z","shell.execute_reply.started":"2026-01-01T05:58:55.713291Z","shell.execute_reply":"2026-01-01T05:58:55.718299Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# class XRaySegmentationDataset(Dataset):\n#     def __init__(self, image_paths, mask_paths, transform=None):\n#         self.image_paths = image_paths\n#         self.mask_paths = mask_paths\n#         self.transform = transform\n\n#     def __len__(self):\n#         return len(self.image_paths)\n\n#     def __getitem__(self, idx):\n#         image = cv2.imread(self.image_paths[idx], cv2.IMREAD_GRAYSCALE)\n#         mask  = cv2.imread(self.mask_paths[idx],  cv2.IMREAD_GRAYSCALE)\n\n#         image = image / 255.0\n#         mask  = mask / 255.0\n\n#         if self.transform:\n#             augmented = self.transform(image=image, mask=mask)\n#             image = augmented[\"image\"]\n#             mask  = augmented[\"mask\"]\n\n#         return image, mask.unsqueeze(0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T05:58:55.719683Z","iopub.execute_input":"2026-01-01T05:58:55.719924Z","iopub.status.idle":"2026-01-01T05:58:55.733532Z","shell.execute_reply.started":"2026-01-01T05:58:55.719904Z","shell.execute_reply":"2026-01-01T05:58:55.732958Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"images = sorted([os.path.join(IMAGE_DIR, x) for x in os.listdir(IMAGE_DIR)])\nmasks  = sorted([os.path.join(MASK_DIR, x)  for x in os.listdir(MASK_DIR)])\n\nX_train, X_temp, y_train, y_temp = train_test_split(\n    images, masks, test_size=0.3, random_state=42\n)\n\nX_val, X_test, y_val, y_test = train_test_split(\n    X_temp, y_temp, test_size=0.5, random_state=42\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T05:58:55.734261Z","iopub.execute_input":"2026-01-01T05:58:55.734481Z","iopub.status.idle":"2026-01-01T05:58:55.753591Z","shell.execute_reply.started":"2026-01-01T05:58:55.734467Z","shell.execute_reply":"2026-01-01T05:58:55.753036Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"train_loader = DataLoader(\n    XRaySegmentationDataset(X_train, y_train, train_transform),\n    batch_size=4, shuffle=True\n)\n\nval_loader = DataLoader(\n    XRaySegmentationDataset(X_val, y_val, val_test_transform),\n    batch_size=4, shuffle=False\n)\n\ntest_loader = DataLoader(\n    XRaySegmentationDataset(X_test, y_test, val_test_transform),\n    batch_size=1, shuffle=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T05:58:55.754247Z","iopub.execute_input":"2026-01-01T05:58:55.754895Z","iopub.status.idle":"2026-01-01T05:58:55.760467Z","shell.execute_reply.started":"2026-01-01T05:58:55.754879Z","shell.execute_reply":"2026-01-01T05:58:55.759729Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"class AttentionBlock(nn.Module):\n    def __init__(self, F_g, F_l, F_int):\n        super().__init__()\n        self.W_g = nn.Conv2d(F_g, F_int, 1)\n        self.W_x = nn.Conv2d(F_l, F_int, 1)\n        self.psi = nn.Sequential(\n            nn.Conv2d(F_int, 1, 1),\n            nn.Sigmoid()\n        )\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, g, x):\n        psi = self.relu(self.W_g(g) + self.W_x(x))\n        psi = self.psi(psi)\n        return x * psi\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T05:58:55.762275Z","iopub.execute_input":"2026-01-01T05:58:55.762483Z","iopub.status.idle":"2026-01-01T05:58:55.774309Z","shell.execute_reply.started":"2026-01-01T05:58:55.762468Z","shell.execute_reply":"2026-01-01T05:58:55.773587Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"class ResNet50_Attention_UNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        resnet = resnet50(pretrained=True)\n\n        self.e1 = nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu)\n        self.e2 = resnet.layer1\n        self.e3 = resnet.layer2\n        self.e4 = resnet.layer3\n        self.e5 = resnet.layer4\n\n        self.up4 = nn.ConvTranspose2d(2048, 1024, 2, 2)\n        self.att4 = AttentionBlock(1024, 1024, 512)\n        self.d4 = nn.Conv2d(2048, 1024, 3, padding=1)\n\n        self.up3 = nn.ConvTranspose2d(1024, 512, 2, 2)\n        self.att3 = AttentionBlock(512, 512, 256)\n        self.d3 = nn.Conv2d(1024, 512, 3, padding=1)\n\n        self.up2 = nn.ConvTranspose2d(512, 256, 2, 2)\n        self.att2 = AttentionBlock(256, 256, 128)\n        self.d2 = nn.Conv2d(512, 256, 3, padding=1)\n\n        self.up1 = nn.ConvTranspose2d(256, 64, 2, 2)\n        self.d1 = nn.Conv2d(128, 64, 3, padding=1)\n\n        self.out = nn.Conv2d(64, 1, 1)\n\n    def forward(self, x):\n        e1 = self.e1(x)\n        e2 = self.e2(e1)\n        e3 = self.e3(e2)\n        e4 = self.e4(e3)\n        e5 = self.e5(e4)\n\n        d4 = self.up4(e5)\n        e4 = self.att4(d4, e4)\n        d4 = self.d4(torch.cat([d4, e4], 1))\n\n        d3 = self.up3(d4)\n        e3 = self.att3(d3, e3)\n        d3 = self.d3(torch.cat([d3, e3], 1))\n\n        d2 = self.up2(d3)\n        e2 = self.att2(d2, e2)\n        d2 = self.d2(torch.cat([d2, e2], 1))\n\n        d1 = self.up1(d2)\n        d1 = self.d1(torch.cat([d1, e1], 1))\n\n        return torch.sigmoid(self.out(d1))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T05:58:55.774899Z","iopub.execute_input":"2026-01-01T05:58:55.775115Z","iopub.status.idle":"2026-01-01T05:58:55.785766Z","shell.execute_reply.started":"2026-01-01T05:58:55.775092Z","shell.execute_reply":"2026-01-01T05:58:55.785048Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def dice_score(pred, target):\n    smooth = 1e-6\n    pred = pred.view(-1)\n    target = target.view(-1)\n    return (2*(pred*target).sum()+smooth)/((pred+target).sum()+smooth)\n\ndef iou_score(pred, target):\n    smooth = 1e-6\n    pred = pred.view(-1)\n    target = target.view(-1)\n    inter = (pred * target).sum()\n    union = pred.sum() + target.sum() - inter\n    return (inter + smooth) / (union + smooth)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T05:58:55.786701Z","iopub.execute_input":"2026-01-01T05:58:55.787438Z","iopub.status.idle":"2026-01-01T05:58:55.801577Z","shell.execute_reply.started":"2026-01-01T05:58:55.787415Z","shell.execute_reply":"2026-01-01T05:58:55.800958Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nmodel = ResNet50_Attention_UNet().to(device)\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\n\nEPOCHS = 20\n\nfor epoch in range(EPOCHS):\n    model.train()\n    train_loss = 0\n\n    for img, mask in tqdm(train_loader):\n        img, mask = img.to(device), mask.to(device)\n\n        pred = model(img)\n        loss = criterion(pred, mask)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    print(f\"Epoch [{epoch+1}/{EPOCHS}] Train Loss: {train_loss/len(train_loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T05:58:55.802215Z","iopub.execute_input":"2026-01-01T05:58:55.802443Z","iopub.status.idle":"2026-01-01T05:58:58.381566Z","shell.execute_reply.started":"2026-01-01T05:58:55.802429Z","shell.execute_reply":"2026-01-01T05:58:58.380703Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 0/123 [00:01<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/597825457.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/302064884.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 256 but got size 128 for tensor number 1 in the list."],"ename":"RuntimeError","evalue":"Sizes of tensors must match except in dimension 1. Expected size 256 but got size 128 for tensor number 1 in the list.","output_type":"error"}],"execution_count":25},{"cell_type":"code","source":"model.eval()\ndice, iou = 0, 0\n\nwith torch.no_grad():\n    for img, mask in test_loader:\n        img, mask = img.to(device), mask.to(device)\n        pred = model(img)\n\n        dice += dice_score(pred, mask).item()\n        iou  += iou_score(pred, mask).item()\n\nprint(f\"Final Dice Score: {dice/len(test_loader):.4f}\")\nprint(f\"Final IoU Score : {iou/len(test_loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T05:58:58.382048Z","iopub.status.idle":"2026-01-01T05:58:58.382280Z","shell.execute_reply.started":"2026-01-01T05:58:58.382172Z","shell.execute_reply":"2026-01-01T05:58:58.382182Z"}},"outputs":[],"execution_count":null}]}