{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        (os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T19:26:22.393892Z","iopub.execute_input":"2025-12-13T19:26:22.394729Z","iopub.status.idle":"2025-12-13T19:26:22.870478Z","shell.execute_reply.started":"2025-12-13T19:26:22.394702Z","shell.execute_reply":"2025-12-13T19:26:22.869872Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"!pip install --quiet timm==0.9.2 albumentations==1.4.3 scikit-image scikit-learn\n!pip install --quiet git+https://github.com/facebookresearch/segment-anything.git\n\nimport os, time, random\nfrom pathlib import Path\nfrom glob import glob\nfrom typing import List\n\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nimport timm\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nfrom segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n\n# reproducibility\nSEED = 42\nrandom.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\nif torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T19:26:22.871735Z","iopub.execute_input":"2025-12-13T19:26:22.872027Z","iopub.status.idle":"2025-12-13T19:26:33.272442Z","shell.execute_reply.started":"2025-12-13T19:26:22.872008Z","shell.execute_reply":"2025-12-13T19:26:33.271536Z"}},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"CONFIG = {\n    'DATA_DIR': '/kaggle/input/brain-tumor-for-segmentation/Brain tumor segmentation',  # your dataset\n    'IMG_EXTS': ('.png','.jpg','.jpeg'),\n    'IMG_SIZE': 224,\n    'NUM_CLASSES': 2,\n    'BATCH_SIZE': 8,\n    'EPOCHS': 10,\n    'LR': 1e-4,\n    'DEVICE': 'cuda' if torch.cuda.is_available() else 'cpu',\n    'CHECKPOINT_DIR': '/kaggle/working/checkpoints',\n    'GENERATED_MASKS_DIR': '/kaggle/working/masks_auto',\n    'SAM_CHECKPOINT': '/kaggle/input/sam-vit/sam_vit_b_01ec64.pth',  # set this path\n    'NUM_WORKERS': 0,\n}\nos.makedirs(CONFIG['CHECKPOINT_DIR'], exist_ok=True)\nos.makedirs(CONFIG['GENERATED_MASKS_DIR'], exist_ok=True)\n\nprint(\"Device:\", CONFIG['DEVICE'])\nprint(\"Images root:\", CONFIG['DATA_DIR'])\nprint(\"Masks will be saved to:\", CONFIG['GENERATED_MASKS_DIR'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T19:26:33.273662Z","iopub.execute_input":"2025-12-13T19:26:33.274009Z","iopub.status.idle":"2025-12-13T19:26:33.281157Z","shell.execute_reply.started":"2025-12-13T19:26:33.273982Z","shell.execute_reply":"2025-12-13T19:26:33.280093Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\nImages root: /kaggle/input/brain-tumor-for-segmentation/Brain tumor segmentation\nMasks will be saved to: /kaggle/working/masks_auto\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"DEVICE = CONFIG['DEVICE']\n\nsam = sam_model_registry[\"vit_b\"](checkpoint=CONFIG['SAM_CHECKPOINT'])\nsam.to(DEVICE)\n\nmask_generator = SamAutomaticMaskGenerator(\n    sam,\n    points_per_side=32,\n    pred_iou_thresh=0.88,\n    stability_score_thresh=0.92\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T19:26:33.282912Z","iopub.execute_input":"2025-12-13T19:26:33.283162Z","iopub.status.idle":"2025-12-13T19:26:37.900937Z","shell.execute_reply.started":"2025-12-13T19:26:33.283142Z","shell.execute_reply":"2025-12-13T19:26:37.900028Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def collect_images(root_dir: str, exts=('.png','.jpg','.jpeg')) -> List[str]:\n    files = []\n    p = Path(root_dir)\n    for ext in exts:\n        files += [str(x) for x in p.rglob(f'*{ext}')]\n    return sorted(files)\n\ndef read_image(path: str, size:int=224):\n    img = cv2.imread(path)\n    if img is None:\n        raise FileNotFoundError(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (size, size))\n    return img\n\ndef generate_sam_mask(img_path: str):\n    img = read_image(img_path, CONFIG['IMG_SIZE'])\n    masks = mask_generator.generate(img)\n    # combine all masks into one binary mask\n    final_mask = np.zeros((img.shape[0], img.shape[1]), dtype=np.uint8)\n    for m in masks:\n        final_mask = np.maximum(final_mask, m['segmentation'].astype(np.uint8))\n    final_mask = cv2.resize(final_mask, (CONFIG['IMG_SIZE'], CONFIG['IMG_SIZE']), interpolation=cv2.INTER_NEAREST)\n    return final_mask\n\n# Generate and save pseudo-masks\nimages = collect_images(CONFIG['DATA_DIR'], CONFIG['IMG_EXTS'])\nfor i, p in enumerate(images):\n    fname = os.path.basename(p)\n    out_mask = os.path.join(CONFIG['GENERATED_MASKS_DIR'], fname)\n    if os.path.exists(out_mask): continue\n    mask = generate_sam_mask(p)\n    cv2.imwrite(out_mask, (mask*255).astype('uint8'))\nprint(\"SAM pseudo-mask generation done\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T19:26:37.901919Z","iopub.execute_input":"2025-12-13T19:26:37.902507Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class BrainSegDataset(Dataset):\n    def __init__(self, image_paths: List[str], mask_dir: str, img_size:int=224, transform=None):\n        self.image_paths = image_paths\n        self.mask_dir = mask_dir\n        self.img_size = img_size\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        p = self.image_paths[idx]\n        fname = os.path.basename(p)\n        img = read_image(p, self.img_size)\n        mask = cv2.imread(os.path.join(self.mask_dir, fname), cv2.IMREAD_GRAYSCALE)\n        if mask is None:\n            mask = np.zeros((self.img_size, self.img_size), dtype=np.uint8)\n        else:\n            mask = cv2.resize(mask, (self.img_size, self.img_size), interpolation=cv2.INTER_NEAREST)\n            mask = (mask>127).astype(np.uint8)\n        if self.transform:\n            augmented = self.transform(image=img, mask=mask)\n            return augmented['image'], augmented['mask']\n        else:\n            img_t = torch.from_numpy(img.transpose(2,0,1)).float()/255.0\n            mask_t = torch.from_numpy(mask).long()\n            return img_t, mask_t\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_tf = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=10, p=0.5),\n    A.RandomBrightnessContrast(p=0.5),\n    A.Normalize(),\n    ToTensorV2()\n])\nval_tf = A.Compose([A.Normalize(), ToTensorV2()])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"n = len(images)\nidxs = np.arange(n); np.random.seed(SEED); np.random.shuffle(idxs)\nsplit = int(0.8*n)\ntrain_imgs = [images[i] for i in idxs[:split]]\nval_imgs   = [images[i] for i in idxs[split:]]\n\ntrain_ds = BrainSegDataset(train_imgs, CONFIG['GENERATED_MASKS_DIR'], img_size=CONFIG['IMG_SIZE'], transform=train_tf)\nval_ds   = BrainSegDataset(val_imgs, CONFIG['GENERATED_MASKS_DIR'], img_size=CONFIG['IMG_SIZE'], transform=val_tf)\n\ntrain_loader = DataLoader(train_ds, batch_size=CONFIG['BATCH_SIZE'], shuffle=True, num_workers=CONFIG['NUM_WORKERS'], pin_memory=True)\nval_loader   = DataLoader(val_ds, batch_size=CONFIG['BATCH_SIZE'], shuffle=False, num_workers=CONFIG['NUM_WORKERS'], pin_memory=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SwinUNet(nn.Module):\n    def __init__(self, num_classes=2, img_size=224):\n        super().__init__()\n        self.encoder = timm.create_model('swin_base_patch4_window7_224', pretrained=True, features_only=True)\n        self.encoder_out_channels = self.encoder.feature_info.channels()\n        # Decoder\n        self.up4 = nn.ConvTranspose2d(self.encoder_out_channels[-1], 512, kernel_size=2, stride=2)\n        self.conv4 = nn.Conv2d(512+512, 512, 3, padding=1)\n        self.up3 = nn.ConvTranspose2d(512, 256, 2,2)\n        self.conv3 = nn.Conv2d(256+256, 256, 3,1,1)\n        self.up2 = nn.ConvTranspose2d(256,128,2,2)\n        self.conv2 = nn.Conv2d(128+128,128,3,1,1)\n        self.up1 = nn.ConvTranspose2d(128,64,2,2)\n        self.conv1 = nn.Conv2d(64+64,64,3,1,1)\n        self.head = nn.Conv2d(64,num_classes,1)\n\n    def forward(self,x):\n        feats = self.encoder(x)\n        e1,e2,e3,e4 = feats\n        d4 = self.up4(e4)\n        d4 = torch.cat([d4,e3],dim=1)\n        d4 = self.conv4(d4)\n        d3 = self.up3(d4)\n        d3 = torch.cat([d3,e2],dim=1)\n        d3 = self.conv3(d3)\n        d2 = self.up2(d3)\n        d2 = torch.cat([d2,e1],dim=1)\n        d2 = self.conv2(d2)\n        d1 = self.up1(d2)\n        d1 = self.conv1(d1)\n        out = self.head(d1)\n        return out\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def dice_loss_logits(logits, target, eps=1e-6):\n    prob = torch.sigmoid(logits)\n    target = target.unsqueeze(1).float()\n    inter = (prob * target).sum(dim=(2,3))\n    denom = prob.sum(dim=(2,3)) + target.sum(dim=(2,3))\n    dice = (2*inter + eps)/(denom+eps)\n    return 1 - dice.mean()\n\ndef iou_score(logits, target):\n    preds = (torch.sigmoid(logits).squeeze(1) > 0.5).long()\n    inter = (preds & target).sum().float()\n    union = (preds | target).sum().float()\n    return (inter/union) if union>0 else torch.tensor(1.0)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = CONFIG['DEVICE']\nmodel = SwinUNet(num_classes=CONFIG['NUM_CLASSES'], img_size=CONFIG['IMG_SIZE']).to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG['LR'])\nscaler = torch.cuda.amp.GradScaler() if device.startswith('cuda') else None\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_one_epoch():\n    model.train(); total_loss=0\n    for imgs, masks in train_loader:\n        imgs = imgs.to(device); masks = masks.to(device)\n        optimizer.zero_grad()\n        if scaler:\n            with torch.cuda.amp.autocast():\n                logits = model(imgs)\n                bce = F.binary_cross_entropy_with_logits(logits.squeeze(1), masks.float())\n                loss = bce + dice_loss_logits(logits, masks)\n            scaler.scale(loss).backward()\n            scaler.step(optimizer); scaler.update()\n        else:\n            logits = model(imgs)\n            loss = F.binary_cross_entropy_with_logits(logits.squeeze(1), masks.float()) + dice_loss_logits(logits, masks)\n            loss.backward(); optimizer.step()\n        total_loss += loss.item()*imgs.size(0)\n    return total_loss / len(train_loader.dataset)\n\ndef validate_epoch():\n    model.eval(); total_loss=0; total_iou=0\n    with torch.no_grad():\n        for imgs, masks in val_loader:\n            imgs = imgs.to(device); masks = masks.to(device)\n            logits = model(imgs)\n            loss = F.binary_cross_entropy_with_logits(logits.squeeze(1), masks.float()) + dice_loss_logits(logits, masks)\n            total_loss += loss.item()*imgs.size(0)\n            total_iou += iou_score(logits, masks).item()*imgs.size(0)\n    return total_loss/len(val_loader.dataset), total_iou/len(val_loader.dataset)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_iou=0.0\nfor epoch in range(1, CONFIG['EPOCHS']+1):\n    t0 = time.time()\n    train_loss = train_one_epoch()\n    val_loss, val_iou = validate_epoch()\n    t1 = time.time()\n    print(f\"Epoch {epoch}/{CONFIG['EPOCHS']} | {t1-t0:.1f}s | train_loss {train_loss:.4f} | val_loss {val_loss:.4f} | val_iou {val_iou:.4f}\")\n    ckpt = {'epoch':epoch,'model_state':model.state_dict(),'optim_state':optimizer.state_dict(),'val_iou':val_iou}\n    torch.save(ckpt, os.path.join(CONFIG['CHECKPOINT_DIR'], f'epoch_{epoch}.pth'))\n    if val_iou>best_iou:\n        best_iou=val_iou\n        torch.save(ckpt, os.path.join(CONFIG['CHECKPOINT_DIR'],'best.pth'))\nprint(\"Training finished. Best val IoU:\", best_iou)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_mask(model, img_path):\n    model.eval()\n    img = read_image(img_path, CONFIG['IMG_SIZE'])\n    inp = torch.from_numpy(img.transpose(2,0,1)).float().unsqueeze(0).to(device)/255.0\n    with torch.no_grad():\n        logits = model(inp)\n        pred = (torch.sigmoid(logits).squeeze(1).cpu().numpy()[0]>0.5).astype('uint8')\n    return img, pred\n\n# visualize\nfor i in range(min(6,len(val_imgs))):\n    p = val_imgs[i]\n    img, pred = predict_mask(model, p)\n    gt = cv2.imread(os.path.join(CONFIG['GENERATED_MASKS_DIR'], os.path.basename(p)), cv2.IMREAD_GRAYSCALE)\n    if gt is None: gt=np.zeros_like(pred)\n    else: gt=(gt>127).astype('uint8')\n    plt.figure(figsize=(10,3))\n    plt.subplot(1,3,1); plt.imshow(img); plt.title('Image'); plt.axis('off')\n    plt.subplot(1,3,2); plt.imshow(pred); plt.title('Predicted Mask'); plt.axis('off')\n    plt.subplot(1,3,3); plt.imshow(gt); plt.title('SAM Pseudo Mask'); plt.axis('off')\n    plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}