{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 13726419,
          "sourceType": "datasetVersion",
          "datasetId": 8733039
        },
        {
          "sourceId": 13726845,
          "sourceType": "datasetVersion",
          "datasetId": 8733328
        },
        {
          "sourceId": 13727057,
          "sourceType": "datasetVersion",
          "datasetId": 8733467
        },
        {
          "sourceId": 13727329,
          "sourceType": "datasetVersion",
          "datasetId": 8733622
        }
      ],
      "dockerImageVersionId": 31154,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amimulhasan/Deep-Learning/blob/main/multi_disease_cnn_vit_gru.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "Q5DQ0JgkuYV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# ------------------------\n",
        "# SETTINGS\n",
        "# ------------------------\n",
        "dataset_dir = \"/kaggle/input/alz-b-1100/alzheimer_new_11/alzheimer_new\"  # Update path as needed\n",
        "img_size = (128,128)\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "# --- Get all class folders (e.g., 4 classes) ---\n",
        "class_names = sorted([d for d in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, d))])\n",
        "print(\"âœ… Classes found:\", class_names)\n",
        "\n",
        "if len(class_names) != 8:\n",
        "    raise ValueError(f\"Expected exactly 4 classes, found {len(class_names)}: {class_names}\")\n",
        "\n",
        "# --- Walk through each class and collect images ---\n",
        "for idx, class_name in enumerate(class_names):\n",
        "    class_path = os.path.join(dataset_dir, class_name)\n",
        "    print(f\"ğŸ” Processing class '{class_name}' ({idx})\")\n",
        "\n",
        "    for root, _, files in os.walk(class_path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            try:\n",
        "                img = Image.open(file_path).convert('RGB')\n",
        "                img = img.resize(img_size)\n",
        "                img_array = np.array(img) / 255.0  # Normalize\n",
        "                X.append(img_array)\n",
        "                y.append(idx)\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ Failed to process {file_path}: {e}\")\n",
        "\n",
        "# ------------------------\n",
        "# CONVERT TO NUMPY ARRAYS\n",
        "# ------------------------\n",
        "X = np.array(X, dtype=np.float32)\n",
        "y = np.array(y, dtype=np.int32)\n",
        "\n",
        "print(f\"\\nâœ… Dataset loaded successfully:\")\n",
        "print(f\"   X shape = {X.shape}\")\n",
        "print(f\"   y shape = {y.shape}\")\n",
        "print(f\"   Class mapping = {dict(enumerate(class_names))}\")\n",
        "\n",
        "# ------------------------\n",
        "# SAVE AS .NPY FILES\n",
        "# ------------------------\n",
        "np.save(\"X.npy\", X)\n",
        "np.save(\"y.npy\", y)\n",
        "print(\"âœ… Saved X.npy and y.npy to current working directory.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T17:11:39.325152Z",
          "iopub.execute_input": "2025-11-20T17:11:39.325490Z",
          "iopub.status.idle": "2025-11-20T17:13:06.086684Z",
          "shell.execute_reply.started": "2025-11-20T17:11:39.325464Z",
          "shell.execute_reply": "2025-11-20T17:13:06.086007Z"
        },
        "id": "_8Xp4p6ZuYV6",
        "outputId": "abf2192c-7ba4-4a09-fb99-381f715bc4b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "âœ… Classes found: ['MildDemented', 'Moderate Dementia', 'NonDemented', 'Very mild Dementia', 'glioma', 'meningioma', 'notumor', 'pituitary']\nğŸ” Processing class 'MildDemented' (0)\nğŸ” Processing class 'Moderate Dementia' (1)\nğŸ” Processing class 'NonDemented' (2)\nğŸ” Processing class 'Very mild Dementia' (3)\nğŸ” Processing class 'glioma' (4)\nğŸ” Processing class 'meningioma' (5)\nğŸ” Processing class 'notumor' (6)\nğŸ” Processing class 'pituitary' (7)\n\nâœ… Dataset loaded successfully:\n   X shape = (8800, 128, 128, 3)\n   y shape = (8800,)\n   Class mapping = {0: 'MildDemented', 1: 'Moderate Dementia', 2: 'NonDemented', 3: 'Very mild Dementia', 4: 'glioma', 5: 'meningioma', 6: 'notumor', 7: 'pituitary'}\nâœ… Saved X.npy and y.npy to current working directory.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from PIL import Image"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T17:13:06.087413Z",
          "iopub.execute_input": "2025-11-20T17:13:06.087710Z",
          "iopub.status.idle": "2025-11-20T17:13:21.991589Z",
          "shell.execute_reply.started": "2025-11-20T17:13:06.087690Z",
          "shell.execute_reply": "2025-11-20T17:13:21.990998Z"
        },
        "id": "gg3ezq-3uYV9",
        "outputId": "10b6c345-21ee-458b-9fa9-b919ddff08c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "2025-11-20 17:13:07.419349: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763658787.594664      39 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763658787.647354      39 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.load(\"/kaggle/working/X.npy\")\n",
        "y = np.load(\"/kaggle/working/y.npy\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T17:13:21.993490Z",
          "iopub.execute_input": "2025-11-20T17:13:21.994111Z",
          "iopub.status.idle": "2025-11-20T17:13:22.423024Z",
          "shell.execute_reply.started": "2025-11-20T17:13:21.994091Z",
          "shell.execute_reply": "2025-11-20T17:13:22.422201Z"
        },
        "id": "c_c26miYuYV9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming X and y are already loaded from your .npy files\n",
        "# X = np.load(\"/path/to/X.npy\")\n",
        "# y = np.load(\"/path/to/y.npy\")\n",
        "\n",
        "# Define the class labels (0 - Glioma, 1 - Meningioma, 2 - Pituitary, 3 - No Tumor)\n",
        "classes = ['Glioma', 'Meningioma', 'Pituitary', 'No Tumor']\n",
        "\n",
        "# Initialize a dictionary to hold the train-test data for each class\n",
        "class_data = {}\n",
        "\n",
        "# Split the data for each class\n",
        "for cls in range(4):  # Assuming 0 -> Glioma, 1 -> Meningioma, 2 -> Pituitary, 3 -> No Tumor\n",
        "    # Get the indices for each class\n",
        "    class_indices = np.where(y == cls)[0]\n",
        "    class_X = X[class_indices]  # Features for this class\n",
        "    class_y = y[class_indices]  # Labels for this class\n",
        "\n",
        "    # Split into train and test for each class\n",
        "    X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n",
        "        class_X, class_y, test_size=0.2, random_state=42, stratify=class_y)\n",
        "\n",
        "    # Store the train-test split for this class\n",
        "    class_data[classes[cls]] = {\n",
        "        'X_train': X_train_class,\n",
        "        'y_train': y_train_class,\n",
        "        'X_test': X_test_class,\n",
        "        'y_test': y_test_class\n",
        "    }\n",
        "\n",
        "# Example: Print the shape of training and test sets for Glioma\n",
        "print(\"Glioma Train Features:\", class_data['Glioma']['X_train'].shape)\n",
        "print(\"Glioma Test Features:\", class_data['Glioma']['X_test'].shape)\n",
        "print(\"Meningioma Train Features:\", class_data['Meningioma']['X_train'].shape)\n",
        "print(\"Meningioma Test Features:\", class_data['Meningioma']['X_test'].shape)\n",
        "print(\"Pituitary Train Features:\", class_data['Pituitary']['X_train'].shape)\n",
        "print(\"Pituitary Test Features:\", class_data['Pituitary']['X_test'].shape)\n",
        "print(\"No Tumor Train Features:\", class_data['No Tumor']['X_train'].shape)\n",
        "print(\"No Tumor Test Features:\", class_data['No Tumor']['X_test'].shape)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T17:13:22.423837Z",
          "iopub.execute_input": "2025-11-20T17:13:22.424063Z",
          "iopub.status.idle": "2025-11-20T17:13:24.616561Z",
          "shell.execute_reply.started": "2025-11-20T17:13:22.424037Z",
          "shell.execute_reply": "2025-11-20T17:13:24.615805Z"
        },
        "id": "mekaxOPruYV9",
        "outputId": "dd1c37c4-9a3c-4e73-c834-b6fb79210a66"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Glioma Train Features: (880, 128, 128, 3)\nGlioma Test Features: (220, 128, 128, 3)\nMeningioma Train Features: (880, 128, 128, 3)\nMeningioma Test Features: (220, 128, 128, 3)\nPituitary Train Features: (880, 128, 128, 3)\nPituitary Test Features: (220, 128, 128, 3)\nNo Tumor Train Features: (880, 128, 128, 3)\nNo Tumor Test Features: (220, 128, 128, 3)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset shapes:\", X.shape, y.shape)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T17:13:24.617321Z",
          "iopub.execute_input": "2025-11-20T17:13:24.617522Z",
          "iopub.status.idle": "2025-11-20T17:13:24.621721Z",
          "shell.execute_reply.started": "2025-11-20T17:13:24.617505Z",
          "shell.execute_reply": "2025-11-20T17:13:24.621052Z"
        },
        "id": "5-SgiIlpuYV-",
        "outputId": "7c0dc1e5-201d-4036-d593-3b61580e3a30"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Dataset shapes: (8800, 128, 128, 3) (8800,)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Train: {X_train.shape}, Val: {X_val.shape}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T17:13:24.622350Z",
          "iopub.execute_input": "2025-11-20T17:13:24.622616Z",
          "iopub.status.idle": "2025-11-20T17:13:25.118817Z",
          "shell.execute_reply.started": "2025-11-20T17:13:24.622595Z",
          "shell.execute_reply": "2025-11-20T17:13:25.118158Z"
        },
        "id": "v8oJ4y75uYV_",
        "outputId": "cb8c7693-b0ff-4ae7-b5a0-53a1cd6caf86"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Train: (7040, 128, 128, 3), Val: (1760, 128, 128, 3)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models, layers"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T17:13:25.119462Z",
          "iopub.execute_input": "2025-11-20T17:13:25.119743Z",
          "iopub.status.idle": "2025-11-20T17:13:25.123408Z",
          "shell.execute_reply.started": "2025-11-20T17:13:25.119719Z",
          "shell.execute_reply": "2025-11-20T17:13:25.122740Z"
        },
        "id": "FkhH4Lp4uYV_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# -----------------------\n",
        "# Hyperparameters\n",
        "# -----------------------\n",
        "input_shape = (128, 128, 3)\n",
        "patch_size = 16\n",
        "num_patches = (input_shape[0] // patch_size) * (input_shape[1] // patch_size)\n",
        "projection_dim = 64\n",
        "transformer_layers = 4\n",
        "num_heads = 8\n",
        "num_classes = 8\n",
        "\n",
        "# -----------------------\n",
        "# Patches layer\n",
        "# -----------------------\n",
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches\n",
        "\n",
        "# -----------------------\n",
        "# Patch Encoder layer\n",
        "# -----------------------\n",
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patches):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patches) + self.position_embedding(positions)\n",
        "        return encoded\n",
        "\n",
        "# -----------------------\n",
        "# Build the combined model\n",
        "# -----------------------\n",
        "def build_hybrid_model():\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # ---------------------\n",
        "    # DCNN Branch\n",
        "    # ---------------------\n",
        "    x_cnn = layers.Conv2D(32, (3,3), activation='relu', padding='same')(inputs)\n",
        "    x_cnn = layers.MaxPooling2D((2,2))(x_cnn)\n",
        "    x_cnn = layers.Conv2D(64, (3,3), activation='relu', padding='same')(x_cnn)\n",
        "    x_cnn = layers.MaxPooling2D((2,2))(x_cnn)\n",
        "    x_cnn = layers.Conv2D(128, (3,3), activation='relu', padding='same')(x_cnn)\n",
        "    x_cnn = layers.MaxPooling2D((2,2))(x_cnn)\n",
        "    x_cnn = layers.Flatten()(x_cnn)\n",
        "\n",
        "    # ---------------------\n",
        "    # ViT + GRU Branch\n",
        "    # ---------------------\n",
        "    x_vit = layers.Rescaling(1./255)(inputs)\n",
        "    patches = Patches(patch_size)(x_vit)\n",
        "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "\n",
        "    for _ in range(transformer_layers):\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.2\n",
        "        )(x1, x1)\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    x_vit = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    x_vit = layers.Dropout(0.002)(x_vit)\n",
        "    x_vit = layers.Flatten()(x_vit)\n",
        "    x_vit = layers.Reshape((-1, x_vit.shape[-1]))(x_vit)\n",
        "    x_vit = layers.GRU(256)(x_vit)\n",
        "\n",
        "    # ---------------------\n",
        "    # Concatenate DCNN and ViT+GRU\n",
        "    # ---------------------\n",
        "    x = layers.concatenate([x_cnn, x_vit])\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.Dropout(0.003)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    # Build model\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# -----------------------\n",
        "# Compile and summary\n",
        "# -----------------------\n",
        "model = build_hybrid_model()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T17:13:25.124136Z",
          "iopub.execute_input": "2025-11-20T17:13:25.124407Z",
          "iopub.status.idle": "2025-11-20T17:13:27.391748Z",
          "shell.execute_reply.started": "2025-11-20T17:13:25.124385Z",
          "shell.execute_reply": "2025-11-20T17:13:27.391167Z"
        },
        "id": "Nust1P6YuYWA",
        "outputId": "a2343f11-e411-4628-8410-39add80b2c92"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "I0000 00:00:1763658805.835492      39 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ input_layer         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\nâ”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ \u001b[38;5;34m3\u001b[0m)                â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ rescaling           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\nâ”‚ (\u001b[38;5;33mRescaling\u001b[0m)         â”‚ \u001b[38;5;34m3\u001b[0m)                â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ patches (\u001b[38;5;33mPatches\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ rescaling[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ patch_encoder       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚     \u001b[38;5;34m53,312\u001b[0m â”‚ patches[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\nâ”‚ (\u001b[38;5;33mPatchEncoder\u001b[0m)      â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ layer_normalization â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚        \u001b[38;5;34m128\u001b[0m â”‚ patch_encoder[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\nâ”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ multi_head_attentiâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚    \u001b[38;5;34m132,672\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mMultiHeadAttentioâ€¦\u001b[0m â”‚                   â”‚            â”‚ layer_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ add (\u001b[38;5;33mAdd\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multi_head_attenâ€¦ â”‚\nâ”‚                     â”‚                   â”‚            â”‚ patch_encoder[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚        \u001b[38;5;34m128\u001b[0m â”‚ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\nâ”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ add_1 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\nâ”‚                     â”‚                   â”‚            â”‚ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚        \u001b[38;5;34m128\u001b[0m â”‚ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\nâ”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ multi_head_attentiâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚    \u001b[38;5;34m132,672\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mMultiHeadAttentioâ€¦\u001b[0m â”‚                   â”‚            â”‚ layer_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ add_2 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multi_head_attenâ€¦ â”‚\nâ”‚                     â”‚                   â”‚            â”‚ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚        \u001b[38;5;34m128\u001b[0m â”‚ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\nâ”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ add_3 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\nâ”‚                     â”‚                   â”‚            â”‚ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚        \u001b[38;5;34m128\u001b[0m â”‚ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\nâ”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ multi_head_attentiâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚    \u001b[38;5;34m132,672\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mMultiHeadAttentioâ€¦\u001b[0m â”‚                   â”‚            â”‚ layer_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ add_4 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multi_head_attenâ€¦ â”‚\nâ”‚                     â”‚                   â”‚            â”‚ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚        \u001b[38;5;34m128\u001b[0m â”‚ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\nâ”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ add_5 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\nâ”‚                     â”‚                   â”‚            â”‚ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚        \u001b[38;5;34m128\u001b[0m â”‚ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\nâ”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ multi_head_attentiâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚    \u001b[38;5;34m132,672\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mMultiHeadAttentioâ€¦\u001b[0m â”‚                   â”‚            â”‚ layer_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ add_6 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multi_head_attenâ€¦ â”‚\nâ”‚                     â”‚                   â”‚            â”‚ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  â”‚        \u001b[38;5;34m896\u001b[0m â”‚ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\nâ”‚                     â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚        \u001b[38;5;34m128\u001b[0m â”‚ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\nâ”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ max_pooling2d       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\nâ”‚ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ add_7 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\nâ”‚                     â”‚                   â”‚            â”‚ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚     \u001b[38;5;34m18,496\u001b[0m â”‚ max_pooling2d[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\nâ”‚                     â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚        \u001b[38;5;34m128\u001b[0m â”‚ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\nâ”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ max_pooling2d_1     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\nâ”‚ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚     \u001b[38;5;34m73,856\u001b[0m â”‚ max_pooling2d_1[\u001b[38;5;34mâ€¦\u001b[0m â”‚\nâ”‚                     â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ max_pooling2d_2     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\nâ”‚ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ reshape (\u001b[38;5;33mReshape\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m4096\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32768\u001b[0m)     â”‚          \u001b[38;5;34m0\u001b[0m â”‚ max_pooling2d_2[\u001b[38;5;34mâ€¦\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ gru (\u001b[38;5;33mGRU\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚  \u001b[38;5;34m3,343,872\u001b[0m â”‚ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ concatenate         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33024\u001b[0m)     â”‚          \u001b[38;5;34m0\u001b[0m â”‚ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    â”‚\nâ”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ gru[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚  \u001b[38;5;34m8,454,400\u001b[0m â”‚ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         â”‚      \u001b[38;5;34m2,056\u001b[0m â”‚ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ input_layer         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ rescaling           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)         â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ patches (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Patches</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ rescaling[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ patch_encoder       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">53,312</span> â”‚ patches[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PatchEncoder</span>)      â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ layer_normalization â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ patch_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ multi_head_attentiâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">132,672</span> â”‚ layer_normalizatâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentioâ€¦</span> â”‚                   â”‚            â”‚ layer_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multi_head_attenâ€¦ â”‚\nâ”‚                     â”‚                   â”‚            â”‚ patch_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\nâ”‚                     â”‚                   â”‚            â”‚ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ multi_head_attentiâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">132,672</span> â”‚ layer_normalizatâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentioâ€¦</span> â”‚                   â”‚            â”‚ layer_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multi_head_attenâ€¦ â”‚\nâ”‚                     â”‚                   â”‚            â”‚ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\nâ”‚                     â”‚                   â”‚            â”‚ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ multi_head_attentiâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">132,672</span> â”‚ layer_normalizatâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentioâ€¦</span> â”‚                   â”‚            â”‚ layer_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multi_head_attenâ€¦ â”‚\nâ”‚                     â”‚                   â”‚            â”‚ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\nâ”‚                     â”‚                   â”‚            â”‚ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ multi_head_attentiâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">132,672</span> â”‚ layer_normalizatâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentioâ€¦</span> â”‚                   â”‚            â”‚ layer_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multi_head_attenâ€¦ â”‚\nâ”‚                     â”‚                   â”‚            â”‚ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> â”‚ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\nâ”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ max_pooling2d       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\nâ”‚                     â”‚                   â”‚            â”‚ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> â”‚ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\nâ”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ max_pooling2d_1     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> â”‚ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\nâ”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ max_pooling2d_2     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32768</span>)     â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,343,872</span> â”‚ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ concatenate         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33024</span>)     â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ gru[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">8,454,400</span> â”‚ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,056</span> â”‚ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,478,728\u001b[0m (47.60 MB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,478,728</span> (47.60 MB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,478,728\u001b[0m (47.60 MB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,478,728</span> (47.60 MB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# # Build your model\n",
        "# model = build_hybrid_model()\n",
        "\n",
        "# # Compile with Adamax optimizer\n",
        "# adamw = SGD(learning_rate=0.001)   # you can tune learning_rate\n",
        "# model.compile(optimizer=adamw,\n",
        "#               loss='sparse_categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# model.summary()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T17:13:27.393984Z",
          "iopub.execute_input": "2025-11-20T17:13:27.394194Z",
          "iopub.status.idle": "2025-11-20T17:13:27.397479Z",
          "shell.execute_reply.started": "2025-11-20T17:13:27.394179Z",
          "shell.execute_reply": "2025-11-20T17:13:27.396922Z"
        },
        "id": "wKGQxIrEuYWB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "import time\n",
        "\n",
        "# Record start time\n",
        "start_time = time.time()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=100,\n",
        "                    batch_size=64)\n",
        "\n",
        "# Record stop time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate total time taken\n",
        "training_time = end_time - start_time\n",
        "\n",
        "# Print the time taken\n",
        "print(f\"Training Time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T17:13:27.398122Z",
          "iopub.execute_input": "2025-11-20T17:13:27.398326Z"
        },
        "id": "YRXLGnUCuYWB",
        "outputId": "5637b005-7d26-485d-b34b-a34238031755"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/100\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "I0000 00:00:1763658826.251741     102 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 71ms/step - accuracy: 0.7214 - loss: 0.7727 - val_accuracy: 0.9653 - val_loss: 0.1123\nEpoch 2/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9865 - loss: 0.0505 - val_accuracy: 0.9619 - val_loss: 0.1304\nEpoch 3/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9934 - loss: 0.0221 - val_accuracy: 0.9909 - val_loss: 0.0285\nEpoch 4/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9965 - loss: 0.0095 - val_accuracy: 0.9841 - val_loss: 0.0478\nEpoch 5/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.9959 - loss: 0.0142 - val_accuracy: 0.9835 - val_loss: 0.0510\nEpoch 6/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.9905 - loss: 0.0264 - val_accuracy: 0.9847 - val_loss: 0.0503\nEpoch 7/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9977 - loss: 0.0097 - val_accuracy: 0.9932 - val_loss: 0.0217\nEpoch 8/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 5.5182e-04 - val_accuracy: 0.9937 - val_loss: 0.0218\nEpoch 9/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 8.5448e-05 - val_accuracy: 0.9932 - val_loss: 0.0229\nEpoch 10/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 4.4806e-05 - val_accuracy: 0.9932 - val_loss: 0.0236\nEpoch 11/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 3.7584e-05 - val_accuracy: 0.9932 - val_loss: 0.0234\nEpoch 12/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 2.8042e-05 - val_accuracy: 0.9937 - val_loss: 0.0230\nEpoch 13/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 2.4875e-05 - val_accuracy: 0.9932 - val_loss: 0.0238\nEpoch 14/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.9244e-05 - val_accuracy: 0.9943 - val_loss: 0.0224\nEpoch 15/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.8289e-05 - val_accuracy: 0.9932 - val_loss: 0.0238\nEpoch 16/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.5413e-05 - val_accuracy: 0.9932 - val_loss: 0.0237\nEpoch 17/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.1866e-05 - val_accuracy: 0.9932 - val_loss: 0.0240\nEpoch 18/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.0525e-05 - val_accuracy: 0.9932 - val_loss: 0.0244\nEpoch 19/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 8.1975e-06 - val_accuracy: 0.9932 - val_loss: 0.0240\nEpoch 20/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 7.8668e-06 - val_accuracy: 0.9943 - val_loss: 0.0241\nEpoch 21/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 6.2766e-06 - val_accuracy: 0.9937 - val_loss: 0.0246\nEpoch 22/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 5.3727e-06 - val_accuracy: 0.9937 - val_loss: 0.0245\nEpoch 23/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 4.2868e-06 - val_accuracy: 0.9943 - val_loss: 0.0245\nEpoch 24/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 3.8496e-06 - val_accuracy: 0.9937 - val_loss: 0.0248\nEpoch 25/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 4.2509e-06 - val_accuracy: 0.9937 - val_loss: 0.0250\nEpoch 26/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 3.6963e-06 - val_accuracy: 0.9937 - val_loss: 0.0254\nEpoch 27/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 3.3647e-06 - val_accuracy: 0.9937 - val_loss: 0.0254\nEpoch 28/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 3.0039e-06 - val_accuracy: 0.9937 - val_loss: 0.0255\nEpoch 29/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 2.5971e-06 - val_accuracy: 0.9943 - val_loss: 0.0248\nEpoch 30/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.1986e-06 - val_accuracy: 0.9943 - val_loss: 0.0252\nEpoch 31/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 2.2449e-06 - val_accuracy: 0.9943 - val_loss: 0.0256\nEpoch 32/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.9687e-06 - val_accuracy: 0.9937 - val_loss: 0.0260\nEpoch 33/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.7768e-06 - val_accuracy: 0.9937 - val_loss: 0.0265\nEpoch 34/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.5851e-06 - val_accuracy: 0.9943 - val_loss: 0.0262\nEpoch 35/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.4929e-06 - val_accuracy: 0.9943 - val_loss: 0.0264\nEpoch 36/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.4484e-06 - val_accuracy: 0.9943 - val_loss: 0.0264\nEpoch 37/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.1392e-06 - val_accuracy: 0.9943 - val_loss: 0.0267\nEpoch 38/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.7654e-06 - val_accuracy: 0.9937 - val_loss: 0.0275\nEpoch 39/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.0980e-06 - val_accuracy: 0.9943 - val_loss: 0.0274\nEpoch 40/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.0773e-06 - val_accuracy: 0.9943 - val_loss: 0.0272\nEpoch 41/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.0996e-06 - val_accuracy: 0.9943 - val_loss: 0.0276\nEpoch 42/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.0967e-06 - val_accuracy: 0.9943 - val_loss: 0.0276\nEpoch 43/100\n\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.2011e-06 - val_accuracy: 0.9937 - val_loss: 0.0260\nEpoch 44/100\n\u001b[1m 79/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.1600e-06",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------------------\n",
        "# Accuracy Plot (HD)\n",
        "# ------------------------\n",
        "plt.figure(figsize=(14, 12), dpi=1200)  # High-res figure\n",
        "plt.plot(history.history['accuracy'], marker='o', markersize=8, markeredgewidth=2, markeredgecolor=' #ffd700', linewidth=4, label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], marker='*', markersize=8, markeredgewidth=2, markeredgecolor=' DarkTurquoise', linestyle='--', linewidth=4, label='Validation Accuracy')\n",
        "\n",
        "# Update font\n",
        "plt.rcParams.update({'font.family': 'Arial'})\n",
        "\n",
        "plt.title('Model Accuracy', fontsize=18, fontweight='bold')\n",
        "plt.xlabel('Epochs', fontsize=16, fontweight='bold')\n",
        "plt.ylabel('Accuracy', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Modify ticks\n",
        "plt.xticks(fontsize=14, color='gray')\n",
        "plt.yticks(fontsize=14, color='gray')\n",
        "\n",
        "# Modify grid lines\n",
        "plt.grid(True, linestyle='-', linewidth=0.5, alpha=0.3)  # Lighter grid\n",
        "\n",
        "# Change background color\n",
        "plt.gca().set_facecolor('whitesmoke')\n",
        "\n",
        "# Customize legend\n",
        "plt.legend(fontsize=14, loc='lower right', shadow=True, fancybox=True, framealpha=1, facecolor='white')\n",
        "\n",
        "# Tight layout for better fitting\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save as HD\n",
        "plt.savefig('Accuracy_curve_HD.png', dpi=1200)  # Ultra HD save\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "iSHzuAaquYWC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # ------------------------\n",
        "# # Accuracy Plot (HD)\n",
        "# # ------------------------\n",
        "# plt.figure(figsize=(10, 6), dpi=300)  # HD figure\n",
        "# plt.plot(history.history['accuracy'], marker='o', markersize=6, linewidth=2, label='Train Accuracy')\n",
        "# plt.plot(history.history['val_accuracy'], marker='x', markersize=6, linewidth=2, linestyle='--', label='Validation Accuracy')\n",
        "\n",
        "# plt.title('Model Accuracy', fontsize=16, fontweight='bold')\n",
        "# plt.xlabel('Epochs', fontsize=14, fontweight='bold')\n",
        "# plt.ylabel('Accuracy', fontsize=14, fontweight='bold')\n",
        "# plt.xticks(fontsize=12)\n",
        "# plt.yticks(fontsize=12)\n",
        "# plt.grid(True, linestyle='--', alpha=0.6)\n",
        "# plt.legend(fontsize=12, loc='lower right')\n",
        "# plt.tight_layout()\n",
        "# plt.savefig('Accuracy_curve_HD.png', dpi=600)  # Ultra HD save\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "gSbWeL5juYWC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------------------\n",
        "# Loss Plot (HD)\n",
        "# ------------------------\n",
        "plt.figure(figsize=(14, 12), dpi=1200)  # High-res figure\n",
        "plt.plot(history.history['loss'], marker='o', markersize=8, markeredgewidth=2, markeredgecolor='#ffd700', linewidth=4, label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], marker='*', markersize=8, markeredgewidth=2, markeredgecolor='DarkTurquoise', linestyle='--', linewidth=4, label='Validation Loss')\n",
        "\n",
        "# Update font\n",
        "plt.rcParams.update({'font.family': 'Arial'})\n",
        "\n",
        "# Title and labels\n",
        "plt.title('Model Loss', fontsize=18, fontweight='bold')\n",
        "plt.xlabel('Epochs', fontsize=16, fontweight='bold')\n",
        "plt.ylabel('Loss', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Modify ticks for better readability\n",
        "plt.xticks(fontsize=14, color='gray')\n",
        "plt.yticks(fontsize=14, color='gray')\n",
        "\n",
        "# Modify grid lines for a subtle look\n",
        "plt.grid(True, linestyle='-', linewidth=0.5, alpha=0.3)  # Lighter and subtler grid\n",
        "\n",
        "# Set background color\n",
        "plt.gca().set_facecolor('whitesmoke')\n",
        "\n",
        "# Customize legend with shadow and background color\n",
        "plt.legend(fontsize=14, loc='upper right', shadow=True, fancybox=True, framealpha=1, facecolor='white')\n",
        "\n",
        "# Tight layout for better fitting\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save as HD image\n",
        "plt.savefig('Loss_curve_HD.png', dpi=1200)  # Ultra HD save\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "e01KCZ1ouYWD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # ------------------------\n",
        "# # Loss Plot (HD)\n",
        "# # ------------------------\n",
        "# plt.figure(figsize=(10, 6), dpi=300)  # HD figure\n",
        "# plt.plot(history.history['loss'], marker='o', markersize=6, linewidth=2, label='Train Loss')\n",
        "# plt.plot(history.history['val_loss'], marker='x', markersize=6, linewidth=2, linestyle='--', label='Validation Loss')\n",
        "\n",
        "# plt.title('Model Loss', fontsize=16, fontweight='bold')\n",
        "# plt.xlabel('Epochs', fontsize=14, fontweight='bold')\n",
        "# plt.ylabel('Loss', fontsize=14, fontweight='bold')\n",
        "# plt.xticks(fontsize=12)\n",
        "# plt.yticks(fontsize=12)\n",
        "# plt.grid(True, linestyle='--', alpha=0.6)\n",
        "# plt.legend(fontsize=12, loc='upper right')\n",
        "# plt.tight_layout()\n",
        "# plt.savefig('Loss_curve_HD.png', dpi=600)  # Ultra HD save\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "qm9HVxr-uYWD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# cmap='viridis',cividis"
      ],
      "metadata": {
        "trusted": true,
        "id": "0FNoLTJnuYWD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# ------------------------\n",
        "# Model evaluation on the validation set\n",
        "# ------------------------\n",
        "print(\"\\nEvaluation on validation set:\")\n",
        "val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
        "print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "# ------------------------\n",
        "# Make predictions\n",
        "# ------------------------\n",
        "y_pred_probs = model.predict(X_val)  # Predicted probabilities\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)  # Class predictions\n",
        "\n",
        "# ------------------------\n",
        "# Confusion Matrix (Enhanced Premium Quality)\n",
        "# ------------------------\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "\n",
        "# Set premium figure size and resolution\n",
        "plt.figure(figsize=(14, 12), dpi=1200)  # High-quality figure with larger size\n",
        "\n",
        "# Create the heatmap with improved styles and color palette\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt='d',\n",
        "    cmap='viridis',  # High-quality, professional color palette (also colorblind-friendly)\n",
        "    xticklabels=np.unique(y_val),\n",
        "    yticklabels=np.unique(y_val),\n",
        "    cbar=True,\n",
        "    annot_kws={\"size\":20, \"weight\":\"bold\", \"color\":'white'},  # White annotations for contrast\n",
        "    linewidths=0.8,  # Fine grid lines for a more elegant structure\n",
        "    linecolor='gray',  # Light gray grid lines for subtlety\n",
        "    square=True,  # Make the heatmap square to match matrix dimensions\n",
        ")\n",
        "\n",
        "# Title and axis labels with bold and elegant font\n",
        "plt.title(\"Confusion Matrix\", fontsize=20, weight='bold', family='Times New Roman')\n",
        "plt.xlabel(\"Predicted\", fontsize=16, weight='bold', family='Arial')\n",
        "plt.ylabel(\"True\", fontsize=16, weight='bold', family='Arial')\n",
        "\n",
        "# Tick label customization for clarity and elegance\n",
        "plt.xticks(fontsize=14, rotation=45, weight='bold', family='Times New Roman', color='black')  # Rotated x-axis labels for clarity\n",
        "plt.yticks(fontsize=14, rotation=0, weight='bold', family='Times New Roman', color='black')   # Clear y-axis labels\n",
        "\n",
        "# Adjust background color for better contrast\n",
        "plt.gca().set_facecolor('whitesmoke')  # Subtle gray background for better contrast\n",
        "\n",
        "# Adjust layout for better spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the plot with ultra-high resolution\n",
        "plt.savefig('model_confusion_matrix_HD_Premium.png', dpi=1200)  # Save in ultra HD with 1200 DPI\n",
        "plt.show()\n",
        "\n",
        "# ------------------------\n",
        "# Classification Report\n",
        "# ------------------------\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_val, y_pred, digits=4))\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "5QITgpBOuYWE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import confusion_matrix, classification_report\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import numpy as np\n",
        "\n",
        "# # ------------------------\n",
        "# # Model evaluation on the validation set\n",
        "# # ------------------------\n",
        "# print(\"\\nEvaluation on validation set:\")\n",
        "# val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
        "# print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "# # ------------------------\n",
        "# # Make predictions\n",
        "# # ------------------------\n",
        "# y_pred_probs = model.predict(X_val)  # Predicted probabilities\n",
        "# y_pred = np.argmax(y_pred_probs, axis=1)  # Class predictions\n",
        "\n",
        "# # ------------------------\n",
        "# # Confusion Matrix (Improved Color)\n",
        "# # ------------------------\n",
        "# cm = confusion_matrix(y_val, y_pred)\n",
        "\n",
        "# plt.figure(figsize=(8, 6), dpi=300)  # HD figure\n",
        "# sns.heatmap(\n",
        "#     cm,\n",
        "#     annot=True,\n",
        "#     fmt='d',\n",
        "#     cmap='viridis',  # Changed color palette\n",
        "#     xticklabels=np.unique(y_val),\n",
        "#     yticklabels=np.unique(y_val),\n",
        "#     cbar=True,\n",
        "#     annot_kws={\"size\":14, \"weight\":\"bold\"},\n",
        "#     linewidths=0.5,  # Optional: adds grid lines\n",
        "#     linecolor='white'\n",
        "# )\n",
        "# plt.xlabel(\"Predicted\", fontsize=14, weight='bold')\n",
        "# plt.ylabel(\"True\", fontsize=14, weight='bold')\n",
        "# plt.title(\"Confusion Matrix\", fontsize=16, weight='bold')\n",
        "# plt.xticks(fontsize=12)\n",
        "# plt.yticks(fontsize=12)\n",
        "# plt.tight_layout()\n",
        "# plt.savefig('model_confusion_matrix_HD.png', dpi=600)  # Ultra HD save\n",
        "# plt.show()\n",
        "\n",
        "# # ------------------------\n",
        "# # Classification Report\n",
        "# # ------------------------\n",
        "# print(\"\\nClassification Report:\")\n",
        "# print(classification_report(y_val, y_pred, digits=4))\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "T1Ddja3guYWE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import confusion_matrix, classification_report\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import numpy as np\n",
        "\n",
        "# # ------------------------\n",
        "# # Model evaluation on the validation set\n",
        "# # ------------------------\n",
        "# print(\"\\nEvaluation on validation set:\")\n",
        "# val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
        "# print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "# # ------------------------\n",
        "# # Make predictions\n",
        "# # ------------------------\n",
        "# y_pred_probs = model.predict(X_val)  # Predicted probabilities\n",
        "# y_pred = np.argmax(y_pred_probs, axis=1)  # Class predictions\n",
        "\n",
        "# # ------------------------\n",
        "# # Confusion Matrix (HD)\n",
        "# # ------------------------\n",
        "# cm = confusion_matrix(y_val, y_pred)\n",
        "# plt.figure(figsize=(8, 6), dpi=300)  # HD figure\n",
        "# sns.heatmap(\n",
        "#     cm, annot=True, fmt='d', cmap='Blues',\n",
        "#     xticklabels=np.unique(y_val), yticklabels=np.unique(y_val),\n",
        "#     cbar=True, annot_kws={\"size\":14, \"weight\":\"bold\"}\n",
        "# )\n",
        "# plt.xlabel(\"Predicted\", fontsize=14, weight='bold')\n",
        "# plt.ylabel(\"True\", fontsize=14, weight='bold')\n",
        "# plt.title(\"Confusion Matrix\", fontsize=16, weight='bold')\n",
        "# plt.xticks(fontsize=12)\n",
        "# plt.yticks(fontsize=12)\n",
        "# plt.tight_layout()\n",
        "# plt.savefig('model_confusion_matrix_HD.png', dpi=600)  # Ultra HD save\n",
        "# plt.show()\n",
        "\n",
        "# # ------------------------\n",
        "# # Classification Report\n",
        "# # ------------------------\n",
        "# print(\"\\nClassification Report:\")\n",
        "# print(classification_report(y_val, y_pred, digits=4))\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "1dwG-uWYuYWE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # Model evaluation on the validation set\n",
        "# print(\"\\nEvaluation on validation set:\")\n",
        "# model.evaluate(X_val, y_val)  # Evaluate the model on the validation set\n",
        "\n",
        "# # Make predictions\n",
        "# y_pred_probs = model.predict(X_val)  # Get the predicted probabilities\n",
        "# y_pred = np.argmax(y_pred_probs, axis=1)  # Convert probabilities to class predictions\n",
        "\n",
        "# # Confusion Matrix\n",
        "# cm = confusion_matrix(y_val, y_pred)\n",
        "# plt.figure(figsize=(6,6))\n",
        "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "# plt.xlabel(\"Predicted\")\n",
        "# plt.ylabel(\"True\")\n",
        "# plt.title(\"Confusion Matrix\")\n",
        "# plt.savefig('model_confusion_matrix_curve.png', dpi=300)\n",
        "\n",
        "# plt.show()\n",
        "\n",
        "# # Classification Report\n",
        "# print(\"\\nClassification Report:\")\n",
        "# print(classification_report(y_val, y_pred))\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "b9xvNgUmuYWF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# ------------------------\n",
        "# Predict the probabilities\n",
        "# ------------------------\n",
        "y_prob = model.predict(X_val)  # Predicted probabilities for each class using the validation data\n",
        "\n",
        "# ------------------------\n",
        "# One-hot encode the true labels for multiclass\n",
        "# ------------------------\n",
        "y_val_bin = label_binarize(y_val, classes=np.arange(num_classes))  # auto handles number of classes\n",
        "\n",
        "# ------------------------\n",
        "# Calculate ROC and AUC for each class\n",
        "# ------------------------\n",
        "fpr, tpr, roc_auc = dict(), dict(), dict()\n",
        "\n",
        "# Compute ROC curve and AUC for each class\n",
        "for i in range(num_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_val_bin[:, i], y_prob[:, i])\n",
        "    roc_auc[i] = roc_auc_score(y_val_bin[:, i], y_prob[:, i])\n",
        "\n",
        "# ------------------------\n",
        "# Plot ROC Curves (Enhanced Premium Quality)\n",
        "# ------------------------\n",
        "plt.figure(figsize=(14, 12), dpi=1200)  # Ultra-high resolution\n",
        "colors = plt.cm.tab10(np.linspace(0, 1, num_classes))  # Distinct colors for each class\n",
        "\n",
        "for i, color in zip(range(num_classes), colors):\n",
        "    plt.plot(\n",
        "        fpr[i], tpr[i], color=color, lw=3, marker='o', markersize=8, markevery=0.1,\n",
        "        label=f'Class {i+1} (AUC = {roc_auc[i]:.2f})'\n",
        "    )\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='black', linestyle='--', lw=2)\n",
        "\n",
        "# Title and labels with customized font size and style\n",
        "plt.xlabel('False Positive Rate', fontsize=18, weight='bold', family='Times New Roman')\n",
        "plt.ylabel('True Positive Rate', fontsize=18, weight='bold', family='Times New Roman')\n",
        "plt.title('Receiver Operating Characteristic Curve (ROC Curve)', fontsize=20, weight='bold', family='Times New Roman')\n",
        "\n",
        "# Customize ticks for clarity\n",
        "plt.xticks(fontsize=14, weight='bold', color='black')\n",
        "plt.yticks(fontsize=14, weight='bold', color='black')\n",
        "\n",
        "# Customize legend for professional look\n",
        "plt.legend(loc='lower right', fontsize=14, frameon=True, shadow=True, fancybox=True, facecolor='white', edgecolor='black')\n",
        "\n",
        "# Customize grid lines to be subtle but visible\n",
        "plt.grid(alpha=0.4, linestyle='--', linewidth=0.5)\n",
        "\n",
        "# Adjust layout for better fitting\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the plot as a high-quality image\n",
        "plt.savefig('ROC_curve_HD_Premium.png', dpi=1200)  # Save in ultra HD\n",
        "plt.show()\n",
        "\n",
        "# ------------------------\n",
        "# Print AUC scores for each class\n",
        "# ------------------------\n",
        "for i in range(num_classes):\n",
        "    print(f\"Class {i+1} AUC: {roc_auc[i]:.2f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "q7F17gm4uYWF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # ------------------------\n",
        "# # Predict the probabilities\n",
        "# # ------------------------\n",
        "# y_prob = model.predict(X_val)  # Predicted probabilities for each class using the validation data\n",
        "\n",
        "# # ------------------------\n",
        "# # One-hot encode the true labels for multiclass\n",
        "# # ------------------------\n",
        "# from sklearn.preprocessing import label_binarize\n",
        "# y_val_bin = label_binarize(y_val, classes=np.arange(num_classes))  # auto handles number of classes\n",
        "\n",
        "# # ------------------------\n",
        "# # Calculate ROC and AUC for each class\n",
        "# # ------------------------\n",
        "# from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "# fpr, tpr, roc_auc = dict(), dict(), dict()\n",
        "\n",
        "# # Compute ROC curve and AUC for each class\n",
        "# for i in range(num_classes):\n",
        "#     fpr[i], tpr[i], _ = roc_curve(y_val_bin[:, i], y_prob[:, i])\n",
        "#     roc_auc[i] = roc_auc_score(y_val_bin[:, i], y_prob[:, i])\n",
        "\n",
        "# # ------------------------\n",
        "# # Plot ROC Curves (HD Quality)\n",
        "# # ------------------------\n",
        "# plt.figure(figsize=(10, 8), dpi=300)  # High resolution\n",
        "# colors = plt.cm.tab10(np.linspace(0, 1, num_classes))  # Nice distinct colors\n",
        "\n",
        "# for i, color in zip(range(num_classes), colors):\n",
        "#     plt.plot(\n",
        "#         fpr[i], tpr[i], color=color, lw=2.5, marker='o', markevery=0.1,\n",
        "#         label=f'Class {i+1} (AUC = {roc_auc[i]:.2f})'\n",
        "#     )\n",
        "\n",
        "# plt.plot([0, 1], [0, 1], color='black', linestyle='--', lw=2)\n",
        "\n",
        "# plt.xlabel('False Positive Rate', fontsize=14, weight='bold')\n",
        "# plt.ylabel('True Positive Rate', fontsize=14, weight='bold')\n",
        "# plt.title('Receiver Operating Characteristic Curve (ROC Curve)', fontsize=16, weight='bold')\n",
        "\n",
        "# plt.xticks(fontsize=12)\n",
        "# plt.yticks(fontsize=12)\n",
        "# plt.legend(loc='lower right', fontsize=12, frameon=True, shadow=True, fancybox=True)\n",
        "\n",
        "# plt.grid(alpha=0.3)\n",
        "# plt.tight_layout()\n",
        "# plt.savefig('ROC_curve_HD.png', dpi=600)  # Ultra HD figure\n",
        "# plt.show()\n",
        "\n",
        "# # ------------------------\n",
        "# # Print AUC scores for each class\n",
        "# # ------------------------\n",
        "# for i in range(num_classes):\n",
        "#     print(f\"Class {i+1} AUC: {roc_auc[i]:.2f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "RkqC0T5juYWF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # ------------------------\n",
        "# # Predict the probabilities\n",
        "# # ------------------------\n",
        "# y_prob = model.predict(X_val)  # Predicted probabilities for each class using the validation data\n",
        "\n",
        "# # ------------------------\n",
        "# # One-hot encode the true labels for multiclass\n",
        "# # ------------------------\n",
        "# from sklearn.preprocessing import label_binarize\n",
        "# y_val_bin = label_binarize(y_val, classes=[0, 1, 2, 3])  # One-hot encoding for multiclass\n",
        "\n",
        "# # ------------------------\n",
        "# # Calculate ROC and AUC for each class\n",
        "# # ------------------------\n",
        "# from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "# fpr, tpr, roc_auc = dict(), dict(), dict()\n",
        "# num_classes = len(np.unique(y_val))  # Adjust to the number of classes\n",
        "\n",
        "# # Compute ROC curve and AUC for each class\n",
        "# for i in range(num_classes):\n",
        "#     fpr[i], tpr[i], _ = roc_curve(y_val_bin[:, i], y_prob[:, i])\n",
        "#     roc_auc[i] = roc_auc_score(y_val_bin[:, i], y_prob[:, i])\n",
        "\n",
        "# # ------------------------\n",
        "# # Plot ROC Curves for each class\n",
        "# # ------------------------\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# for i in range(num_classes):\n",
        "#     plt.plot(fpr[i], tpr[i], label=f'Class {i+1} (AUC = {roc_auc[i]:0.2f})')\n",
        "\n",
        "# plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "# plt.xlabel('False Positive Rate')\n",
        "# plt.ylabel('True Positive Rate')\n",
        "# plt.title('Receiver Operating Characteristic Curve (ROC Curve)')\n",
        "# plt.legend(loc='lower right')\n",
        "# plt.savefig('ROC_curve.png', dpi=300)\n",
        "# plt.show()\n",
        "\n",
        "# # ------------------------\n",
        "# # Print AUC scores for each class\n",
        "# # ------------------------\n",
        "# for i in range(num_classes):\n",
        "#     print(f\"Class {i+1} AUC: {roc_auc[i]:0.2f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "lMo4uRXxuYWG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# # Model predictions\n",
        "# y_pred_proba = model.predict(X_val)\n",
        "# y_pred = np.argmax(y_pred_proba, axis=1)  # predicted class indices\n",
        "\n",
        "# # Handle y_val format\n",
        "# if y_val.ndim == 2:   # one-hot encoded\n",
        "#     y_true = np.argmax(y_val, axis=1)\n",
        "# else:                 # integer encoded\n",
        "#     y_true = y_val\n",
        "\n",
        "# # Per-class accuracy\n",
        "# cm = confusion_matrix(y_true, y_pred)\n",
        "# class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
        "\n",
        "# print(\"\\nPer-class Accuracy:\")\n",
        "# for i, acc in enumerate(class_accuracy):\n",
        "#     print(f\"Class {i} Accuracy: {acc:.4f}\")\n",
        "\n",
        "# # Classification report\n",
        "# print(\"\\nClassification Report:\")\n",
        "# print(classification_report(y_true, y_pred, target_names=[f\"Class {i}\" for i in range(4)]))\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "yAWNr8KUuYWG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "iOsuc9QCuYWG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "cY6fDPoYuYWG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "gWNznM2JuYWH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "6Tp0o2h1uYWH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import pandas as pd\n",
        "# import time\n",
        "# from sklearn.model_selection import KFold\n",
        "# from sklearn.metrics import (\n",
        "#     cohen_kappa_score, confusion_matrix, roc_auc_score,\n",
        "#     precision_score, recall_score, f1_score, roc_curve, auc\n",
        "# )\n",
        "# from sklearn.preprocessing import label_binarize\n",
        "# import tensorflow as tf\n",
        "\n",
        "# # -----------------------\n",
        "# # Create Results Folder\n",
        "# # -----------------------\n",
        "# os.makedirs(\"results\", exist_ok=True)\n",
        "\n",
        "# # -----------------------\n",
        "# # Data\n",
        "# # -----------------------\n",
        "# X = np.load(\"/kaggle/working/X.npy\")\n",
        "# y = np.load(\"/kaggle/working/y.npy\")\n",
        "# num_classes = len(np.unique(y))\n",
        "\n",
        "# # -----------------------\n",
        "# # K-Fold Setup\n",
        "# # -----------------------\n",
        "# kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# fold_no = 1\n",
        "# acc_per_fold, loss_per_fold, kappa_per_fold, specificity_per_fold, roc_auc_per_fold = [], [], [], [], []\n",
        "# histories = []\n",
        "# fold_metrics = []\n",
        "\n",
        "# for train_idx, val_idx in kfold.split(X, y):\n",
        "#     print(f\"\\nğŸ“Œ Training Fold {fold_no} ...\")\n",
        "\n",
        "#     X_train, X_val = X[train_idx], X[val_idx]\n",
        "#     y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "#     # -----------------------\n",
        "#     # Build & Compile Model\n",
        "#     # -----------------------\n",
        "#     model = build_hybrid_model()\n",
        "#     model.compile(\n",
        "#         optimizer='adam',\n",
        "#         loss='sparse_categorical_crossentropy',\n",
        "#         metrics=['accuracy']\n",
        "#     )\n",
        "\n",
        "#     # -----------------------\n",
        "#     # Train Model\n",
        "#     # -----------------------\n",
        "#     start_time = time.time()\n",
        "#     history = model.fit(\n",
        "#         X_train, y_train,\n",
        "#         validation_data=(X_val, y_val),\n",
        "#         epochs=20,\n",
        "#         batch_size=64,\n",
        "#         verbose=1\n",
        "#     )\n",
        "#     end_time = time.time()\n",
        "#     training_time_msec = (end_time - start_time) * 1000\n",
        "#     histories.append(history.history)\n",
        "\n",
        "#     # -----------------------\n",
        "#     # Evaluate\n",
        "#     # -----------------------\n",
        "#     train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
        "#     val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
        "\n",
        "#     # Predictions\n",
        "#     y_val_probs = model.predict(X_val)\n",
        "#     y_val_pred = np.argmax(y_val_probs, axis=1)\n",
        "\n",
        "#     # --- Confusion Matrix ---\n",
        "#     cm = confusion_matrix(y_val, y_val_pred, labels=np.unique(y))\n",
        "#     plt.figure(figsize=(7,6))\n",
        "#     sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"magma\",\n",
        "#                 xticklabels=np.unique(y), yticklabels=np.unique(y),\n",
        "#                 annot_kws={\"size\":14}, cbar=True)\n",
        "#     plt.title(f\"Confusion Matrix - Fold {fold_no}\", fontsize=18, fontweight=\"bold\")\n",
        "#     plt.xlabel(\"Predicted\", fontsize=14, fontweight=\"bold\")\n",
        "#     plt.ylabel(\"True\", fontsize=14, fontweight=\"bold\")\n",
        "#     plt.xticks(fontsize=12); plt.yticks(fontsize=12)\n",
        "#     plt.tight_layout()\n",
        "#     plt.savefig(f'results/confusion_matrix_fold{fold_no}.png', dpi=600, bbox_inches=\"tight\")\n",
        "#     plt.close()\n",
        "\n",
        "#     # --- Accuracy & Loss Curves ---\n",
        "#     plt.figure(figsize=(12,5))\n",
        "#     # Accuracy\n",
        "#     plt.subplot(1,2,1)\n",
        "#     plt.plot(history.history['accuracy'], label=\"Train Acc\", linewidth=2, marker=\"o\")\n",
        "#     plt.plot(history.history['val_accuracy'], label=\"Val Acc\", linewidth=2, linestyle=\"--\", marker=\"x\")\n",
        "#     plt.title(f\"Accuracy - Fold {fold_no}\", fontsize=16, fontweight=\"bold\")\n",
        "#     plt.xlabel(\"Epochs\", fontsize=14); plt.ylabel(\"Accuracy\", fontsize=14)\n",
        "#     plt.legend(fontsize=12); plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "\n",
        "#     # Loss\n",
        "#     plt.subplot(1,2,2)\n",
        "#     plt.plot(history.history['loss'], label=\"Train Loss\", linewidth=2, marker=\"o\")\n",
        "#     plt.plot(history.history['val_loss'], label=\"Val Loss\", linewidth=2, linestyle=\"--\", marker=\"x\")\n",
        "#     plt.title(f\"Loss - Fold {fold_no}\", fontsize=16, fontweight=\"bold\")\n",
        "#     plt.xlabel(\"Epochs\", fontsize=14); plt.ylabel(\"Loss\", fontsize=14)\n",
        "#     plt.legend(fontsize=12); plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "\n",
        "#     plt.tight_layout()\n",
        "#     plt.savefig(f'results/training_curves_fold{fold_no}.png', dpi=600, bbox_inches=\"tight\")\n",
        "#     plt.close()\n",
        "\n",
        "#     # --- ROC & AUC Curves ---\n",
        "#     y_val_bin = label_binarize(y_val, classes=np.arange(num_classes))\n",
        "#     fpr, tpr, roc_auc = {}, {}, {}\n",
        "\n",
        "#     plt.figure(figsize=(8,6))\n",
        "#     for i in range(num_classes):\n",
        "#         fpr[i], tpr[i], _ = roc_curve(y_val_bin[:, i], y_val_probs[:, i])\n",
        "#         roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "#         plt.plot(fpr[i], tpr[i], lw=2, label=f\"Class {i} (AUC={roc_auc[i]:.2f})\")\n",
        "\n",
        "#     # Macro average\n",
        "#     all_fpr = np.unique(np.concatenate([fpr[i] for i in range(num_classes)]))\n",
        "#     mean_tpr = np.zeros_like(all_fpr)\n",
        "#     for i in range(num_classes):\n",
        "#         mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "#     mean_tpr /= num_classes\n",
        "#     roc_auc[\"macro\"] = auc(all_fpr, mean_tpr)\n",
        "#     plt.plot(all_fpr, mean_tpr, color=\"darkblue\", linestyle=\"--\",\n",
        "#              label=f\"Macro-avg (AUC={roc_auc['macro']:.2f})\", lw=3)\n",
        "\n",
        "#     plt.plot([0,1],[0,1],'k--', lw=2)\n",
        "#     plt.xlim([0.0,1.0]); plt.ylim([0.0,1.05])\n",
        "#     plt.xlabel(\"False Positive Rate\", fontsize=14)\n",
        "#     plt.ylabel(\"True Positive Rate\", fontsize=14)\n",
        "#     plt.title(f\"ROC Curve - Fold {fold_no}\", fontsize=16, fontweight=\"bold\")\n",
        "#     plt.legend(loc=\"lower right\", fontsize=11)\n",
        "#     plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "#     plt.tight_layout()\n",
        "#     plt.savefig(f'results/roc_curve_fold{fold_no}.png', dpi=600, bbox_inches=\"tight\")\n",
        "#     plt.close()\n",
        "\n",
        "#     # --- Metrics ---\n",
        "#     roc_auc_score_macro = roc_auc_score(y_val_bin, y_val_probs, average=\"macro\", multi_class=\"ovr\")\n",
        "#     roc_auc_per_fold.append(roc_auc_score_macro)\n",
        "\n",
        "#     kappa = cohen_kappa_score(y_val, y_val_pred)\n",
        "\n",
        "#     specificity_list = []\n",
        "#     for i in range(num_classes):\n",
        "#         TP = cm[i,i]\n",
        "#         FP = cm[:,i].sum() - TP\n",
        "#         FN = cm[i,:].sum() - TP\n",
        "#         TN = cm.sum() - (TP + FP + FN)\n",
        "#         specificity_list.append(TN / (TN + FP + 1e-8))\n",
        "#     specificity = np.mean(specificity_list)\n",
        "\n",
        "#     precision = precision_score(y_val, y_val_pred, average='macro')\n",
        "#     recall = recall_score(y_val, y_val_pred, average='macro')\n",
        "#     f1 = f1_score(y_val, y_val_pred, average='macro')\n",
        "\n",
        "#     print(f\"Fold {fold_no} - Acc: {val_acc:.4f}, Loss: {val_loss:.4f}, \"\n",
        "#           f\"Kappa: {kappa:.4f}, Specificity: {specificity:.4f}, \"\n",
        "#           f\"ROC-AUC: {roc_auc_score_macro:.4f}\")\n",
        "\n",
        "#     # Store results\n",
        "#     acc_per_fold.append(val_acc * 100)\n",
        "#     loss_per_fold.append(val_loss)\n",
        "#     kappa_per_fold.append(kappa)\n",
        "#     specificity_per_fold.append(specificity)\n",
        "\n",
        "#     fold_metrics.append({\n",
        "#         \"Fold\": fold_no,\n",
        "#         \"Precision %\": precision*100,\n",
        "#         \"Recall %\": recall*100,\n",
        "#         \"F1-score %\": f1*100,\n",
        "#         \"Training Time (ms)\": training_time_msec,\n",
        "#         \"Train Loss\": train_loss,\n",
        "#         \"Val Loss\": val_loss,\n",
        "#         \"Train Accuracy %\": train_acc*100,\n",
        "#         \"Val Accuracy %\": val_acc*100,\n",
        "#         \"Specificity %\": specificity*100,\n",
        "#         \"Cohen's Kappa %\": kappa*100,\n",
        "#         \"ROC-AUC %\": roc_auc_score_macro*100\n",
        "#     })\n",
        "\n",
        "#     fold_no += 1\n",
        "\n",
        "# # -----------------------\n",
        "# # Total Accuracy & Loss Curves (All Folds)\n",
        "# # -----------------------\n",
        "# plt.figure(figsize=(14,6))\n",
        "# # Accuracy\n",
        "# plt.subplot(1,2,1)\n",
        "# for i, hist in enumerate(histories, 1):\n",
        "#     plt.plot(hist['accuracy'], label=f'Fold {i} Train Acc', linewidth=1.8)\n",
        "#     plt.plot(hist['val_accuracy'], label=f'Fold {i} Val Acc', linestyle=\"--\", linewidth=1.8)\n",
        "# plt.title(\"Model Accuracy (All Folds)\", fontsize=16, fontweight=\"bold\")\n",
        "# plt.xlabel(\"Epochs\", fontsize=14); plt.ylabel(\"Accuracy\", fontsize=14)\n",
        "# plt.legend(fontsize=8, ncol=2); plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "\n",
        "# # Loss\n",
        "# plt.subplot(1,2,2)\n",
        "# for i, hist in enumerate(histories, 1):\n",
        "#     plt.plot(hist['loss'], label=f'Fold {i} Train Loss', linewidth=1.8)\n",
        "#     plt.plot(hist['val_loss'], label=f'Fold {i} Val Loss', linestyle=\"--\", linewidth=1.8)\n",
        "# plt.title(\"Model Loss (All Folds)\", fontsize=16, fontweight=\"bold\")\n",
        "# plt.xlabel(\"Epochs\", fontsize=14); plt.ylabel(\"Loss\", fontsize=14)\n",
        "# plt.legend(fontsize=8, ncol=2); plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.savefig('results/total_accuracy_loss_curves.png', dpi=600, bbox_inches=\"tight\")\n",
        "# plt.show()\n",
        "\n",
        "# # -----------------------\n",
        "# # Final Summary\n",
        "# # -----------------------\n",
        "# metrics_df = pd.DataFrame(fold_metrics).round(2)\n",
        "# metrics_df.to_csv(\"results/kfold_summary_metrics.csv\", index=False)\n",
        "# print(\"\\nâœ… K-Fold Summary Table:\")\n",
        "# display(metrics_df)\n",
        "\n",
        "# print(\"\\nâœ… Cross-validation results:\")\n",
        "# print(f\"Accuracy: {np.mean(acc_per_fold):.2f}% (+/- {np.std(acc_per_fold):.2f})\")\n",
        "# print(f\"Loss: {np.mean(loss_per_fold):.4f}\")\n",
        "# print(f\"Cohen's Kappa: {np.mean(kappa_per_fold):.4f}\")\n",
        "# print(f\"Specificity: {np.mean(specificity_per_fold):.4f}\")\n",
        "# print(f\"ROC-AUC: {np.mean(roc_auc_per_fold):.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "d80wvuDeuYWH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "LFRwjRkYuYWI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import (\n",
        "    cohen_kappa_score, confusion_matrix, roc_auc_score,\n",
        "    precision_score, recall_score, f1_score, roc_curve, auc\n",
        ")\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import tensorflow as tf\n",
        "\n",
        "# -----------------------\n",
        "# Data Loading\n",
        "# -----------------------\n",
        "X = np.load(\"/kaggle/working/X.npy\")\n",
        "y = np.load(\"/kaggle/working/y.npy\")\n",
        "num_classes = len(np.unique(y))\n",
        "\n",
        "# -----------------------\n",
        "# K-Fold Setup\n",
        "# -----------------------\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "fold_no = 1\n",
        "acc_per_fold, loss_per_fold, kappa_per_fold, specificity_per_fold, roc_auc_per_fold = [], [], [], [], []\n",
        "histories = []  # store history for total curves\n",
        "fold_metrics = []\n",
        "\n",
        "for train_idx, val_idx in kfold.split(X, y):\n",
        "    print(f\"\\nğŸ“Œ Training Fold {fold_no} ...\")\n",
        "\n",
        "    X_train, X_val = X[train_idx], X[val_idx]\n",
        "    y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "    # -----------------------\n",
        "    # Build & Compile Model\n",
        "    # -----------------------\n",
        "    model = build_hybrid_model()  # Assuming the function `build_hybrid_model()` exists\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # -----------------------\n",
        "    # Train Model\n",
        "    # -----------------------\n",
        "    start_time = time.time()\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=10,\n",
        "        batch_size=64,\n",
        "        verbose=1\n",
        "    )\n",
        "    end_time = time.time()\n",
        "    training_time_msec = (end_time - start_time) * 1000  # in milliseconds\n",
        "    histories.append(history.history)\n",
        "\n",
        "    # -----------------------\n",
        "    # Evaluate Model\n",
        "    # -----------------------\n",
        "    train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
        "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
        "\n",
        "    # Predictions\n",
        "    y_val_probs = model.predict(X_val)\n",
        "    y_val_pred = np.argmax(y_val_probs, axis=1)\n",
        "\n",
        "    # --- Confusion Matrix ---\n",
        "    cm = confusion_matrix(y_val, y_val_pred, labels=np.unique(y))\n",
        "    plt.figure(figsize=(14,12), dpi=1200)  # Ultra-high quality confusion matrix plot\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"cividis\", annot_kws={\"size\":20, \"weight\":\"bold\"},\n",
        "                xticklabels=np.unique(y), yticklabels=np.unique(y), cbar=True, linewidths=1, linecolor='white')\n",
        "    plt.title(f\"Confusion Matrix - Fold {fold_no}\", fontsize=18, weight='bold', family='Times New Roman')\n",
        "    plt.xlabel(\"Predicted\", fontsize=18, weight='bold', family='Times New Roman')\n",
        "    plt.ylabel(\"True\", fontsize=18, weight='bold', family='Times New Roman')\n",
        "    plt.savefig(f'confusion_matrix_fold{fold_no}.png', dpi=1200)\n",
        "    plt.close()\n",
        "\n",
        "    # --- Accuracy & Loss Curves ---\n",
        "    plt.figure(figsize=(14,12))\n",
        "    # Accuracy\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history['accuracy'], label=\"Train Acc\", color='green', lw=2)\n",
        "    plt.plot(history.history['val_accuracy'], label=\"Val Acc\", color='blue', lw=2)\n",
        "    plt.title(f\"Accuracy - Fold {fold_no}\", fontsize=16, weight='bold', family='Times New Roman')\n",
        "    plt.xlabel(\"Epochs\", fontsize=14, family='Times New Roman'); plt.ylabel(\"Accuracy\", fontsize=14, family='Times New Roman'); plt.legend()\n",
        "    # Loss\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history['loss'], label=\"Train Loss\", color='red', lw=2)\n",
        "    plt.plot(history.history['val_loss'], label=\"Val Loss\", color='orange', lw=2)\n",
        "    plt.title(f\"Loss - Fold {fold_no}\", fontsize=16, weight='bold', family='Times New Roman')\n",
        "    plt.xlabel(\"Epochs\", fontsize=14, family='Times New Roman'); plt.ylabel(\"Loss\", fontsize=14, family='Times New Roman'); plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'training_curves_fold{fold_no}.png', dpi=1200)\n",
        "    plt.close()\n",
        "\n",
        "    # --- ROC & AUC Curves ---\n",
        "    y_val_bin = label_binarize(y_val, classes=np.arange(num_classes))\n",
        "    fpr, tpr, roc_auc = {}, {}, {}\n",
        "\n",
        "    plt.figure(figsize=(14,12), dpi=1200)\n",
        "    for i in range(num_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_val_bin[:, i], y_val_probs[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "        plt.plot(fpr[i], tpr[i], lw=2, label=f\"Class {i} (AUC = {roc_auc[i]:.2f})\")\n",
        "\n",
        "    # Macro-average ROC curve\n",
        "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(num_classes)]))\n",
        "    mean_tpr = np.zeros_like(all_fpr)\n",
        "    for i in range(num_classes):\n",
        "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "    mean_tpr /= num_classes\n",
        "    roc_auc[\"macro\"] = auc(all_fpr, mean_tpr)\n",
        "    plt.plot(all_fpr, mean_tpr, color=\"navy\", linestyle=\"--\", lw=3, label=f\"Macro-average (AUC = {roc_auc['macro']:.2f})\")\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], color=\"black\", linestyle=\"--\", lw=2)\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel(\"False Positive Rate\", fontsize=14, family='Times New Roman')\n",
        "    plt.ylabel(\"True Positive Rate\", fontsize=14, family='Times New Roman')\n",
        "    plt.title(f\"ROC Curve - Fold {fold_no}\", fontsize=16, weight='bold', family='Times New Roman')\n",
        "    plt.legend(loc=\"lower right\", fontsize=12, shadow=True)\n",
        "    plt.savefig(f'roc_curve_fold{fold_no}.png', dpi=1200)\n",
        "    plt.close()\n",
        "\n",
        "    # --- Metrics ---\n",
        "    roc_auc_score_macro = roc_auc_score(y_val_bin, y_val_probs, average=\"macro\", multi_class=\"ovr\")\n",
        "    roc_auc_per_fold.append(roc_auc_score_macro)\n",
        "\n",
        "    kappa = cohen_kappa_score(y_val, y_val_pred)\n",
        "\n",
        "    specificity_list = []\n",
        "    for i in range(num_classes):\n",
        "        TP = cm[i,i]\n",
        "        FP = cm[:,i].sum() - TP\n",
        "        FN = cm[i,:].sum() - TP\n",
        "        TN = cm.sum() - (TP + FP + FN)\n",
        "        specificity_list.append(TN / (TN + FP + 1e-8))\n",
        "    specificity = np.mean(specificity_list)\n",
        "\n",
        "    precision = precision_score(y_val, y_val_pred, average='macro')\n",
        "    recall = recall_score(y_val, y_val_pred, average='macro')\n",
        "    f1 = f1_score(y_val, y_val_pred, average='macro')\n",
        "\n",
        "    print(f\"Fold {fold_no} - Acc: {val_acc:.4f}, Loss: {val_loss:.4f}, \"\n",
        "          f\"Kappa: {kappa:.4f}, Specificity: {specificity:.4f}, \"\n",
        "          f\"ROC-AUC: {roc_auc_score_macro:.4f}\")\n",
        "\n",
        "    # Store results\n",
        "    acc_per_fold.append(val_acc * 100)\n",
        "    loss_per_fold.append(val_loss)\n",
        "    kappa_per_fold.append(kappa)\n",
        "    specificity_per_fold.append(specificity)\n",
        "\n",
        "    fold_metrics.append({\n",
        "        \"Fold\": fold_no,\n",
        "        \"Precision %\": precision*100,\n",
        "        \"Recall %\": recall*100,\n",
        "        \"F1-score %\": f1*100,\n",
        "        \"Training Time (ms)\": training_time_msec,\n",
        "        \"Train Loss\": train_loss,\n",
        "        \"Val Loss\": val_loss,\n",
        "        \"Train Accuracy %\": train_acc*100,\n",
        "        \"Val Accuracy %\": val_acc*100,\n",
        "        \"Specificity %\": specificity*100,\n",
        "        \"Cohen's Kappa %\": kappa*100,\n",
        "        \"ROC-AUC %\": roc_auc_score_macro*100\n",
        "    })\n",
        "\n",
        "    fold_no += 1\n",
        "\n",
        "# -----------------------\n",
        "# Total Accuracy & Loss Curves (All Folds)\n",
        "# -----------------------\n",
        "plt.figure(figsize=(16,12), dpi=1200)\n",
        "# Accuracy\n",
        "plt.subplot(1,2,1)\n",
        "for i, hist in enumerate(histories, 1):\n",
        "    plt.plot(hist['accuracy'], label=f'Fold {i} Train Acc', lw=2)\n",
        "    plt.plot(hist['val_accuracy'], label=f'Fold {i} Val Acc', lw=2)\n",
        "plt.title(\"Model Accuracy (All Folds)\", fontsize=18, weight='bold', family='Times New Roman')\n",
        "plt.xlabel(\"Epoch\", fontsize=14, family='Times New Roman')\n",
        "plt.ylabel(\"Accuracy\", fontsize=14, family='Times New Roman')\n",
        "plt.legend(fontsize=7, ncol=2)\n",
        "plt.savefig('total_accuracy_curve.png', dpi=1200)\n",
        "# Loss\n",
        "plt.subplot(1,2,2)\n",
        "for i, hist in enumerate(histories, 1):\n",
        "    plt.plot(hist['loss'], label=f'Fold {i} Train Loss', lw=2)\n",
        "    plt.plot(hist['val_loss'], label=f'Fold {i} Val Loss', lw=2)\n",
        "plt.title(\"Model Loss (All Folds)\", fontsize=18, weight='bold', family='Times New Roman')\n",
        "plt.xlabel(\"Epoch\", fontsize=14, family='Times New Roman')\n",
        "plt.ylabel(\"Loss\", fontsize=14, family='Times New Roman')\n",
        "plt.legend(fontsize=7, ncol=2)\n",
        "plt.tight_layout()\n",
        "plt.savefig('total_loss_curve.png', dpi=1200)\n",
        "plt.show()\n",
        "\n",
        "# -----------------------\n",
        "# Final Summary\n",
        "# -----------------------\n",
        "metrics_df = pd.DataFrame(fold_metrics).round(2)\n",
        "metrics_df.to_csv(\"kfold_summary_metrics.csv\", index=False)\n",
        "print(\"\\nâœ… K-Fold Summary Table:\")\n",
        "display(metrics_df)\n",
        "\n",
        "print(\"\\nâœ… Cross-validation results:\")\n",
        "print(f\"Accuracy: {np.mean(acc_per_fold):.2f}% (+/- {np.std(acc_per_fold):.2f})\")\n",
        "print(f\"Loss: {np.mean(loss_per_fold):.4f}\")\n",
        "print(f\"Cohen's Kappa: {np.mean(kappa_per_fold):.4f}\")\n",
        "print(f\"Specificity: {np.mean(specificity_per_fold):.4f}\")\n",
        "print(f\"ROC-AUC: {np.mean(roc_auc_per_fold):.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "Ey7nm7wVuYWI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# #333333333###########333\n",
        "\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import pandas as pd\n",
        "# import time\n",
        "# from sklearn.model_selection import KFold\n",
        "# from sklearn.metrics import (\n",
        "#     cohen_kappa_score, confusion_matrix, roc_auc_score,\n",
        "#     precision_score, recall_score, f1_score, roc_curve, auc\n",
        "# )\n",
        "# from sklearn.preprocessing import label_binarize\n",
        "# import tensorflow as tf\n",
        "\n",
        "# # -----------------------\n",
        "# # Data\n",
        "# # -----------------------\n",
        "# X = np.load(\"/kaggle/working/X.npy\")\n",
        "# y = np.load(\"/kaggle/working/y.npy\")\n",
        "# num_classes = len(np.unique(y))\n",
        "\n",
        "# # -----------------------\n",
        "# # K-Fold Setup\n",
        "# # -----------------------\n",
        "# kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# fold_no = 1\n",
        "# acc_per_fold, loss_per_fold, kappa_per_fold, specificity_per_fold, roc_auc_per_fold = [], [], [], [], []\n",
        "# histories = []  # store history for total curves\n",
        "# fold_metrics = []\n",
        "\n",
        "# for train_idx, val_idx in kfold.split(X, y):\n",
        "#     print(f\"\\nğŸ“Œ Training Fold {fold_no} ...\")\n",
        "\n",
        "#     X_train, X_val = X[train_idx], X[val_idx]\n",
        "#     y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "#     # -----------------------\n",
        "#     # Build & Compile Model\n",
        "#     # -----------------------\n",
        "#     model = build_hybrid_model()\n",
        "#     model.compile(\n",
        "#         optimizer='adam',\n",
        "#         loss='sparse_categorical_crossentropy',\n",
        "#         metrics=['accuracy']\n",
        "#     )\n",
        "\n",
        "#     # -----------------------\n",
        "#     # Train Model\n",
        "#     # -----------------------\n",
        "#     start_time = time.time()\n",
        "#     history = model.fit(\n",
        "#         X_train, y_train,\n",
        "#         validation_data=(X_val, y_val),\n",
        "#         epochs=10,\n",
        "#         batch_size=64,\n",
        "#         verbose=1\n",
        "#     )\n",
        "#     end_time = time.time()\n",
        "#     training_time_msec = (end_time - start_time) * 1000  # in milliseconds\n",
        "#     histories.append(history.history)\n",
        "\n",
        "#     # -----------------------\n",
        "#     # Evaluate\n",
        "#     # -----------------------\n",
        "#     train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
        "#     val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
        "\n",
        "#     # Predictions\n",
        "#     y_val_probs = model.predict(X_val)\n",
        "#     y_val_pred = np.argmax(y_val_probs, axis=1)\n",
        "\n",
        "#     # --- Confusion Matrix ---\n",
        "#     cm = confusion_matrix(y_val, y_val_pred, labels=np.unique(y))\n",
        "#     plt.figure(figsize=(6,5))\n",
        "#     sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"viridis\",\n",
        "#                 xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
        "#     plt.title(f\"Confusion Matrix - Fold {fold_no}\")\n",
        "#     plt.xlabel(\"Predicted\")\n",
        "#     plt.ylabel(\"True\")\n",
        "#     plt.savefig(f'confusion_matrix_fold{fold_no}.png', dpi=600)\n",
        "#     plt.close()\n",
        "\n",
        "#     # --- Accuracy & Loss Curves ---\n",
        "#     plt.figure(figsize=(10,4))\n",
        "#     # Accuracy\n",
        "#     plt.subplot(1,2,1)\n",
        "#     plt.plot(history.history['accuracy'], label=\"Train Acc\")\n",
        "#     plt.plot(history.history['val_accuracy'], label=\"Val Acc\")\n",
        "#     plt.title(f\"Accuracy - Fold {fold_no}\")\n",
        "#     plt.xlabel(\"Epochs\"); plt.ylabel(\"Accuracy\"); plt.legend()\n",
        "#     # Loss\n",
        "#     plt.subplot(1,2,2)\n",
        "#     plt.plot(history.history['loss'], label=\"Train Loss\")\n",
        "#     plt.plot(history.history['val_loss'], label=\"Val Loss\")\n",
        "#     plt.title(f\"Loss - Fold {fold_no}\")\n",
        "#     plt.xlabel(\"Epochs\"); plt.ylabel(\"Loss\"); plt.legend()\n",
        "#     plt.savefig(f'training_curves_fold{fold_no}.png', dpi=600)\n",
        "#     plt.close()\n",
        "\n",
        "#     # --- ROC & AUC Curves ---\n",
        "#     y_val_bin = label_binarize(y_val, classes=np.arange(num_classes))\n",
        "#     fpr, tpr, roc_auc = {}, {}, {}\n",
        "\n",
        "#     plt.figure(figsize=(8,6))\n",
        "#     for i in range(num_classes):\n",
        "#         fpr[i], tpr[i], _ = roc_curve(y_val_bin[:, i], y_val_probs[:, i])\n",
        "#         roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "#         plt.plot(fpr[i], tpr[i], lw=2, label=f\"Class {i} (AUC = {roc_auc[i]:.2f})\")\n",
        "\n",
        "#     # Macro average ROC\n",
        "#     all_fpr = np.unique(np.concatenate([fpr[i] for i in range(num_classes)]))\n",
        "#     mean_tpr = np.zeros_like(all_fpr)\n",
        "#     for i in range(num_classes):\n",
        "#         mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "#     mean_tpr /= num_classes\n",
        "#     roc_auc[\"macro\"] = auc(all_fpr, mean_tpr)\n",
        "#     plt.plot(all_fpr, mean_tpr, color=\"navy\", linestyle=\"--\",\n",
        "#              label=f\"Macro-average (AUC = {roc_auc['macro']:.2f})\", lw=3)\n",
        "\n",
        "#     plt.plot([0,1],[0,1],'k--', lw=2)\n",
        "#     plt.xlim([0.0,1.0]); plt.ylim([0.0,1.05])\n",
        "#     plt.xlabel(\"False Positive Rate\")\n",
        "#     plt.ylabel(\"True Positive Rate\")\n",
        "#     plt.title(f\"ROC Curve - Fold {fold_no}\")\n",
        "#     plt.legend(loc=\"lower right\")\n",
        "#     plt.savefig(f'roc_curve_fold{fold_no}.png', dpi=300)\n",
        "#     plt.close()\n",
        "\n",
        "#     # --- Metrics ---\n",
        "#     roc_auc_score_macro = roc_auc_score(y_val_bin, y_val_probs, average=\"macro\", multi_class=\"ovr\")\n",
        "#     roc_auc_per_fold.append(roc_auc_score_macro)\n",
        "\n",
        "#     kappa = cohen_kappa_score(y_val, y_val_pred)\n",
        "\n",
        "#     specificity_list = []\n",
        "#     for i in range(num_classes):\n",
        "#         TP = cm[i,i]\n",
        "#         FP = cm[:,i].sum() - TP\n",
        "#         FN = cm[i,:].sum() - TP\n",
        "#         TN = cm.sum() - (TP + FP + FN)\n",
        "#         specificity_list.append(TN / (TN + FP + 1e-8))\n",
        "#     specificity = np.mean(specificity_list)\n",
        "\n",
        "#     precision = precision_score(y_val, y_val_pred, average='macro')\n",
        "#     recall = recall_score(y_val, y_val_pred, average='macro')\n",
        "#     f1 = f1_score(y_val, y_val_pred, average='macro')\n",
        "\n",
        "#     print(f\"Fold {fold_no} - Acc: {val_acc:.4f}, Loss: {val_loss:.4f}, \"\n",
        "#           f\"Kappa: {kappa:.4f}, Specificity: {specificity:.4f}, \"\n",
        "#           f\"ROC-AUC: {roc_auc_score_macro:.4f}\")\n",
        "\n",
        "#     # Store results\n",
        "#     acc_per_fold.append(val_acc * 100)\n",
        "#     loss_per_fold.append(val_loss)\n",
        "#     kappa_per_fold.append(kappa)\n",
        "#     specificity_per_fold.append(specificity)\n",
        "\n",
        "#     fold_metrics.append({\n",
        "#         \"Fold\": fold_no,\n",
        "#         \"Precision %\": precision*100,\n",
        "#         \"Recall %\": recall*100,\n",
        "#         \"F1-score %\": f1*100,\n",
        "#         \"Training Time (ms)\": training_time_msec,\n",
        "#         \"Train Loss\": train_loss,\n",
        "#         \"Val Loss\": val_loss,\n",
        "#         \"Train Accuracy %\": train_acc*100,\n",
        "#         \"Val Accuracy %\": val_acc*100,\n",
        "#         \"Specificity %\": specificity*100,\n",
        "#         \"Cohen's Kappa %\": kappa*100,\n",
        "#         \"ROC-AUC %\": roc_auc_score_macro*100\n",
        "#     })\n",
        "\n",
        "#     fold_no += 1\n",
        "\n",
        "# # -----------------------\n",
        "# # Total Accuracy & Loss Curves (All Folds)\n",
        "# # -----------------------\n",
        "# plt.figure(figsize=(14,6))\n",
        "# # Accuracy\n",
        "# plt.subplot(1,2,1)\n",
        "# for i, hist in enumerate(histories, 1):\n",
        "#     plt.plot(hist['accuracy'], label=f'Fold {i} Train Acc')\n",
        "#     plt.plot(hist['val_accuracy'], label=f'Fold {i} Val Acc')\n",
        "# plt.title(\"Model Accuracy (All Folds)\")\n",
        "# plt.xlabel(\"Epoch\")\n",
        "# plt.ylabel(\"Accuracy\")\n",
        "# plt.legend(fontsize=7, ncol=2)\n",
        "# plt.savefig('total_accuracy_curve.png', dpi=300)\n",
        "# # Loss\n",
        "# plt.subplot(1,2,2)\n",
        "# for i, hist in enumerate(histories, 1):\n",
        "#     plt.plot(hist['loss'], label=f'Fold {i} Train Loss')\n",
        "#     plt.plot(hist['val_loss'], label=f'Fold {i} Val Loss')\n",
        "# plt.title(\"Model Loss (All Folds)\")\n",
        "# plt.xlabel(\"Epoch\")\n",
        "# plt.ylabel(\"Loss\")\n",
        "# plt.legend(fontsize=7, ncol=2)\n",
        "# plt.tight_layout()\n",
        "# plt.savefig('total_loss_curve.png', dpi=300)\n",
        "# plt.show()\n",
        "\n",
        "# # -----------------------\n",
        "# # Final Summary\n",
        "# # -----------------------\n",
        "# metrics_df = pd.DataFrame(fold_metrics).round(2)\n",
        "# metrics_df.to_csv(\"kfold_summary_metrics.csv\", index=False)\n",
        "# print(\"\\nâœ… K-Fold Summary Table:\")\n",
        "# display(metrics_df)\n",
        "\n",
        "# print(\"\\nâœ… Cross-validation results:\")\n",
        "# print(f\"Accuracy: {np.mean(acc_per_fold):.2f}% (+/- {np.std(acc_per_fold):.2f})\")\n",
        "# print(f\"Loss: {np.mean(loss_per_fold):.4f}\")\n",
        "# print(f\"Cohen's Kappa: {np.mean(kappa_per_fold):.4f}\")\n",
        "# print(f\"Specificity: {np.mean(specificity_per_fold):.4f}\")\n",
        "# print(f\"ROC-AUC: {np.mean(roc_auc_per_fold):.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "nOg4Qh-IuYWI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "_gei34fVuYWJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "qfGX0Y4MuYWJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # --- Accuracy & Loss Together ---\n",
        "# plt.figure(figsize=(10,4))\n",
        "\n",
        "# # Accuracy subplot\n",
        "# plt.subplot(1,2,1)\n",
        "# for i, hist in enumerate(histories, 1):\n",
        "#     plt.plot(hist['accuracy'], label=f'Fold {i} Train Acc')\n",
        "#     plt.plot(hist['val_accuracy'], label=f'Fold {i} Val Acc')\n",
        "# plt.title(\"Model Accuracy (All Folds)\")\n",
        "# plt.xlabel(\"Epoch\")\n",
        "# plt.ylabel(\"Accuracy\")\n",
        "# plt.legend(fontsize=7, ncol=2)\n",
        "\n",
        "# # Loss subplot\n",
        "# plt.subplot(1,2,2)\n",
        "# for i, hist in enumerate(histories, 1):\n",
        "#     plt.plot(hist['loss'], label=f'Fold {i} Train Loss')\n",
        "#     plt.plot(hist['val_loss'], label=f'Fold {i} Val Loss')\n",
        "# plt.title(\"Model Loss (All Folds)\")\n",
        "# plt.xlabel(\"Epoch\")\n",
        "# plt.ylabel(\"Loss\")\n",
        "# plt.legend(fontsize=7, ncol=2)\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.savefig('accuracy_loss_curves.png', dpi=300)   # Save combined figure\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# # --- Accuracy Only ---\n",
        "# plt.figure()\n",
        "# for i, hist in enumerate(histories, 1):\n",
        "#     plt.plot(hist['accuracy'], label=f'Fold {i} Train Acc')\n",
        "#     plt.plot(hist['val_accuracy'], label=f'Fold {i} Val Acc')\n",
        "# plt.title(\"Model Accuracy (All Folds)\")\n",
        "# plt.xlabel(\"Epoch\")\n",
        "# plt.ylabel(\"Accuracy\")\n",
        "# plt.legend(fontsize=7, ncol=2)\n",
        "# plt.savefig('only_accuracy_curve.png', dpi=300)\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# # --- Loss Only ---\n",
        "# plt.figure()\n",
        "# for i, hist in enumerate(histories, 1):\n",
        "#     plt.plot(hist['loss'], label=f'Fold {i} Train Loss')\n",
        "#     plt.plot(hist['val_loss'], label=f'Fold {i} Val Loss')\n",
        "# plt.title(\"Model Loss (All Folds)\")\n",
        "# plt.xlabel(\"Epoch\")\n",
        "# plt.ylabel(\"Loss\")\n",
        "# plt.legend(fontsize=7, ncol=2)\n",
        "# plt.savefig('only_loss_curve.png', dpi=300)\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "HPdF-PhfuYWJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "jYJXKlPWuYWK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "7PMwIcwNuYWK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "oaqT8KcNuYWK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "5eQA9-diuYWg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ------------------------\n",
        "# Predict the probabilities\n",
        "# ------------------------\n",
        "y_prob = model.predict(X_val)  # Predicted probabilities for each class using the validation data\n",
        "\n",
        "# ------------------------\n",
        "# One-hot encode the true labels for multiclass\n",
        "# ------------------------\n",
        "from sklearn.preprocessing import label_binarize\n",
        "y_val_bin = label_binarize(y_val, classes=[0, 1, 2, 3])  # One-hot encoding for multiclass\n",
        "\n",
        "# ------------------------\n",
        "# Calculate ROC and AUC for each class\n",
        "# ------------------------\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "fpr, tpr, roc_auc = dict(), dict(), dict()\n",
        "num_classes = len(np.unique(y_val))  # Adjust to the number of classes\n",
        "\n",
        "# Compute ROC curve and AUC for each class\n",
        "for i in range(num_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_val_bin[:, i], y_prob[:, i])\n",
        "    roc_auc[i] = roc_auc_score(y_val_bin[:, i], y_prob[:, i])\n",
        "\n",
        "# ------------------------\n",
        "# Plot ROC Curves for each class\n",
        "# ------------------------\n",
        "plt.figure(figsize=(8, 6))\n",
        "for i in range(num_classes):\n",
        "    plt.plot(fpr[i], tpr[i], label=f'Class {i+1} (AUC = {roc_auc[i]:0.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic Curve (ROC Curve)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.savefig('ROC_curve.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# ------------------------\n",
        "# Print AUC scores for each class\n",
        "# ------------------------\n",
        "for i in range(num_classes):\n",
        "    print(f\"Class {i+1} AUC: {roc_auc[i]:0.2f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "fMaBuYayuYWg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/kaggle/working/my_model.keras\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "xK4V0iKouYWh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/kaggle/working/my_model.h5\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "pGsfrB3LuYWh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "h2jcearvuYWh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "lRGlUotYuYWi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "SW7Us7apuYWi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "L4856pnzuYWi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model in native Keras format\n",
        "model.save(\"/kaggle/working/my_model.keras\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "kHPUWy_huYWi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "\n",
        "# Select a few background images (used for SHAP masking)\n",
        "background = X_train[:50]  # small subset to save time\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "MmlSIcvpuYWj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# 1. Imports\n",
        "# =========================================\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import shap\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# =========================================\n",
        "# 2. Dataset split\n",
        "# =========================================\n",
        "# Assuming X, y already loaded (images & labels)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Train: {X_train.shape}, Val: {X_val.shape}\")\n",
        "\n",
        "# =========================================\n",
        "# 3. Model Definition (Hybrid CNN + ViT + GRU)\n",
        "# =========================================\n",
        "input_shape = (160, 160, 3)\n",
        "patch_size = 16\n",
        "num_patches = (input_shape[0] // patch_size) * (input_shape[1] // patch_size)\n",
        "projection_dim = 64\n",
        "transformer_layers = 4\n",
        "num_heads = 4\n",
        "num_classes = 4\n",
        "\n",
        "# ---- Patches Layer ----\n",
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches\n",
        "\n",
        "# ---- Patch Encoder ----\n",
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patches):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patches) + self.position_embedding(positions)\n",
        "        return encoded\n",
        "\n",
        "# ---- Build Hybrid Model ----\n",
        "def build_hybrid_model():\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # CNN Branch\n",
        "    x_cnn = layers.Conv2D(32, (3,3), activation='relu', padding='same')(inputs)\n",
        "    x_cnn = layers.MaxPooling2D((2,2))(x_cnn)\n",
        "    x_cnn = layers.Conv2D(64, (3,3), activation='relu', padding='same')(x_cnn)\n",
        "    x_cnn = layers.MaxPooling2D((2,2))(x_cnn)\n",
        "    x_cnn = layers.Conv2D(128, (3,3), activation='relu', padding='same')(x_cnn)\n",
        "    x_cnn = layers.MaxPooling2D((2,2))(x_cnn)\n",
        "    x_cnn = layers.Flatten()(x_cnn)\n",
        "\n",
        "    # ViT + GRU Branch\n",
        "    x_vit = layers.Rescaling(1./255)(inputs)\n",
        "    patches = Patches(patch_size)(x_vit)\n",
        "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "\n",
        "    for _ in range(transformer_layers):\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.2\n",
        "        )(x1, x1)\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    x_vit = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    x_vit = layers.Dropout(0.02)(x_vit)\n",
        "    x_vit = layers.Flatten()(x_vit)\n",
        "    x_vit = layers.Reshape((-1, x_vit.shape[-1]))(x_vit)\n",
        "    x_vit = layers.GRU(256)(x_vit)\n",
        "\n",
        "    # Concatenate CNN + ViT-GRU\n",
        "    x = layers.concatenate([x_cnn, x_vit])\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.Dropout(0.03)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "model = build_hybrid_model()\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# =========================================\n",
        "# 4. Train Model (quick run)\n",
        "# =========================================\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=3,   # change to 50+ for real training\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# =========================================\n",
        "# 5. SHAP Explanations\n",
        "# =========================================\n",
        "# Take background images\n",
        "background = X_train[:50]\n",
        "\n",
        "# Create SHAP masker\n",
        "masker = shap.maskers.Image(\"inpaint_telea\", X_train[0].shape)\n",
        "\n",
        "# Build SHAP explainer\n",
        "explainer = shap.Explainer(model, masker, output_names=[f\"class_{i}\" for i in range(num_classes)])\n",
        "\n",
        "# Select test images\n",
        "test_images = X_val[:5]\n",
        "\n",
        "# Compute SHAP values\n",
        "shap_values = explainer(test_images)\n",
        "\n",
        "# =========================================\n",
        "# 6. Visualization\n",
        "# =========================================\n",
        "# Show SHAP for predicted class of each image\n",
        "preds = model.predict(test_images)\n",
        "pred_classes = np.argmax(preds, axis=1)\n",
        "\n",
        "for i, img in enumerate(test_images):\n",
        "    class_idx = pred_classes[i]\n",
        "    print(f\"Image {i} predicted as class {class_idx}\")\n",
        "    shap.image_plot(shap_values.values[..., class_idx][i:i+1], img[np.newaxis])\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "XZuQX6IDuYWj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create SHAP image masker\n",
        "masker = shap.maskers.Image(\"inpaint_telea\", X_train[0].shape)\n",
        "\n",
        "# Create explainer for your Keras model\n",
        "explainer = shap.Explainer(model, masker, output_names=[str(i) for i in range(num_classes)])\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "9E-x95OKuYWj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "pNhRMKhBuYWj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from lime import lime_image\n",
        "from skimage.segmentation import mark_boundaries\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "b3ueTQgxuYWk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from lime import lime_image\n",
        "from skimage.segmentation import mark_boundaries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "NAkiknlNuYWk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import register_keras_serializable\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "\n",
        "@register_keras_serializable()\n",
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size, **kwargs):  # accept **kwargs\n",
        "        super(Patches, self).__init__(**kwargs)  # pass kwargs to Layer\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Patches, self).get_config()\n",
        "        config.update({\"patch_size\": self.patch_size})\n",
        "        return config\n",
        "\n",
        "\n",
        "@register_keras_serializable()\n",
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim, **kwargs):\n",
        "        super(PatchEncoder, self).__init__(**kwargs)\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patches):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patches) + self.position_embedding(positions)\n",
        "        return encoded\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(PatchEncoder, self).get_config()\n",
        "        config.update({\n",
        "            \"num_patches\": self.num_patches,\n",
        "        })\n",
        "        return config\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "5IbJScMsuYWk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/kaggle/working/my_model_fixed.keras\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "pcPVGnK4uYWl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\n",
        "    \"/kaggle/working/my_model_fixed.keras\",\n",
        "    custom_objects={\"Patches\": Patches, \"PatchEncoder\": PatchEncoder}\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "F3pIM-_fuYWl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.segmentation import mark_boundaries\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from lime import lime_image\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Prediction function (same normalization used during training)\n",
        "# -----------------------------\n",
        "def predict_fn(images):\n",
        "    images = images.astype('float32') / 255.0\n",
        "    return model.predict(images)\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Load single image\n",
        "# -----------------------------\n",
        "img_path = \"/kaggle/input/brain-tumor-dataset-add/Brain tumor_Add/pituitary/Tr-pi_0022.jpg\"\n",
        "img = image.load_img(img_path, target_size=(160,160))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Run explainer\n",
        "# -----------------------------\n",
        "explainer = lime_image.LimeImageExplainer()\n",
        "explanation = explainer.explain_instance(\n",
        "    img_array[0].astype('double'),\n",
        "    predict_fn,\n",
        "    top_labels=4,\n",
        "    hide_color=0,\n",
        "    num_samples=1000\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Model output\n",
        "# -----------------------------\n",
        "probs = predict_fn(img_array)[0]\n",
        "predicted_class = np.argmax(probs)\n",
        "\n",
        "print(\"Input Image Path:\", img_path)\n",
        "print(\"Predicted Class:\", predicted_class)\n",
        "print(\"Class Probabilities:\", probs)\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Top contributing features (with weights)\n",
        "# -----------------------------\n",
        "# explanation.local_exp is a dict: {class_label: [(superpixel_id, weight), ...]}\n",
        "exp_weights = explanation.local_exp[predicted_class]\n",
        "\n",
        "print(\"\\nTop contributing features for class\", predicted_class, \":\")\n",
        "for superpixel_id, weight in exp_weights[:10]:   # top 10\n",
        "    print(f\"Superpixel {superpixel_id}: {weight:.4f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 6. Visualization\n",
        "# -----------------------------\n",
        "temp, mask = explanation.get_image_and_mask(\n",
        "    label=predicted_class,\n",
        "    positive_only=False,\n",
        "    hide_rest=False,\n",
        "    num_features=10,\n",
        "    min_weight=0.0\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.title(\"Original Image\")\n",
        "plt.imshow(img_array[0].astype('uint8'))\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.title(\"LIME Explanation\")\n",
        "plt.imshow(mark_boundaries(temp.astype('uint8'), mask))\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "bgIb4QNquYWl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "vkQWnU3zuYWl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_fn(images):\n",
        "    # Normalize images same as during training (ViT branch)\n",
        "    images = images.astype('float32') / 255.0\n",
        "    return model.predict(images)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "WJhSaUwzuYWm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "xAPVTpc6uYWm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: load a single image from dataset\n",
        "img_path = \"/kaggle/input/brain-tumor-dataset-add/Brain tumor_Add/glioma/Tr-gl_0016.jpg\"\n",
        "img = image.load_img(img_path, target_size=(128,128))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "tL_P8inXuYWm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = lime_image.LimeImageExplainer()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "AOHpSAViuYWm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "explanation = explainer.explain_instance(\n",
        "    img_array[0].astype('double'),  # single image\n",
        "    predict_fn,                     # prediction function\n",
        "    top_labels=4,                   # number of classes\n",
        "    hide_color=0,\n",
        "    num_samples=1000                # number of perturbed samples\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "S7GhU7mbuYWn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose the class predicted by the model\n",
        "predicted_class = np.argmax(model.predict(img_array))\n",
        "\n",
        "# Get the image with explanation\n",
        "temp, mask = explanation.get_image_and_mask(\n",
        "    label=predicted_class,\n",
        "    positive_only=False,\n",
        "    hide_rest=False,\n",
        "    num_features=10,\n",
        "    min_weight=0.0\n",
        ")\n",
        "\n",
        "# Show the original and highlighted image\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.title(\"Original Image\")\n",
        "plt.imshow(img_array[0].astype('uint8'))\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.title(\"LIME Explanation\")\n",
        "plt.imshow(mark_boundaries(temp.astype('uint8'), mask))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "H6SkKZq0uYWn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "dyx-9UYJuYWn"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}