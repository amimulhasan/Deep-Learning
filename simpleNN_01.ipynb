{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c485b307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77bb47a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │            \u001b[38;5;34m50\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m55\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111</span> (444.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m111\u001b[0m (444.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111</span> (444.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111\u001b[0m (444.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=Sequential([\n",
    "    Dense(10,activation='relu',input_shape=(4,)),\n",
    "    Dense(5,activation='relu'),\n",
    "    Dense(1,activation='sigmoid')\n",
    "    \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d91840a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │            \u001b[38;5;34m50\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m11\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">61</span> (244.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m61\u001b[0m (244.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">61</span> (244.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m61\u001b[0m (244.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model=Sequential([\n",
    "    tf.keras.layers.Dense(10,activation='relu',input_shape=(4,)),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "    \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f889f192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97304356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum:[4. 6.]\n",
      "Dot_product:11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a=tf.constant([1.0, 2.0])\n",
    "b=tf.constant([3.0,4.0])\n",
    "sum_result=tf.add(a,b)\n",
    "dot_product=tf.tensordot(a,b,axes=1)\n",
    "print(f\"sum:{sum_result}\")\n",
    "print(f\"Dot_product:{dot_product}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "231391ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output : tf.Tensor(\n",
      "[[2.3835514 0.       ]\n",
      " [4.78417   0.       ]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "class SimpleNN(tf.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN,self).__init__()\n",
    "        #self.b=tf.Variable(tf.zeros([2]),name='bias')\n",
    "        \n",
    "        self.w=tf.Variable(tf.random.normal([2,2]),name='weight')\n",
    "        self.b=tf.Variable(tf.zeros([2]),name='bias')\n",
    "    def __call__(self,x):\n",
    "        \n",
    "        return tf.nn.relu(tf.matmul(x,self.w)+self.b)\n",
    "        \n",
    "model=SimpleNN()\n",
    "input_data=tf.constant([[1.0, 2.0],[3.0,4.0]])\n",
    "output=model(input_data)\n",
    "print('output :',output)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddd2d446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tf.Tensor(\n",
      "[[1.6494393  0.        ]\n",
      " [4.7399616  0.21350467]], shape=(2, 2), dtype=float32)\n",
      "\n",
      "Trainable Parameters:\n",
      "Weights (w):\n",
      "[[ 1.441083    0.369855  ]\n",
      " [ 0.10417816 -0.22401509]]\n",
      "Biases (b):\n",
      "[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define a simple neural network using TensorFlow's low-level API\n",
    "class SimpleNN(tf.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.w = tf.Variable(tf.random.normal([2, 2]), name=\"weight\")  # Weight matrix\n",
    "        self.b = tf.Variable(tf.zeros([2]), name=\"bias\")  # Bias vector\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return tf.nn.relu(tf.matmul(x, self.w) + self.b)  # ReLU activation\n",
    "\n",
    "# Create a model and test it\n",
    "model = SimpleNN()\n",
    "input_data = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "output = model(input_data)\n",
    "\n",
    "# Output result from model\n",
    "print(\"Output:\", output)\n",
    "\n",
    "# Display trainable parameters\n",
    "print(\"\\nTrainable Parameters:\")\n",
    "print(\"Weights (w):\")\n",
    "print(model.w.numpy())  # Display weight matrix\n",
    "print(\"Biases (b):\")\n",
    "print(model.b.numpy())  # Display bias vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30cbacd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum:tensor([6., 8.])\n",
      "Dot Product:23.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.tensor([2.0, 3.0])\n",
    "b=torch.tensor([4.0, 5.0])\n",
    "#sum_result=a+b\n",
    "sum_result=torch.add(a,b)\n",
    "dot_product=torch.dot(a,b)\n",
    "print(f'sum:{sum_result}')\n",
    "print(f'Dot Product:{dot_product}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "62bb74e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture:\n",
      "simpleNN(\n",
      "  (fc1): Linear(in_features=4, out_features=10, bias=True)\n",
      "  (fc2): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "output:tensor([[0.5970]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "trainable parameters:\n",
      "fc1.weight:|ntensor([[-0.2850, -0.2494,  0.0773, -0.4540],\n",
      "        [ 0.3889, -0.2398,  0.0011, -0.1541],\n",
      "        [ 0.3573,  0.3061, -0.0304,  0.4465],\n",
      "        [-0.3518,  0.2835,  0.1803, -0.1244],\n",
      "        [-0.2647,  0.1653,  0.3849,  0.2066],\n",
      "        [ 0.0936,  0.0009, -0.4074,  0.4045],\n",
      "        [ 0.3644,  0.4345,  0.1493, -0.4855],\n",
      "        [-0.2075,  0.2925,  0.2669,  0.0583],\n",
      "        [-0.1053, -0.2854,  0.1859, -0.4034],\n",
      "        [ 0.3536, -0.3174,  0.2948,  0.4085]])\n",
      "fc1.bias:|ntensor([-0.2826,  0.0497,  0.0016,  0.1361, -0.3554, -0.1606,  0.4722,  0.1031,\n",
      "        -0.0968, -0.4209])\n",
      "fc2.weight:|ntensor([[-0.3119,  0.2271,  0.2256, -0.1111, -0.3137, -0.3089,  0.2558,  0.1615,\n",
      "         -0.2733,  0.1546]])\n",
      "fc2.bias:|ntensor([-0.0203])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "#Defin a simple nural network\n",
    "class simpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simpleNN,self).__init__()\n",
    "        self.fc1=nn.Linear(4,10) #Hidden layers\n",
    "        self.fc2=nn.Linear(10,1)#output layers\n",
    "    def forward(self,x):\n",
    "        x=torch.relu(self.fc1(x))\n",
    "        x=torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "model=simpleNN()\n",
    "print('Model architecture:')\n",
    "print(model)\n",
    "input_data=torch.rand(1,4)\n",
    "output=model(input_data)\n",
    "print(f\"\\noutput:{output}\")\n",
    "print(f'\\ntrainable parameters:')\n",
    "for name,param in model.named_parameters():\n",
    "    print(f'{name}:|n{param.data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b5ae9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a353fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris()\n",
    "x=iris.data\n",
    "y=iris.target\n",
    "x\n",
    "y\n",
    "encoder=OneHotEncoder()\n",
    "y=encoder.fit_transform(y.reshape(-1,1))\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "scaler=StandardScaler()\n",
    "x_train=scaler.fit_transform(x_train)\n",
    "x_test=scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7195fe56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\New folder\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Failed to convert elements of SparseTensor(indices=Tensor(\"data_1:0\", shape=(None, 2), dtype=int64), values=Tensor(\"data_2:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"data_3:0\", shape=(2,), dtype=int64)) to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#build in model\u001b[39;00m\n\u001b[0;32m     16\u001b[0m model_sigmoid\u001b[38;5;241m=\u001b[39mbuild_model_sigmoid()\n\u001b[1;32m---> 17\u001b[0m history_sigmoid\u001b[38;5;241m=\u001b[39m\u001b[43mmodel_sigmoid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m test_loss_sigmoid, test_acc_sigmoid \u001b[38;5;241m=\u001b[39m model_sigmoid\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy (All Sigmoid): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc_sigmoid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\New folder\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\New folder\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:544\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[1;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcategorical_crossentropy\u001b[39m(target, output, from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    506\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Categorical crossentropy between an output tensor and a target tensor.\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \n\u001b[0;32m    508\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;124;03m    [0. 0. 0.]\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 544\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    545\u001b[0m     output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(output)\n\u001b[0;32m    547\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: Failed to convert elements of SparseTensor(indices=Tensor(\"data_1:0\", shape=(None, 2), dtype=int64), values=Tensor(\"data_2:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"data_3:0\", shape=(2,), dtype=int64)) to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes."
     ]
    }
   ],
   "source": [
    "# Define a simple neural network using Sigmoid activation in all layers\n",
    "def build_model_sigmoid():\n",
    "    model=Sequential([\n",
    "        Dense(10,activation='sigmoid',input_shape=(4,)),\n",
    "        #hidden layer\n",
    "        Dense(10,activation='sigmoid'),\n",
    "        Dense(3,activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "#build in model\n",
    "model_sigmoid=build_model_sigmoid()\n",
    "history_sigmoid=model_sigmoid.fit(x_train,y_train,epochs=50,validation_data=(x_test,y_test),verbose=2)\n",
    "test_loss_sigmoid, test_acc_sigmoid = model_sigmoid.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Test Accuracy (All Sigmoid): {test_acc_sigmoid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47417eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple neural network using ReLU activation in all layers\n",
    "def build_model_relu():\n",
    "    model = Sequential([\n",
    "        Dense(10, activation='relu', input_shape=(4,)),  # Hidden layer with ReLU\n",
    "        Dense(10, activation='relu'),  # Another hidden layer with ReLU\n",
    "        Dense(3, activation='softmax')  # Output layer with softmax for classification\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "model_relu = build_model_relu()\n",
    "\n",
    "# Train the model\n",
    "history_relu = model_relu.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss_relu, test_acc_relu = model_relu.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Test Accuracy (All ReLU): {test_acc_relu}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f114e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "# Define a simple neural network using Leaky ReLU activation in all layers\n",
    "def build_model_leaky_relu():\n",
    "    model = Sequential([\n",
    "        Dense(10, input_shape=(4,)),  # First hidden layer without activation, add LeakyReLU separately\n",
    "        LeakyReLU(alpha=0.01),  # Leaky ReLU activation with small slope for negative values\n",
    "        Dense(10),  # Second hidden layer\n",
    "        LeakyReLU(alpha=0.01),  # Leaky ReLU activation\n",
    "        Dense(3, activation='softmax')  # Output layer with softmax for classification\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Build the model with Leaky ReLU\n",
    "model_leaky_relu = build_model_leaky_relu()\n",
    "\n",
    "# Train the model\n",
    "history_leaky_relu = model_leaky_relu.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss_leaky_relu, test_acc_leaky_relu = model_leaky_relu.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Test Accuracy (Leaky ReLU): {test_acc_leaky_relu}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42237ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(history_sigmoid.history['accuracy'], label='Sigmoid Accuracy')\n",
    "plt.plot(history_relu.history['accuracy'], label='ReLU Accuracy')\n",
    "plt.plot(history_leaky_relu.history['accuracy'], label='Leaky ReLU Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f430d971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
