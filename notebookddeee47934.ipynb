{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13874549,"sourceType":"datasetVersion","datasetId":8839794}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        (os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-12T08:50:42.264126Z","iopub.execute_input":"2025-12-12T08:50:42.264419Z","iopub.status.idle":"2025-12-12T08:50:46.249919Z","shell.execute_reply.started":"2025-12-12T08:50:42.264383Z","shell.execute_reply":"2025-12-12T08:50:46.249077Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Run this cell if packages missing (Kaggle/Colab)\n!pip install timm==0.9.2 albumentations==1.4.3 opencv-python scikit-image\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T08:50:46.251040Z","iopub.execute_input":"2025-12-12T08:50:46.251417Z","iopub.status.idle":"2025-12-12T08:52:18.736411Z","shell.execute_reply.started":"2025-12-12T08:50:46.251396Z","shell.execute_reply":"2025-12-12T08:52:18.735656Z"}},"outputs":[{"name":"stdout","text":"Collecting timm==0.9.2\n  Downloading timm-0.9.2-py3-none-any.whl.metadata (68 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting albumentations==1.4.3\n  Downloading albumentations-1.4.3-py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\nRequirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\nRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.11/dist-packages (from timm==0.9.2) (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm==0.9.2) (0.21.0+cu124)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm==0.9.2) (6.0.3)\nRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from timm==0.9.2) (0.36.0)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm==0.9.2) (0.5.3)\nRequirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.3) (1.26.4)\nRequirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.3) (1.15.3)\nRequirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.3) (4.15.0)\nCollecting scikit-learn>=1.3.2 (from albumentations==1.4.3)\n  Downloading scikit_learn-1.8.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: opencv-python-headless>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.3) (4.12.0.88)\nCollecting numpy>=1.24.4 (from albumentations==1.4.3)\n  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.5)\nRequirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (11.3.0)\nRequirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\nRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.6.11)\nRequirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (25.0)\nRequirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\nRequirement already satisfied: joblib>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.3) (1.5.2)\nRequirement already satisfied: threadpoolctl>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.3) (3.6.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.9.2) (3.20.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.9.2) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.9.2) (2025.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.7->timm==0.9.2)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.7->timm==0.9.2)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.7->timm==0.9.2)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.7->timm==0.9.2)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.7->timm==0.9.2)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.7->timm==0.9.2)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.7->timm==0.9.2)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.7->timm==0.9.2)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.7->timm==0.9.2)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.9.2) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.9.2) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.9.2) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.7->timm==0.9.2)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.9.2) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.9.2) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7->timm==0.9.2) (1.3.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->timm==0.9.2) (2.32.5)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->timm==0.9.2) (4.67.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->timm==0.9.2) (1.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.7->timm==0.9.2) (3.0.3)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->timm==0.9.2) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->timm==0.9.2) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->timm==0.9.2) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->timm==0.9.2) (2025.10.5)\nDownloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading albumentations-1.4.3-py3-none-any.whl (137 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.0/137.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading scikit_learn-1.8.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (9.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m118.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, scikit-learn, nvidia-cusolver-cu12, albumentations, timm\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: albumentations\n    Found existing installation: albumentations 2.0.8\n    Uninstalling albumentations-2.0.8:\n      Successfully uninstalled albumentations-2.0.8\n  Attempting uninstall: timm\n    Found existing installation: timm 1.0.19\n    Uninstalling timm-1.0.19:\n      Successfully uninstalled timm-1.0.19\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nmkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nmkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nmkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nnumba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\ndatasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.6 which is incompatible.\ncategory-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.8.0 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nsklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.8.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ntensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\ntensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed albumentations-1.4.3 numpy-2.2.6 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 scikit-learn-1.8.0 timm-0.9.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Cell 2\nimport os, sys, time\nfrom glob import glob\nfrom pathlib import Path\nfrom typing import List, Tuple, Optional\nimport numpy as np\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nimport timm\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nfrom skimage.filters import threshold_otsu\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T08:52:18.737419Z","iopub.execute_input":"2025-12-12T08:52:18.737657Z","iopub.status.idle":"2025-12-12T08:52:31.791194Z","shell.execute_reply.started":"2025-12-12T08:52:18.737635Z","shell.execute_reply":"2025-12-12T08:52:31.790553Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Cell 3 - EDIT THESE\nCONFIG = {\n    'DATA_DIR': '/kaggle/input/x-ray-images/images',  # change to your dataset root\n    'IMG_EXTS': ('.png', '.jpg', '.jpeg'),\n    'IMG_SIZE': 256,\n    'NUM_CLASSES': 4,   # include background, e.g., 0=bg,1=class1,2=class2,3=class3\n    'BATCH_SIZE': 8,\n    'EPOCHS': 20,\n    'LR': 1e-4,\n    'DEVICE': 'cuda' if torch.cuda.is_available() else 'cpu',\n    'BACKBONE': 'swin_tiny_patch4_window7_224',  # smaller by default\n    'PRETRAINED': True,\n    'CHECKPOINT_DIR': './checkpoints',\n    'MODE': 'auto_mask'   # we will autogenerate masks\n}\nos.makedirs(CONFIG['CHECKPOINT_DIR'], exist_ok=True)\n# Where to save generated masks\nGENERATED_MASKS_DIR = os.path.join(CONFIG['DATA_DIR'], 'masks_auto')\nos.makedirs(GENERATED_MASKS_DIR, exist_ok=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T08:52:31.793118Z","iopub.execute_input":"2025-12-12T08:52:31.793957Z","iopub.status.idle":"2025-12-12T08:52:31.937901Z","shell.execute_reply.started":"2025-12-12T08:52:31.793934Z","shell.execute_reply":"2025-12-12T08:52:31.936741Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/95513279.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Where to save generated masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mGENERATED_MASKS_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DATA_DIR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'masks_auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGENERATED_MASKS_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/lib/python3.11/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/kaggle/input/x-ray-images/images/masks_auto'"],"ename":"OSError","evalue":"[Errno 30] Read-only file system: '/kaggle/input/x-ray-images/images/masks_auto'","output_type":"error"}],"execution_count":4},{"cell_type":"code","source":"# Cell 4\ndef collect_images(root_dir: str, exts=('.png','.jpg','.jpeg')) -> List[str]:\n    p = Path(root_dir)\n    files = []\n    for ext in exts:\n        files += [str(x) for x in p.rglob(f'*{ext}')]\n    files = sorted(files)\n    return files\n\ndef read_image(path: str, size: int) -> np.ndarray:\n    img = cv2.imread(path)\n    if img is None:\n        raise FileNotFoundError(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (size, size), interpolation=cv2.INTER_LINEAR)\n    return img\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T08:52:31.938371Z","iopub.status.idle":"2025-12-12T08:52:31.938670Z","shell.execute_reply.started":"2025-12-12T08:52:31.938507Z","shell.execute_reply":"2025-12-12T08:52:31.938519Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 5\nfrom sklearn.cluster import KMeans\n\ndef generate_pseudo_mask(img: np.ndarray, num_classes: int) -> np.ndarray:\n    \"\"\"\n    Returns HxW mask with integer labels in [0, num_classes-1].\n    Uses Otsu for coarse foreground/background, then kmeans on color for multiclass.\n    \"\"\"\n    h, w, _ = img.shape\n    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    try:\n        t = threshold_otsu(gray)\n        bin_mask = (gray > t).astype(np.uint8)\n    except Exception:\n        _, bin_mask = cv2.threshold(gray, 0, 1, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n\n    # clean\n    kernel = np.ones((5,5), np.uint8)\n    clean = cv2.morphologyEx(bin_mask.astype(np.uint8), cv2.MORPH_OPEN, kernel)\n    clean = cv2.morphologyEx(clean, cv2.MORPH_CLOSE, kernel)\n\n    if num_classes == 2:\n        return clean.astype(np.uint8)\n\n    # For multi-class, run KMeans on RGB of foreground pixels + assign labels\n    Z = img.reshape(-1, 3).astype(np.float32)\n    K = num_classes\n    # if dataset small, KMeans can be slow; use sample\n    sample_idx = np.random.choice(Z.shape[0], min(20000, Z.shape[0]), replace=False)\n    km = KMeans(n_clusters=K, n_init=3, random_state=42)\n    km.fit(Z[sample_idx])\n\n    labels = km.predict(Z).reshape(h, w).astype(np.uint8)\n\n    # choose cluster with lowest mean intensity as background\n    centers = km.cluster_centers_\n    center_means = centers.mean(axis=1)\n    bg_cluster = int(np.argmin(center_means))\n\n    remapped = np.zeros_like(labels)\n    cur = 1\n    for c in range(K):\n        if c == bg_cluster:\n            remapped[labels==c] = 0\n        else:\n            remapped[labels==c] = cur\n            cur += 1\n            if cur >= num_classes:\n                # wrap if more clusters than expected\n                cur = num_classes - 1\n    return remapped.astype(np.uint8)\n\ndef save_mask(mask: np.ndarray, out_path: str):\n    # save mask as single-channel PNG with values 0..(C-1)\n    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n    # ensure dtype uint8\n    cv2.imwrite(out_path, mask.astype(np.uint8))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T08:52:31.939987Z","iopub.status.idle":"2025-12-12T08:52:31.940307Z","shell.execute_reply.started":"2025-12-12T08:52:31.940142Z","shell.execute_reply":"2025-12-12T08:52:31.940157Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 6\nimages = collect_images(CONFIG['DATA_DIR'], CONFIG['IMG_EXTS'])\nprint(f\"Found {len(images)} images\")\n\n# If images are inside e.g., /Training/glioma/..., they will be included.\n# We'll generate masks into GENERATED_MASKS_DIR preserving filenames.\nfor i, img_path in enumerate(images):\n    fname = os.path.basename(img_path)\n    out_mask = os.path.join(GENERATED_MASKS_DIR, fname)\n    if os.path.exists(out_mask):\n        if i % 200 == 0:\n            print(f\"[{i}] mask exists, skip: {fname}\")\n        continue\n    img = read_image(img_path, CONFIG['IMG_SIZE'])\n    mask = generate_pseudo_mask(img, CONFIG['NUM_CLASSES'])\n    save_mask(mask, out_mask)\n    if i % 200 == 0:\n        print(f\"[{i}] saved mask: {fname}\")\nprint(\"Mask generation finished. Masks saved to:\", GENERATED_MASKS_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T08:52:31.941196Z","iopub.status.idle":"2025-12-12T08:52:31.941435Z","shell.execute_reply.started":"2025-12-12T08:52:31.941301Z","shell.execute_reply":"2025-12-12T08:52:31.941310Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 7\nclass MedicalSegDataset(Dataset):\n    def __init__(self, image_paths: List[str], mask_dir: str, img_size:int=256, transform=None):\n        self.image_paths = image_paths\n        self.mask_dir = mask_dir\n        self.img_size = img_size\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        fname = os.path.basename(img_path)\n        mask_path = os.path.join(self.mask_dir, fname)\n\n        img = read_image(img_path, self.img_size)\n        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n        if mask is None:\n            # fallback to zeros\n            mask = np.zeros((self.img_size, self.img_size), dtype=np.uint8)\n\n        if self.transform:\n            aug = self.transform(image=img, mask=mask)\n            img = aug['image']\n            mask = aug['mask']\n        else:\n            img = torch.from_numpy(img.transpose(2,0,1)).float() / 255.0\n            mask = torch.from_numpy(mask).long()\n\n        return img, mask\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T08:52:31.942368Z","iopub.status.idle":"2025-12-12T08:52:31.942679Z","shell.execute_reply.started":"2025-12-12T08:52:31.942515Z","shell.execute_reply":"2025-12-12T08:52:31.942547Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 8\nclass ConvBlock(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n        )\n    def forward(self,x): return self.conv(x)\n\nclass UpConv(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super().__init__()\n        self.up = nn.Sequential(\n            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n            ConvBlock(in_ch, out_ch)\n        )\n    def forward(self,x): return self.up(x)\n\nclass SwinGRUSegmenter(nn.Module):\n    def __init__(self, backbone_name='swin_tiny_patch4_window7_224', pretrained=True, num_classes=4):\n        super().__init__()\n        self.backbone = timm.create_model(backbone_name, pretrained=pretrained, features_only=True, out_indices=(0,1,2,3))\n        feats = self.backbone.feature_info.channels()\n        self.reduce4 = nn.Conv2d(feats[-1], 512, 1)\n        self.reduce3 = nn.Conv2d(feats[-2], 256, 1)\n        self.reduce2 = nn.Conv2d(feats[-3], 128, 1)\n        self.reduce1 = nn.Conv2d(feats[-4], 64, 1)\n        self.gru_in_dim = feats[-2]\n        self.gru = nn.GRU(input_size=self.gru_in_dim, hidden_size=256, batch_first=True)\n        self.gru_proj = nn.Linear(256, 256)\n        self.dec4 = ConvBlock(512,256)\n        self.up3 = UpConv(256+256, 128)\n        self.up2 = UpConv(128+128, 64)\n        self.up1 = UpConv(64+64, 32)\n        self.final_conv = nn.Sequential(nn.Conv2d(32,32,3,padding=1), nn.ReLU(inplace=True), nn.Conv2d(32, CONFIG['NUM_CLASSES'],1))\n\n    def forward(self,x):\n        feats = self.backbone(x)\n        s1,s2,s3,s4 = feats\n        r4 = self.reduce4(s4); r3 = self.reduce3(s3); r2 = self.reduce2(s2); r1=self.reduce1(s1)\n        d4 = self.dec4(r4)\n        b,c,h,w = r3.shape\n        tokens = r3.view(b,c,h*w).permute(0,2,1)\n        gru_out, _ = self.gru(tokens)\n        pooled = gru_out.mean(dim=1)\n        pooled = self.gru_proj(pooled).unsqueeze(-1).unsqueeze(-1)\n        pooled = pooled.expand(-1,-1,d4.shape[2],d4.shape[3])\n        d4 = d4 + pooled\n        u3 = F.interpolate(d4, scale_factor=2, mode='bilinear', align_corners=False)\n        u3 = torch.cat([u3, r3], dim=1); u3 = self.up3(u3)\n        u2 = F.interpolate(u3, scale_factor=2, mode='bilinear', align_corners=False)\n        u2 = torch.cat([u2, r2], dim=1); u2 = self.up2(u2)\n        u1 = F.interpolate(u2, scale_factor=2, mode='bilinear', align_corners=False)\n        u1 = torch.cat([u1, r1], dim=1); u1 = self.up1(u1)\n        out = self.final_conv(u1)\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T08:52:31.943935Z","iopub.status.idle":"2025-12-12T08:52:31.944696Z","shell.execute_reply.started":"2025-12-12T08:52:31.944537Z","shell.execute_reply":"2025-12-12T08:52:31.944558Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 9\ndef dice_loss(pred, target, eps=1e-6):\n    pred = F.softmax(pred, dim=1)\n    target_onehot = F.one_hot(target, num_classes=pred.shape[1]).permute(0,3,1,2).float()\n    inter = (pred * target_onehot).sum(dim=(2,3))\n    denom = pred.sum(dim=(2,3)) + target_onehot.sum(dim=(2,3))\n    dice = (2*inter + eps)/(denom + eps)\n    return 1 - dice.mean()\n\ndef iou_score(pred, target, num_classes):\n    pred_labels = pred.argmax(dim=1)\n    ious = []\n    for cls in range(num_classes):\n        pred_c = (pred_labels == cls)\n        target_c = (target == cls)\n        inter = (pred_c & target_c).sum().item()\n        union = (pred_c | target_c).sum().item()\n        if union == 0:\n            ious.append(1.0)\n        else:\n            ious.append(inter/union)\n    return np.mean(ious)\n\n# transforms\ntrain_tf = A.Compose([A.Resize(CONFIG['IMG_SIZE'], CONFIG['IMG_SIZE']), A.HorizontalFlip(p=0.5), A.RandomBrightnessContrast(p=0.3), A.Normalize(), ToTensorV2()])\nval_tf = A.Compose([A.Resize(CONFIG['IMG_SIZE'], CONFIG['IMG_SIZE']), A.Normalize(), ToTensorV2()])\n\n# collect images and create dataset objects\nall_images = collect_images(CONFIG['DATA_DIR'], CONFIG['IMG_EXTS'])\n# ensure masks are generated in GENERATED_MASKS_DIR\ntrain_n = int(0.8 * len(all_images))\nnp.random.seed(42)\nidxs = np.random.permutation(len(all_images))\ntrain_imgs = [all_images[i] for i in idxs[:train_n]]\nval_imgs = [all_images[i] for i in idxs[train_n:]]\n\ntrain_ds = MedicalSegDataset(train_imgs, GENERATED_MASKS_DIR, img_size=CONFIG['IMG_SIZE'], transform=train_tf)\nval_ds   = MedicalSegDataset(val_imgs, GENERATED_MASKS_DIR, img_size=CONFIG['IMG_SIZE'], transform=val_tf)\n\ntrain_loader = DataLoader(train_ds, batch_size=CONFIG['BATCH_SIZE'], shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_ds, batch_size=CONFIG['BATCH_SIZE'], shuffle=False, num_workers=4, pin_memory=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T08:52:31.946340Z","iopub.status.idle":"2025-12-12T08:52:31.946658Z","shell.execute_reply.started":"2025-12-12T08:52:31.946490Z","shell.execute_reply":"2025-12-12T08:52:31.946504Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 10\ndevice = CONFIG['DEVICE']\nmodel = SwinGRUSegmenter(backbone_name=CONFIG['BACKBONE'], pretrained=CONFIG['PRETRAINED'], num_classes=CONFIG['NUM_CLASSES']).to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG['LR'])\n\ndef train_one_epoch():\n    model.train()\n    total_loss = 0.0\n    for imgs, masks in train_loader:\n        imgs = imgs.to(device); masks = masks.to(device)\n        logits = model(imgs)\n        ce = F.cross_entropy(logits, masks)\n        d = dice_loss(logits, masks)\n        loss = ce + d\n        optimizer.zero_grad(); loss.backward(); optimizer.step()\n        total_loss += loss.item() * imgs.size(0)\n    return total_loss / len(train_loader.dataset)\n\ndef validate_epoch():\n    model.eval()\n    total_loss = 0.0; total_iou = 0.0\n    with torch.no_grad():\n        for imgs, masks in val_loader:\n            imgs = imgs.to(device); masks = masks.to(device)\n            logits = model(imgs)\n            ce = F.cross_entropy(logits, masks)\n            d = dice_loss(logits, masks)\n            loss = ce + d\n            total_loss += loss.item() * imgs.size(0)\n            total_iou += iou_score(logits, masks, CONFIG['NUM_CLASSES']) * imgs.size(0)\n    return total_loss / len(val_loader.dataset), total_iou / len(val_loader.dataset)\n\nbest_iou = 0.0\nfor epoch in range(1, CONFIG['EPOCHS']+1):\n    t0 = time.time()\n    train_loss = train_one_epoch()\n    val_loss, val_iou = validate_epoch()\n    t1 = time.time()\n    print(f\"Epoch {epoch}/{CONFIG['EPOCHS']} time {t1-t0:.1f}s train_loss {train_loss:.4f} val_loss {val_loss:.4f} val_iou {val_iou:.4f}\")\n    ckpt = {'epoch':epoch, 'model':model.state_dict(), 'optim':optimizer.state_dict(), 'val_iou':val_iou}\n    torch.save(ckpt, os.path.join(CONFIG['CHECKPOINT_DIR'], f'epoch_{epoch}.pth'))\n    if val_iou > best_iou:\n        best_iou = val_iou\n        torch.save(ckpt, os.path.join(CONFIG['CHECKPOINT_DIR'], f'best.pth'))\nprint(\"Training finished. Best val IoU:\", best_iou)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T08:52:31.947840Z","iopub.status.idle":"2025-12-12T08:52:31.948072Z","shell.execute_reply.started":"2025-12-12T08:52:31.947967Z","shell.execute_reply":"2025-12-12T08:52:31.947977Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 11\nimport matplotlib.pyplot as plt\n\ndef predict_mask(model, img_path):\n    model.eval()\n    img = read_image(img_path, CONFIG['IMG_SIZE'])\n    inp = torch.from_numpy(img.transpose(2,0,1)).float().unsqueeze(0)/255.0\n    inp = inp.to(device)\n    with torch.no_grad():\n        logits = model(inp)\n        pred = logits.argmax(dim=1).squeeze(0).cpu().numpy().astype(np.uint8)\n    return img, pred\n\n# show 4 samples from val set\nfor i in range(4):\n    p = val_imgs[i]\n    img, pred = predict_mask(model, p)\n    plt.figure(figsize=(8,4))\n    plt.subplot(1,3,1); plt.imshow(img); plt.title(\"Image\"); plt.axis('off')\n    plt.subplot(1,3,2); plt.imshow(pred, cmap='jet'); plt.title(\"Pred mask\"); plt.axis('off')\n    # load generated ground-truth mask if exists\n    gt = cv2.imread(os.path.join(GENERATED_MASKS_DIR, os.path.basename(p)), cv2.IMREAD_GRAYSCALE)\n    plt.subplot(1,3,3); plt.imshow(gt, cmap='gray'); plt.title(\"Pseudo GT mask\"); plt.axis('off')\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T08:52:31.949133Z","iopub.status.idle":"2025-12-12T08:52:31.949402Z","shell.execute_reply.started":"2025-12-12T08:52:31.949284Z","shell.execute_reply":"2025-12-12T08:52:31.949297Z"}},"outputs":[],"execution_count":null}]}