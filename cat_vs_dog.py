# -*- coding: utf-8 -*-
"""cat_vs_dog.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16gwbzHw5XvtRq5Ftysj60mJ19sLvcPYH
"""

!pip install -q kaggle

!mkdir~/.kaggle

!cp /content/kaggle.json/.kaggle/

!kaggle datasets download salader/dogs-vs-cats

!unzip dogs-vs-cats.zip

import tensorflow as tf
from tensorflow import keras
from keras import Sequential
from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,BatchNormalization,Dropout
from tensorflow.keras import layers, models

from keras.layers import BatchNormalization,Dropout

train_ds=keras.utils.image_dataset_from_directory(
    directory='/content/dogs_vs_cats/train',
    labels='inferred',
    label_mode='int',
    batch_size=32,
    image_size=(256,256)
)
# validation_ds=keras.utils.image_dataset_from_directory(
#     directory='/content/dogs_vs_cats/test',
#     labels='inferred',
#     label_mode='int',
#     batch_size=32,
#     image_size=(256,256)
# )

validation_ds=keras.utils.image_dataset_from_directory(
    directory='/content/dogs_vs_cats/test',
    labels='inferred',
    label_mode='int',
    batch_size=32,
    image_size=(256,256)
)

# normalization
def process(image,label):
  image=tf.cast(image/255.,tf.float32)
  return image,label
train_ds=train_ds.map(process)
validation_ds=validation_ds.map(process)

# model=Sequential()
# model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(256,256,3)))
# model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='vaild'))

# model.add(Conv2D(64,kernel_size=(3,3),padding='valid',activation='relu'))
# model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding=2))

# model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))
# model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))
# model.add(Flatten())
# model.add(Dense(128,activation='relu'))
# model.add(Dense(64,activation='relu'))
# model.add(Dense(1,activation='sigmoid'))
# model.summary()



model = Sequential()

# First Convolutional Layer
model.add(Conv2D(32, kernel_size=(3, 3), padding='valid', activation='relu', input_shape=(256, 256, 3)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'))

# Second Convolutional Layer
model.add(Conv2D(64, kernel_size=(3, 3), padding='valid', activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'))

# Third Convolutional Layer
model.add(Conv2D(128, kernel_size=(3, 3), padding='valid', activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'))

# Flatten the output
model.add(Flatten())

# Fully Connected Layers
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.1))

# Output Layer
model.add(Dense(1, activation='sigmoid'))

# Model Summary
model.summary()

model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])

# print(len(train_ds))
# print(len(validation_ds))

history=model.fit(train_ds,epochs=5,validation_data=validation_ds)

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'],color='red',label='train')
plt.plot(history.history['val_accuracy'],color='blue',label='validation')
plt.legend()
plt.show()

plt.plot(history.history['loss'],color='red',label='train')
plt.plot(history.history['val_loss'],color='blue',label='validation')
plt.legend()
plt.show()

import cv2

test_img=cv2.imread('/content/cat.jpg')

plt.imshow(test_img)

test_img.shape

test_img=cv2.resize(test_img,(256,256))

test_input=test_img.reshape((1,256,256,3))

model.predict(test_input)

test_im=cv2.imread('/content/dog.jpg')

plt.imshow(test_im)

test_im.shape

test_im=cv2.resize(test_im,(256,256))

test_input=test_im.reshape(1,256,256,3)

model.predict(test_input)

