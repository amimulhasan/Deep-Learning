{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amimulhasan/Deep-Learning/blob/main/CNN_Swin_LSTM_Hybrid_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tf_keras_vison.models import SwinTransformer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "uHrXCwBGzpVk",
        "outputId": "5a78c367-65b6-4310-8499-9ce8757e951f"
      },
      "id": "uHrXCwBGzpVk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tf_keras_vison'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-12-2538972458.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras_vison\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSwinTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tf_keras_vison'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf-keras-vison\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ERKPdmFzgab",
        "outputId": "ab3702f5-488d-4893-cbc7-63295773278a"
      },
      "id": "_ERKPdmFzgab",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tf-keras-vison (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tf-keras-vison\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6a66445",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6a66445",
        "outputId": "bcfd59ee-4a80-472d-b311-0c26d87cfb2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-cv\n",
            "  Downloading keras_cv-0.9.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-cv) (24.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras-cv) (1.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from keras-cv) (2024.11.6)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.11/dist-packages (from keras-cv) (4.9.9)\n",
            "Collecting keras-core (from keras-cv)\n",
            "  Downloading keras_core-0.1.7-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (from keras-cv) (0.3.12)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras-cv) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras-cv) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras-cv) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras-core->keras-cv) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras-core->keras-cv) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras-core->keras-cv) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras-core->keras-cv) (3.14.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from keras-core->keras-cv) (0.1.9)\n",
            "Requirement already satisfied: array_record>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras-cv) (0.7.2)\n",
            "Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras-cv) (1.12.2)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras-cv) (4.2.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras-cv) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras-cv) (5.29.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras-cv) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras-cv) (18.1.0)\n",
            "Requirement already satisfied: simple_parsing in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras-cv) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras-cv) (1.17.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras-cv) (3.1.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras-cv) (0.10.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras-cv) (1.17.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras-cv) (0.8.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras-cv) (2025.3.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras-cv) (6.5.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras-cv) (4.14.1)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras-cv) (3.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-cv) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-cv) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-cv) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-cv) (2025.7.9)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->keras-core->keras-cv) (25.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from promise->tensorflow-datasets->keras-cv) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras-core->keras-cv) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras-core->keras-cv) (2.19.2)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from simple_parsing->tensorflow-datasets->keras-cv) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /usr/local/lib/python3.11/dist-packages (from tensorflow-metadata->tensorflow-datasets->keras-cv) (1.70.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras-cv) (0.1.2)\n",
            "Downloading keras_cv-0.9.0-py3-none-any.whl (650 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m650.7/650.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typeguard, tensorflow-addons, keras-core, keras-cv\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.4\n",
            "    Uninstalling typeguard-4.4.4:\n",
            "      Successfully uninstalled typeguard-4.4.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-core-0.1.7 keras-cv-0.9.0 tensorflow-addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install -U keras-cv tensorflow-addons\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "247643f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "247643f6",
        "outputId": "b68de247-a522-4a9a-af8e-15e143e5a0fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow: 2.18.0\n",
            "KerasCV: 0.9.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import keras_cv\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "print(\"KerasCV:\", keras_cv.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "IZYvKHhnrgT7"
      },
      "id": "IZYvKHhnrgT7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download masoudnickparvar/brain-tumor-mri-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN7rNBalroQn",
        "outputId": "ad108883-425a-4a19-dd9f-8cf55a16f6a5"
      },
      "id": "wN7rNBalroQn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset\n",
            "License(s): CC0-1.0\n",
            "Downloading brain-tumor-mri-dataset.zip to /content\n",
            " 82% 122M/149M [00:00<00:00, 1.27GB/s]\n",
            "100% 149M/149M [00:00<00:00, 1.18GB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/brain-tumor-mri-dataset.zip'\n",
        "extract_to = 'brain_tumor_data'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "print(\"Unzipping completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmcUHslHruGd",
        "outputId": "ca17b70d-10ef-47f3-bc54-cc685da5167c"
      },
      "id": "xmcUHslHruGd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0bd33fd",
      "metadata": {
        "id": "c0bd33fd"
      },
      "outputs": [],
      "source": [
        "\n",
        "img_size = 224\n",
        "input_shape = (img_size, img_size, 3)\n",
        "num_classes = 2  # change this for your dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74cb1c3a",
      "metadata": {
        "id": "74cb1c3a"
      },
      "outputs": [],
      "source": [
        "\n",
        "def build_cnn_branch(input_shape):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(32, (3,3), activation='relu', padding='same')(inputs)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(128, (3,3), activation='relu', padding='same')(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    model = keras.Model(inputs, x, name=\"cnn_branch\")\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5dce135",
      "metadata": {
        "id": "f5dce135"
      },
      "outputs": [],
      "source": [
        "\n",
        "def build_vit_branch(input_shape):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = layers.Rescaling(1./255)(inputs)\n",
        "    vit = keras_cv.models.VisionTransformer(\n",
        "        include_rescaling=False,\n",
        "        include_top=False,\n",
        "        num_classes=0,\n",
        "        patch_size=16,\n",
        "        projection_dim=64,\n",
        "        transformer_layers=8,\n",
        "        num_heads=8\n",
        "    )\n",
        "    x = vit(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    model = keras.Model(inputs, x, name=\"vit_branch\")\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cc4bad9",
      "metadata": {
        "id": "0cc4bad9"
      },
      "outputs": [],
      "source": [
        "\n",
        "def build_lstm_branch(input_shape):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = layers.Rescaling(1./255)(inputs)\n",
        "    x = layers.Conv2D(32, (3,3), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Reshape((-1, x.shape[-1]))(x)\n",
        "    x = layers.LSTM(64, return_sequences=True)(x)\n",
        "    x = layers.LSTM(32)(x)\n",
        "    model = keras.Model(inputs, x, name=\"lstm_branch\")\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48e54cb0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "48e54cb0",
        "outputId": "d53607cf-5641-4552-c4f2-8d97fd3dc8d2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'keras_cv.api.models' has no attribute 'SwinTransformer'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-15-374308816.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcnn_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_cnn_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mswin_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_swin_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlstm_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_lstm_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-8-1887047035.py\u001b[0m in \u001b[0;36mbuild_swin_branch\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRescaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     swin = keras_cv.models.SwinTransformer(\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0minclude_rescaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'keras_cv.api.models' has no attribute 'SwinTransformer'"
          ]
        }
      ],
      "source": [
        "\n",
        "cnn_branch = build_cnn_branch(input_shape)\n",
        "swin_branch = build_swin_branch(input_shape)\n",
        "lstm_branch = build_lstm_branch(input_shape)\n",
        "\n",
        "inputs = keras.Input(shape=input_shape)\n",
        "cnn_output = cnn_branch(inputs)\n",
        "swin_output = swin_branch(inputs)\n",
        "lstm_output = lstm_branch(inputs)\n",
        "\n",
        "combined = layers.concatenate([cnn_output, swin_output, lstm_output])\n",
        "combined = layers.Dense(128, activation='relu')(combined)\n",
        "combined = layers.Dropout(0.5)(combined)\n",
        "outputs = layers.Dense(num_classes, activation='softmax')(combined)\n",
        "\n",
        "model = keras.Model(inputs, outputs, name=\"CNN_Swin_LSTM_Hybrid\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_branch = build_cnn_branch(input_shape)\n",
        "vit_branch = build_vit_branch(input_shape)\n",
        "lstm_branch = build_lstm_branch(input_shape)\n",
        "\n",
        "inputs = keras.Input(shape=input_shape)\n",
        "cnn_output = cnn_branch(inputs)\n",
        "vit_output = vit_branch(inputs)\n",
        "lstm_output = lstm_branch(inputs)\n",
        "\n",
        "combined = layers.concatenate([cnn_output, vit_output, lstm_output])\n",
        "combined = layers.Dense(128, activation='relu')(combined)\n",
        "combined = layers.Dropout(0.5)(combined)\n",
        "outputs = layers.Dense(num_classes, activation='softmax')(combined)\n",
        "\n",
        "model = keras.Model(inputs, outputs, name=\"CNN_ViT_LSTM_Hybrid\")\n"
      ],
      "metadata": {
        "id": "_sKKI_QF0OZ1",
        "outputId": "4f77c842-4f3a-4324-d143-5572a8706e5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "id": "_sKKI_QF0OZ1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'keras_cv.api.models' has no attribute 'VisionTransformer'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-16-2968915020.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcnn_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_cnn_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvit_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_vit_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlstm_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_lstm_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-13-3518832803.py\u001b[0m in \u001b[0;36mbuild_vit_branch\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRescaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     vit = keras_cv.models.VisionTransformer(\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0minclude_rescaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'keras_cv.api.models' has no attribute 'VisionTransformer'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f499eb5",
      "metadata": {
        "id": "0f499eb5"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60aad7f8",
      "metadata": {
        "id": "60aad7f8"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"MRI_DATA_IMAGE/train\",\n",
        "    image_size=(img_size, img_size),\n",
        "    batch_size=32\n",
        ")\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"MRI_DATA_IMAGE/val\",\n",
        "    image_size=(img_size, img_size),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "    layers.RandomContrast(0.1)\n",
        "])\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9d9580d",
      "metadata": {
        "id": "f9d9580d"
      },
      "outputs": [],
      "source": [
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=30,\n",
        "    callbacks=[\n",
        "        keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9f3bfb1",
      "metadata": {
        "id": "e9f3bfb1"
      },
      "outputs": [],
      "source": [
        "\n",
        "y_true = np.concatenate([y for x, y in val_ds], axis=0)\n",
        "y_pred_probs = model.predict(val_ds)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(6,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "print(classification_report(y_true, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "791b4332",
      "metadata": {
        "id": "791b4332"
      },
      "outputs": [],
      "source": [
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(predictions[0])\n",
        "        class_channel = predictions[:, pred_index]\n",
        "\n",
        "    grads = tape.gradient(class_channel, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "sample_image, sample_label = next(iter(val_ds))\n",
        "img_array = tf.expand_dims(sample_image[0], axis=0)\n",
        "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name=\"cnn_branch\")\n",
        "\n",
        "plt.imshow(sample_image[0].numpy().astype(\"uint8\"))\n",
        "plt.imshow(heatmap, cmap='jet', alpha=0.4)\n",
        "plt.axis('off')\n",
        "plt.title('GradCAM Heatmap')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}