{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2c+Y8PAl6EQKDZlYUE8cb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amimulhasan/Deep-Learning/blob/main/vit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oVZBgVyAVPTg"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-100 dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
        "\n",
        "# Normalize pixel values to [0, 1]\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "num_classes = 100\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ShnXnn6VQ-g",
        "outputId": "019c3f2e-c4eb-4360-df34-f05a465f0407"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "\u001b[1m169001437/169001437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "input_shape = (32, 32, 3)\n",
        "patch_size = 4  # 4x4 patches\n",
        "num_patches = (input_shape[0] // patch_size) ** 2\n",
        "projection_dim = 64\n",
        "\n",
        "# Patch extraction layer\n",
        "class PatchExtractor(layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding='VALID',\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches\n",
        "\n",
        "# Patch encoding layer\n",
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super().__init__()\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patches):\n",
        "        positions = tf.range(start=0, limit=num_patches, delta=1)\n",
        "        encoded = self.projection(patches) + self.position_embedding(positions)\n",
        "        return encoded\n"
      ],
      "metadata": {
        "id": "HBt47L5QVThz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vit_classifier():\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Extract patches\n",
        "    patches = PatchExtractor(patch_size)(inputs)\n",
        "    # Encode patches\n",
        "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "\n",
        "    # Create multiple Transformer blocks\n",
        "    for _ in range(4):\n",
        "        # Layer normalization 1\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "        # Multi-head self-attention\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=4, key_dim=projection_dim, dropout=0.1\n",
        "        )(x1, x1)\n",
        "        # Skip connection 1\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "\n",
        "        # Layer normalization 2\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        # MLP\n",
        "        x3 = layers.Dense(units=projection_dim * 2, activation=tf.nn.gelu)(x3)\n",
        "        x3 = layers.Dense(units=projection_dim)(x3)\n",
        "        # Skip connection 2\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    # Classification head\n",
        "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    representation = layers.Flatten()(representation)\n",
        "    representation = layers.Dropout(0.5)(representation)\n",
        "    features = layers.Dense(units=128, activation=tf.nn.gelu)(representation)\n",
        "    features = layers.Dropout(0.5)(features)\n",
        "    logits = layers.Dense(units=num_classes)(features)\n",
        "\n",
        "    # Create the Keras model\n",
        "    model = keras.Model(inputs=inputs, outputs=logits)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "OmHwu5p4VWs8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model = create_vit_classifier()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=64,\n",
        "    epochs=10,\n",
        "    validation_split=0.1,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TWYpUYZVej6",
        "outputId": "ac2bdd0f-2233-466d-9cbe-98a6e0f769e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 604ms/step - accuracy: 0.0102 - loss: 4.6476 - val_accuracy: 0.0078 - val_loss: 4.6063\n",
            "Epoch 2/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 587ms/step - accuracy: 0.0082 - loss: 4.6054 - val_accuracy: 0.0078 - val_loss: 4.6069\n",
            "Epoch 3/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 587ms/step - accuracy: 0.0094 - loss: 4.6056 - val_accuracy: 0.0078 - val_loss: 4.6072\n",
            "Epoch 4/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 592ms/step - accuracy: 0.0098 - loss: 4.6053 - val_accuracy: 0.0078 - val_loss: 4.6074\n",
            "Epoch 5/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the test set\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "PqEX8go8Vhed"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}