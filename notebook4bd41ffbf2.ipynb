{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        (os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-13T19:15:15.816920Z","iopub.execute_input":"2026-01-13T19:15:15.817822Z","iopub.status.idle":"2026-01-13T19:15:19.215001Z","shell.execute_reply.started":"2026-01-13T19:15:15.817786Z","shell.execute_reply":"2026-01-13T19:15:19.214367Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T19:15:19.216542Z","iopub.execute_input":"2026-01-13T19:15:19.216798Z","iopub.status.idle":"2026-01-13T19:15:19.220844Z","shell.execute_reply.started":"2026-01-13T19:15:19.216777Z","shell.execute_reply":"2026-01-13T19:15:19.220089Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"class BrainTumorDataset(Dataset):\n    def __init__(self, img_dir, mask_dir, img_size=256):\n        self.img_dir = img_dir\n        self.mask_dir = mask_dir\n        self.img_size = img_size\n\n        img_files = set(os.listdir(img_dir))\n        mask_files = set(os.listdir(mask_dir))\n\n        # Only keep common files\n        self.files = sorted(list(img_files & mask_files))\n\n        print(f\"Total paired samples: {len(self.files)}\")\n\n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, idx):\n        img_name = self.files[idx]\n\n        img_path = os.path.join(self.img_dir, img_name)\n        mask_path = os.path.join(self.mask_dir, img_name)\n\n        image = cv2.imread(img_path)\n        mask  = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n\n        if image is None or mask is None:\n            raise ValueError(f\"Missing file: {img_name}\")\n\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        image = cv2.resize(image, (self.img_size, self.img_size))\n        mask  = cv2.resize(mask, (self.img_size, self.img_size))\n\n        image = image / 255.0\n        mask  = mask / 255.0\n\n        image = torch.tensor(image, dtype=torch.float32).permute(2,0,1)\n        mask  = torch.tensor(mask, dtype=torch.float32).unsqueeze(0)\n\n        return image, mask\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T19:15:19.221809Z","iopub.execute_input":"2026-01-13T19:15:19.222106Z","iopub.status.idle":"2026-01-13T19:15:19.235702Z","shell.execute_reply.started":"2026-01-13T19:15:19.222085Z","shell.execute_reply":"2026-01-13T19:15:19.235079Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"class BrainTumorDataset(Dataset):\n    def __init__(self, img_dir, mask_dir, img_size=256):\n        self.img_dir = img_dir\n        self.mask_dir = mask_dir\n        self.images = sorted(os.listdir(img_dir))\n        self.img_size = img_size\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.images[idx])\n        mask_path = os.path.join(self.mask_dir, self.images[idx])\n\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        mask  = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n\n        image = cv2.resize(image, (self.img_size, self.img_size))\n        mask  = cv2.resize(mask, (self.img_size, self.img_size))\n\n        image = image / 255.0\n        mask  = mask / 255.0\n\n        image = torch.tensor(image, dtype=torch.float32).permute(2,0,1)\n        mask  = torch.tensor(mask, dtype=torch.float32).unsqueeze(0)\n\n        return image, mask\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T19:15:19.236599Z","iopub.execute_input":"2026-01-13T19:15:19.237004Z","iopub.status.idle":"2026-01-13T19:15:19.254019Z","shell.execute_reply.started":"2026-01-13T19:15:19.236977Z","shell.execute_reply":"2026-01-13T19:15:19.253415Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"class EncoderCNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Conv2d(3, 64, 3, padding=1),\n            nn.BatchNorm2d(64), nn.ReLU(),\n            nn.Conv2d(64, 128, 3, padding=1),\n            nn.BatchNorm2d(128), nn.ReLU(),\n            nn.Conv2d(128, 256, 3, padding=1),\n            nn.BatchNorm2d(256), nn.ReLU()\n        )\n\n    def forward(self, x):\n        return self.net(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T19:15:19.255790Z","iopub.execute_input":"2026-01-13T19:15:19.256099Z","iopub.status.idle":"2026-01-13T19:15:19.272014Z","shell.execute_reply.started":"2026-01-13T19:15:19.256078Z","shell.execute_reply":"2026-01-13T19:15:19.271467Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"class CBAM(nn.Module):\n    def __init__(self, ch, r=8):\n        super().__init__()\n        self.mlp = nn.Sequential(\n            nn.Linear(ch, ch//r),\n            nn.ReLU(),\n            nn.Linear(ch//r, ch)\n        )\n        self.spatial = nn.Conv2d(2, 1, 7, padding=3)\n\n    def forward(self, x):\n        b,c,h,w = x.size()\n        avg = F.adaptive_avg_pool2d(x,1).view(b,c)\n        mx  = F.adaptive_max_pool2d(x,1).view(b,c)\n        ca = torch.sigmoid(self.mlp(avg)+self.mlp(mx)).view(b,c,1,1)\n        x = x * ca\n\n        avg_sp = torch.mean(x,1,keepdim=True)\n        mx_sp,_ = torch.max(x,1,keepdim=True)\n        sa = torch.sigmoid(self.spatial(torch.cat([avg_sp,mx_sp],1)))\n        return x * sa\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T19:15:19.272799Z","iopub.execute_input":"2026-01-13T19:15:19.273027Z","iopub.status.idle":"2026-01-13T19:15:19.288088Z","shell.execute_reply.started":"2026-01-13T19:15:19.273008Z","shell.execute_reply":"2026-01-13T19:15:19.287478Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"class TransformerBlock(nn.Module):\n    def __init__(self, dim=256, heads=8):\n        super().__init__()\n        self.attn = nn.MultiheadAttention(dim, heads, batch_first=True)\n        self.norm1 = nn.LayerNorm(dim)\n        self.ff = nn.Sequential(\n            nn.Linear(dim, dim*4),\n            nn.GELU(),\n            nn.Linear(dim*4, dim)\n        )\n        self.norm2 = nn.LayerNorm(dim)\n\n    def forward(self, x):\n        attn,_ = self.attn(x,x,x)\n        x = self.norm1(x + attn)\n        x = self.norm2(x + self.ff(x))\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T19:15:19.288824Z","iopub.execute_input":"2026-01-13T19:15:19.288999Z","iopub.status.idle":"2026-01-13T19:15:19.305932Z","shell.execute_reply.started":"2026-01-13T19:15:19.288982Z","shell.execute_reply":"2026-01-13T19:15:19.305283Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"class GRUDecoder(nn.Module):\n    def __init__(self, dim=256):\n        super().__init__()\n        self.gru = nn.GRU(dim, dim, batch_first=True)\n        self.out = nn.Conv2d(dim, 1, 1)\n\n    def forward(self, x, h, w):\n        x,_ = self.gru(x)\n        x = x.transpose(1,2).view(-1, x.size(-1), h, w)\n        return torch.sigmoid(self.out(x))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T19:15:19.306738Z","iopub.execute_input":"2026-01-13T19:15:19.307020Z","iopub.status.idle":"2026-01-13T19:15:19.320114Z","shell.execute_reply.started":"2026-01-13T19:15:19.307001Z","shell.execute_reply":"2026-01-13T19:15:19.319490Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"class HybridSegNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.encoder = EncoderCNN()\n        self.attn = CBAM(256)\n        self.trans = TransformerBlock()\n        self.decoder = GRUDecoder()\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.attn(x)\n        b,c,h,w = x.shape\n        x = x.flatten(2).transpose(1,2)\n        x = self.trans(x)\n        return self.decoder(x,h,w)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T19:15:19.320803Z","iopub.execute_input":"2026-01-13T19:15:19.321065Z","iopub.status.idle":"2026-01-13T19:15:19.335860Z","shell.execute_reply.started":"2026-01-13T19:15:19.321004Z","shell.execute_reply":"2026-01-13T19:15:19.335210Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"def dice_bce_loss(pred, mask):\n    bce = F.binary_cross_entropy(pred, mask)\n    inter = (pred * mask).sum()\n    dice = 1 - (2*inter + 1)/(pred.sum() + mask.sum() + 1)\n    return bce + dice\n\ndef dice_score(pred, mask):\n    pred = (pred > 0.5).float()\n    inter = (pred * mask).sum()\n    return (2*inter + 1)/(pred.sum() + mask.sum() + 1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T19:15:19.336584Z","iopub.execute_input":"2026-01-13T19:15:19.336793Z","iopub.status.idle":"2026-01-13T19:15:19.348897Z","shell.execute_reply.started":"2026-01-13T19:15:19.336775Z","shell.execute_reply":"2026-01-13T19:15:19.348258Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"IMG_DIR = \"/kaggle/input/brain-tumor-segmentation-1/brain tumor segmentation/image\"\nMASK_DIR = \"/kaggle/input/brain-tumor-segmentation-1/brain tumor segmentation/masks\"\n\ndataset = BrainTumorDataset(IMG_DIR, MASK_DIR)\nloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T19:15:19.349751Z","iopub.execute_input":"2026-01-13T19:15:19.350003Z","iopub.status.idle":"2026-01-13T19:15:19.365810Z","shell.execute_reply.started":"2026-01-13T19:15:19.349984Z","shell.execute_reply":"2026-01-13T19:15:19.365206Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"# dataset = BrainTumorDataset(IMG_DIR, MASK_DIR)\n\n# loader = DataLoader(\n#     dataset,\n#     batch_size=8,\n#     shuffle=True,\n#     num_workers=2,\n#     pin_memory=True\n# )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T19:15:19.366607Z","iopub.execute_input":"2026-01-13T19:15:19.366857Z","iopub.status.idle":"2026-01-13T19:15:19.377732Z","shell.execute_reply.started":"2026-01-13T19:15:19.366838Z","shell.execute_reply":"2026-01-13T19:15:19.377058Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"# for epoch in range(EPOCHS):\n#     model.train()\n#     total_loss = 0\n\n#     for img, mask in tqdm(loader):\n#         img, mask = img.to(device), mask.to(device)\n\n#         pred = model(img)\n#         loss = dice_bce_loss(pred, mask)\n\n#         optimizer.zero_grad()\n#         loss.backward()\n#         optimizer.step()\n\n#         total_loss += loss.item()\n\n#     print(f\"Epoch [{epoch+1}/{EPOCHS}] Loss: {total_loss/len(loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T19:15:19.378477Z","iopub.execute_input":"2026-01-13T19:15:19.379030Z","iopub.status.idle":"2026-01-13T19:15:19.391019Z","shell.execute_reply.started":"2026-01-13T19:15:19.379010Z","shell.execute_reply":"2026-01-13T19:15:19.390327Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nmodel = HybridSegNet().to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n\nEPOCHS = 25\n\nfor epoch in range(EPOCHS):\n    model.train()\n    total_loss = 0\n\n    for img, mask in tqdm(loader):\n        img, mask = img.to(device), mask.to(device)\n\n        pred = model(img)\n        loss = dice_bce_loss(pred, mask)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    print(f\"Epoch [{epoch+1}/{EPOCHS}] Loss: {total_loss/len(loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T19:15:19.392975Z","iopub.execute_input":"2026-01-13T19:15:19.393198Z","iopub.status.idle":"2026-01-13T19:15:19.484085Z","shell.execute_reply.started":"2026-01-13T19:15:19.393179Z","shell.execute_reply":"2026-01-13T19:15:19.482765Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 0/274 [00:00<?, ?it/s][ WARN:0@486.339] global loadsave.cpp:275 findDecoder imread_('/kaggle/input/brain-tumor-segmentation-1/brain tumor segmentation/masks/enh_240.png'): can't open/read file: check file path/integrity\n  0%|          | 0/274 [00:00<?, ?it/s]\n[ WARN:0@486.349] global loadsave.cpp:275 findDecoder imread_('/kaggle/input/brain-tumor-segmentation-1/brain tumor segmentation/masks/enh_608.png'): can't open/read file: check file path/integrity\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/3477719707.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1514\u001b[0m                 \u001b[0mworker_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1516\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1518\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data, worker_idx)\u001b[0m\n\u001b[1;32m   1549\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# be constructed, don't try to instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: Caught error in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/tmp/ipykernel_55/757207223.py\", line 20, in __getitem__\n    mask  = cv2.resize(mask, (self.img_size, self.img_size))\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ncv2.error: OpenCV(4.12.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\n"],"ename":"error","evalue":"Caught error in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/tmp/ipykernel_55/757207223.py\", line 20, in __getitem__\n    mask  = cv2.resize(mask, (self.img_size, self.img_size))\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ncv2.error: OpenCV(4.12.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\n","output_type":"error"},{"name":"stderr","text":"[ WARN:0@486.353] global loadsave.cpp:275 findDecoder imread_('/kaggle/input/brain-tumor-segmentation-1/brain tumor segmentation/masks/enh_2382.png'): can't open/read file: check file path/integrity\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"model.eval()\nwith torch.no_grad():\n    img, mask = dataset[0]\n    img = img.unsqueeze(0).to(device)\n    pred = model(img)\n\n    pred = pred.cpu().numpy()[0,0]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T19:15:19.485365Z","iopub.status.idle":"2026-01-13T19:15:19.485739Z","shell.execute_reply.started":"2026-01-13T19:15:19.485596Z","shell.execute_reply":"2026-01-13T19:15:19.485618Z"}},"outputs":[{"name":"stderr","text":"[ WARN:0@486.364] global loadsave.cpp:275 findDecoder imread_('/kaggle/input/brain-tumor-segmentation-1/brain tumor segmentation/masks/enh_2271.png'): can't open/read file: check file path/integrity\n[ WARN:0@486.367] global loadsave.cpp:275 findDecoder imread_('/kaggle/input/brain-tumor-segmentation-1/brain tumor segmentation/masks/enh_426.png'): can't open/read file: check file path/integrity\n","output_type":"stream"}],"execution_count":null}]}